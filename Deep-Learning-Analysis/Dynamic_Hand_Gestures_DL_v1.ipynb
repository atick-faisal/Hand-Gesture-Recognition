{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/Hand-Gesture-Recognition/blob/main/Deep-Learning-Analysis/Dynamic_Hand_Gestures_DL_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkE25oMeBzt6"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NSI8PsLeyijV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import joblib\n",
        "import shutil\n",
        "import tarfile\n",
        "import requests\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy.signal import butter, lfilter\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qnTuZP2MA69B"
      },
      "outputs": [],
      "source": [
        "\n",
        "DATASET_ID      = '1p0CSRb9gax0sKqdyzOYVt-BXvZ4GtrBv'\n",
        "\n",
        "# -------------BASE DIR (MODIFY THIS TO YOUR NEED) ------------ #\n",
        "BASE_DIR        = \".\"\n",
        "# BASE_DIR       = '../Dataset/'\n",
        "# BASE_DIR       = '/content/drive/MyDrive/Research/Hand Gesture/GitHub/'\n",
        "\n",
        "DATA_DIR        = 'Sensor-Data/'\n",
        "CHANNELS_DIR    = 'Channels/'\n",
        "FEATURES_DIR    = 'Features/'\n",
        "FIGURE_DIR      = 'Figures/'\n",
        "LOG_DIR         = 'Logs/'\n",
        "\n",
        "USERS           = ['001', '002', '003', '004', '005', '006', '007', '008', '009',\n",
        "                   '010', '011', '012', '013', '014', '015', '016', '017', '018',\n",
        "                   '019', '020', '021', '022', '023', '024', '025']\n",
        "GESTURES        = ['j', 'z', 'bad', 'deaf', 'fine', 'good', 'goodbye', 'hello', 'hungry',\n",
        "                   'me', 'no', 'please', 'sorry', 'thankyou', 'yes', 'you']\n",
        "\n",
        "WINDOW_LEN      = 150\n",
        "\n",
        "# ------------- FOR THE GREATER GOOD :) ------------- #\n",
        "DATASET_LEN     = 1120\n",
        "TRAIN_LEN       = 960\n",
        "TEST_LEN        = 160\n",
        "\n",
        "TEST_USER       = '001'\n",
        "EPOCHS          = 5\n",
        "\n",
        "CHANNELS_GROUP  = 'DYNAMIC_ACC_ONLY_'\n",
        "CUT_OFF         = 3.0\n",
        "ORDER           = 4\n",
        "FS              = 100\n",
        "\n",
        "CONFIG          = \"Rolling median filter for flex, LPF for IMU, Stacked CNN, epochs 20, lr 0.001\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TNEMKhZ2A69C"
      },
      "outputs": [],
      "source": [
        "\n",
        "#--------------------- Download util for Google Drive ------------------- #\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "        \n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "        \n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "\n",
        "def download_data(fid, destination):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(destination)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('creating data directory ... ', end='')\n",
        "    os.mkdir(destination)\n",
        "    print('√')\n",
        "    \n",
        "    print('downloading dataset from the repository ... ', end='')\n",
        "    filename = os.path.join(destination, 'dataset.tar.xz')\n",
        "    try:\n",
        "        download_file_from_google_drive(fid, filename)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('extracting the dataset ... ', end='')\n",
        "    try:\n",
        "        tar = tarfile.open(filename)\n",
        "        tar.extractall(destination)\n",
        "        tar.close()\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "R6fUrhiFA69E",
        "outputId": "474801c1-48f4-4306-d0af-9b0a2104e72a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cleaning already existing files ... ✕\n",
            "creating data directory ... √\n",
            "downloading dataset from the repository ... √\n",
            "extracting the dataset ... √\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ------- Comment This if already downloaded -------- #\n",
        "\n",
        "destination = os.path.join(BASE_DIR, DATA_DIR)\n",
        "download_data(DATASET_ID, destination)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yYml41AQA69E"
      },
      "outputs": [],
      "source": [
        "class LowPassFilter(object): \n",
        "    def butter_lowpass(cutoff, fs, order):\n",
        "        nyq = 0.5 * fs\n",
        "        normal_cutoff = cutoff / nyq\n",
        "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "        return b, a\n",
        "\n",
        "    def apply(data, cutoff=CUT_OFF, fs=FS, order=ORDER):\n",
        "        b, a = LowPassFilter.butter_lowpass(cutoff, fs, order=order)\n",
        "        y = lfilter(b, a, data)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3FgIg6L0A69F"
      },
      "outputs": [],
      "source": [
        "def clean_dir(path):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(path)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "    \n",
        "    print('creating ' + path + ' directory ... ', end='')\n",
        "    os.mkdir(path)\n",
        "    print('√')\n",
        "\n",
        "def extract_channels():\n",
        "    channels_dir = os.path.join(BASE_DIR, CHANNELS_DIR)\n",
        "    clean_dir(channels_dir)\n",
        "        \n",
        "    for user in USERS:\n",
        "        print('Processing data for user ' + user, end=' ')\n",
        "        \n",
        "        X = []\n",
        "        y = []\n",
        "        first_time = True\n",
        "        \n",
        "        for gesture in GESTURES:\n",
        "              \n",
        "            user_dir = os.path.join(BASE_DIR, DATA_DIR, user)\n",
        "            gesture_dir = os.path.join(user_dir, gesture + '.csv')\n",
        "\n",
        "            dataset = pd.read_csv(gesture_dir)\n",
        "\n",
        "            dataset['flex_1'] = dataset['flex_1'].rolling(3).median()\n",
        "            dataset['flex_2'] = dataset['flex_2'].rolling(3).median()\n",
        "            dataset['flex_3'] = dataset['flex_3'].rolling(3).median()\n",
        "            dataset['flex_4'] = dataset['flex_4'].rolling(3).median()\n",
        "            dataset['flex_5'] = dataset['flex_5'].rolling(3).median()\n",
        "\n",
        "            dataset.fillna(0, inplace=True)\n",
        "\n",
        "            # flex = ['flex_1', 'flex_2', 'flex_3', 'flex_4', 'flex_5']\n",
        "            # max_flex = dataset[flex].max(axis=1)\n",
        "            # max_flex.replace(0, 1, inplace=True)\n",
        "            # dataset[flex] = dataset[flex].divide(max_flex, axis=0)\n",
        "            \n",
        "            flx1 = dataset['flex_1'].to_numpy().reshape(-1, WINDOW_LEN)\n",
        "            flx2 = dataset['flex_2'].to_numpy().reshape(-1, WINDOW_LEN)\n",
        "            flx3 = dataset['flex_3'].to_numpy().reshape(-1, WINDOW_LEN)\n",
        "            flx4 = dataset['flex_4'].to_numpy().reshape(-1, WINDOW_LEN)\n",
        "            flx5 = dataset['flex_5'].to_numpy().reshape(-1, WINDOW_LEN)\n",
        "            \n",
        "            accx = dataset['ACCx'].to_numpy()\n",
        "            accy = dataset['ACCy'].to_numpy()\n",
        "            accz = dataset['ACCz'].to_numpy()\n",
        "            \n",
        "            accx = LowPassFilter.apply(accx).reshape(-1, WINDOW_LEN)\n",
        "            accy = LowPassFilter.apply(accy).reshape(-1, WINDOW_LEN)\n",
        "            accz = LowPassFilter.apply(accz).reshape(-1, WINDOW_LEN)\n",
        "            \n",
        "            gyrx = dataset['GYRx'].to_numpy()\n",
        "            gyry = dataset['GYRy'].to_numpy()\n",
        "            gyrz = dataset['GYRz'].to_numpy()\n",
        "            \n",
        "            gyrx = LowPassFilter.apply(gyrx).reshape(-1, WINDOW_LEN)\n",
        "            gyry = LowPassFilter.apply(gyry).reshape(-1, WINDOW_LEN)\n",
        "            gyrz = LowPassFilter.apply(gyrz).reshape(-1, WINDOW_LEN)\n",
        "            \n",
        "            accm = np.sqrt(accx ** 2 + accy ** 2 + accz ** 2)\n",
        "            gyrm = np.sqrt(gyrx ** 2 + gyry ** 2 + gyrz ** 2)\n",
        "            \n",
        "            g_idx = GESTURES.index(gesture)\n",
        "            labels = np.ones((accx.shape[0], 1)) * g_idx\n",
        "            \n",
        "            channels = np.stack([\n",
        "                flx1, flx2, flx3, flx4, flx5,\n",
        "                accx, accy, accz\n",
        "            ], axis=-1)\n",
        "            \n",
        "            if first_time == True:\n",
        "                X = channels\n",
        "                y = labels\n",
        "                first_time = False\n",
        "            else:\n",
        "                X = np.append(X, channels, axis=0)\n",
        "                y = np.append(y, labels, axis=0)\n",
        "            \n",
        "        \n",
        "        x_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_X.joblib')\n",
        "        y_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_y.joblib')\n",
        "        joblib.dump(X, x_path)\n",
        "        joblib.dump(y, y_path)\n",
        "        \n",
        "        print('√')\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8JNhoZxMA69H",
        "outputId": "5cd90c7f-7965-4cdc-be56-635989e645c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cleaning already existing files ... ✕\n",
            "creating ./Channels/ directory ... √\n",
            "Processing data for user 001 √\n",
            "Processing data for user 002 √\n",
            "Processing data for user 003 √\n",
            "Processing data for user 004 √\n",
            "Processing data for user 005 √\n",
            "Processing data for user 006 √\n",
            "Processing data for user 007 √\n",
            "Processing data for user 008 √\n",
            "Processing data for user 009 √\n",
            "Processing data for user 010 √\n",
            "Processing data for user 011 √\n",
            "Processing data for user 012 √\n",
            "Processing data for user 013 √\n",
            "Processing data for user 014 √\n",
            "Processing data for user 015 √\n",
            "Processing data for user 016 √\n",
            "Processing data for user 017 √\n",
            "Processing data for user 018 √\n",
            "Processing data for user 019 √\n",
            "Processing data for user 020 √\n",
            "Processing data for user 021 √\n",
            "Processing data for user 022 √\n",
            "Processing data for user 023 √\n",
            "Processing data for user 024 √\n",
            "Processing data for user 025 √\n"
          ]
        }
      ],
      "source": [
        "extract_channels()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l_nMIkDOA69I"
      },
      "outputs": [],
      "source": [
        "def get_model(input_shape = (150, 8)):\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(0.0001)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(BatchNormalization(input_shape=input_shape))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(len(GESTURES), activation='softmax'))\n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=optimizer,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EyDNvK-B7zTS"
      },
      "outputs": [],
      "source": [
        "def get_conv_block():\n",
        "    input = Input(shape=(150, 1))\n",
        "    x = BatchNormalization()(input)\n",
        "    x = Conv1D(filters=8, kernel_size=3, activation='selu', padding='valid')(x)\n",
        "    x = Conv1D(filters=16, kernel_size=3, activation='selu', padding='valid')(x)\n",
        "    x = MaxPooling1D(2)(x)\n",
        "    x = Conv1D(filters=16, kernel_size=3, activation='selu', padding='valid')(x)\n",
        "    x = Conv1D(filters=16, kernel_size=3, activation='selu', padding='valid')(x)\n",
        "    x = MaxPooling1D(2)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(50, activation='elu')(x)\n",
        "\n",
        "    return input, x\n",
        "\n",
        "def get_stacked_model(n=8):\n",
        "    inputs = []\n",
        "    CNNs = []\n",
        "\n",
        "    for i in range(n):\n",
        "        input_i, CNN_i = get_conv_block()\n",
        "        inputs.append(input_i)\n",
        "        CNNs.append(CNN_i)\n",
        "\n",
        "    x = concatenate(CNNs, axis=-1)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(100, activation='selu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    # x = Dense(20, activation='selu')(x)\n",
        "    # x = Dropout(0.5)(x)\n",
        "    output = Dense(len(GESTURES), activation='softmax')(x)\n",
        "    model = Model(inputs, output)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a_A_E2lA69J",
        "outputId": "7a86011f-6ccf-4d2f-bd79-66580424d01f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing results for user 007... \n",
            "Epoch 1/300\n",
            "120/120 [==============================] - 6s 21ms/step - loss: 2.4284 - accuracy: 0.2966 - val_loss: 0.7585 - val_accuracy: 0.7688\n",
            "Epoch 2/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 1.3216 - accuracy: 0.5667 - val_loss: 0.4368 - val_accuracy: 0.8875\n",
            "Epoch 3/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.9684 - accuracy: 0.6831 - val_loss: 0.3028 - val_accuracy: 0.9375\n",
            "Epoch 4/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.7929 - accuracy: 0.7383 - val_loss: 0.2452 - val_accuracy: 0.9500\n",
            "Epoch 5/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.6704 - accuracy: 0.7844 - val_loss: 0.2061 - val_accuracy: 0.9688\n",
            "Epoch 6/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.6136 - accuracy: 0.8070 - val_loss: 0.1814 - val_accuracy: 0.9625\n",
            "Epoch 7/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.5291 - accuracy: 0.8281 - val_loss: 0.1627 - val_accuracy: 0.9625\n",
            "Epoch 8/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.4635 - accuracy: 0.8539 - val_loss: 0.1344 - val_accuracy: 0.9812\n",
            "Epoch 9/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.4254 - accuracy: 0.8703 - val_loss: 0.1273 - val_accuracy: 0.9812\n",
            "Epoch 10/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.3715 - accuracy: 0.8846 - val_loss: 0.1149 - val_accuracy: 0.9812\n",
            "Epoch 11/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.3585 - accuracy: 0.8865 - val_loss: 0.1264 - val_accuracy: 0.9563\n",
            "Epoch 12/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.3283 - accuracy: 0.9018 - val_loss: 0.1178 - val_accuracy: 0.9625\n",
            "Epoch 13/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.3071 - accuracy: 0.9031 - val_loss: 0.1117 - val_accuracy: 0.9750\n",
            "Epoch 14/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.2792 - accuracy: 0.9138 - val_loss: 0.1154 - val_accuracy: 0.9688\n",
            "Epoch 15/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.2785 - accuracy: 0.9138 - val_loss: 0.1193 - val_accuracy: 0.9563\n",
            "Epoch 16/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.2472 - accuracy: 0.9193 - val_loss: 0.1051 - val_accuracy: 0.9563\n",
            "Epoch 17/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.2510 - accuracy: 0.9138 - val_loss: 0.1100 - val_accuracy: 0.9563\n",
            "Epoch 18/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.2381 - accuracy: 0.9242 - val_loss: 0.1007 - val_accuracy: 0.9563\n",
            "Epoch 19/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.2194 - accuracy: 0.9331 - val_loss: 0.0977 - val_accuracy: 0.9812\n",
            "Epoch 20/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.2003 - accuracy: 0.9391 - val_loss: 0.1188 - val_accuracy: 0.9563\n",
            "Epoch 21/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.2016 - accuracy: 0.9349 - val_loss: 0.1191 - val_accuracy: 0.9563\n",
            "Epoch 22/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1830 - accuracy: 0.9430 - val_loss: 0.1131 - val_accuracy: 0.9563\n",
            "Epoch 23/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.1679 - accuracy: 0.9508 - val_loss: 0.1123 - val_accuracy: 0.9500\n",
            "Epoch 24/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1668 - accuracy: 0.9469 - val_loss: 0.0950 - val_accuracy: 0.9750\n",
            "Epoch 25/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1667 - accuracy: 0.9445 - val_loss: 0.0995 - val_accuracy: 0.9563\n",
            "Epoch 26/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.1702 - accuracy: 0.9466 - val_loss: 0.1516 - val_accuracy: 0.9438\n",
            "Epoch 27/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.1607 - accuracy: 0.9484 - val_loss: 0.1195 - val_accuracy: 0.9563\n",
            "Epoch 28/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1550 - accuracy: 0.9464 - val_loss: 0.0835 - val_accuracy: 0.9812\n",
            "Epoch 29/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1573 - accuracy: 0.9482 - val_loss: 0.0802 - val_accuracy: 0.9812\n",
            "Epoch 30/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1363 - accuracy: 0.9549 - val_loss: 0.1065 - val_accuracy: 0.9625\n",
            "Epoch 31/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1495 - accuracy: 0.9542 - val_loss: 0.0779 - val_accuracy: 0.9812\n",
            "Epoch 32/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1441 - accuracy: 0.9529 - val_loss: 0.0777 - val_accuracy: 0.9812\n",
            "Epoch 33/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.1225 - accuracy: 0.9565 - val_loss: 0.0907 - val_accuracy: 0.9812\n",
            "Epoch 34/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1295 - accuracy: 0.9583 - val_loss: 0.0878 - val_accuracy: 0.9750\n",
            "Epoch 35/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1179 - accuracy: 0.9607 - val_loss: 0.0750 - val_accuracy: 0.9812\n",
            "Epoch 36/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1269 - accuracy: 0.9602 - val_loss: 0.1258 - val_accuracy: 0.9563\n",
            "Epoch 37/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.1164 - accuracy: 0.9635 - val_loss: 0.0784 - val_accuracy: 0.9812\n",
            "Epoch 38/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.1188 - accuracy: 0.9607 - val_loss: 0.0987 - val_accuracy: 0.9625\n",
            "Epoch 39/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1143 - accuracy: 0.9594 - val_loss: 0.0906 - val_accuracy: 0.9812\n",
            "Epoch 40/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.1081 - accuracy: 0.9661 - val_loss: 0.0782 - val_accuracy: 0.9812\n",
            "Epoch 41/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.1183 - accuracy: 0.9635 - val_loss: 0.0875 - val_accuracy: 0.9812\n",
            "Epoch 42/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1020 - accuracy: 0.9706 - val_loss: 0.0820 - val_accuracy: 0.9750\n",
            "Epoch 43/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.1059 - accuracy: 0.9682 - val_loss: 0.0968 - val_accuracy: 0.9688\n",
            "Epoch 44/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0975 - accuracy: 0.9698 - val_loss: 0.0962 - val_accuracy: 0.9688\n",
            "Epoch 45/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1000 - accuracy: 0.9680 - val_loss: 0.0899 - val_accuracy: 0.9750\n",
            "Epoch 46/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.0990 - accuracy: 0.9706 - val_loss: 0.1042 - val_accuracy: 0.9563\n",
            "Epoch 47/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.1075 - accuracy: 0.9641 - val_loss: 0.0875 - val_accuracy: 0.9812\n",
            "Epoch 48/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.0956 - accuracy: 0.9661 - val_loss: 0.1024 - val_accuracy: 0.9563\n",
            "Epoch 49/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0914 - accuracy: 0.9708 - val_loss: 0.0865 - val_accuracy: 0.9812\n",
            "Epoch 50/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0904 - accuracy: 0.9719 - val_loss: 0.0754 - val_accuracy: 0.9812\n",
            "Epoch 51/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0934 - accuracy: 0.9729 - val_loss: 0.1013 - val_accuracy: 0.9812\n",
            "Epoch 52/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0841 - accuracy: 0.9755 - val_loss: 0.0857 - val_accuracy: 0.9812\n",
            "Epoch 53/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.0838 - accuracy: 0.9758 - val_loss: 0.0884 - val_accuracy: 0.9812\n",
            "Epoch 54/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0904 - accuracy: 0.9693 - val_loss: 0.0837 - val_accuracy: 0.9750\n",
            "Epoch 55/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.0786 - accuracy: 0.9727 - val_loss: 0.0760 - val_accuracy: 0.9812\n",
            "Epoch 56/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0797 - accuracy: 0.9760 - val_loss: 0.0899 - val_accuracy: 0.9625\n",
            "Epoch 57/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.0714 - accuracy: 0.9768 - val_loss: 0.0789 - val_accuracy: 0.9812\n",
            "Epoch 58/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0742 - accuracy: 0.9771 - val_loss: 0.0686 - val_accuracy: 0.9812\n",
            "Epoch 59/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0719 - accuracy: 0.9773 - val_loss: 0.0787 - val_accuracy: 0.9812\n",
            "Epoch 60/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0744 - accuracy: 0.9747 - val_loss: 0.0632 - val_accuracy: 0.9875\n",
            "Epoch 61/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0810 - accuracy: 0.9740 - val_loss: 0.0575 - val_accuracy: 0.9875\n",
            "Epoch 62/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.0814 - accuracy: 0.9742 - val_loss: 0.0698 - val_accuracy: 0.9875\n",
            "Epoch 63/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.0693 - accuracy: 0.9784 - val_loss: 0.0537 - val_accuracy: 0.9875\n",
            "Epoch 64/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0741 - accuracy: 0.9758 - val_loss: 0.0577 - val_accuracy: 0.9875\n",
            "Epoch 65/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0724 - accuracy: 0.9776 - val_loss: 0.0573 - val_accuracy: 0.9875\n",
            "Epoch 66/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0660 - accuracy: 0.9786 - val_loss: 0.0717 - val_accuracy: 0.9875\n",
            "Epoch 67/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.0753 - accuracy: 0.9784 - val_loss: 0.0860 - val_accuracy: 0.9812\n",
            "Epoch 68/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0640 - accuracy: 0.9799 - val_loss: 0.0774 - val_accuracy: 0.9812\n",
            "Epoch 69/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0689 - accuracy: 0.9750 - val_loss: 0.0484 - val_accuracy: 0.9875\n",
            "Epoch 70/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0747 - accuracy: 0.9779 - val_loss: 0.0726 - val_accuracy: 0.9812\n",
            "Epoch 71/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0655 - accuracy: 0.9786 - val_loss: 0.0630 - val_accuracy: 0.9875\n",
            "Epoch 72/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0589 - accuracy: 0.9820 - val_loss: 0.0801 - val_accuracy: 0.9812\n",
            "Epoch 73/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0710 - accuracy: 0.9750 - val_loss: 0.0526 - val_accuracy: 0.9875\n",
            "Epoch 74/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0623 - accuracy: 0.9771 - val_loss: 0.0765 - val_accuracy: 0.9750\n",
            "Epoch 75/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0610 - accuracy: 0.9784 - val_loss: 0.0779 - val_accuracy: 0.9812\n",
            "Epoch 76/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0686 - accuracy: 0.9794 - val_loss: 0.0825 - val_accuracy: 0.9812\n",
            "Epoch 77/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0573 - accuracy: 0.9826 - val_loss: 0.0905 - val_accuracy: 0.9688\n",
            "Epoch 78/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0606 - accuracy: 0.9823 - val_loss: 0.0940 - val_accuracy: 0.9688\n",
            "Epoch 79/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0545 - accuracy: 0.9826 - val_loss: 0.0926 - val_accuracy: 0.9688\n",
            "Epoch 80/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0585 - accuracy: 0.9810 - val_loss: 0.0560 - val_accuracy: 0.9875\n",
            "Epoch 81/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0526 - accuracy: 0.9828 - val_loss: 0.0430 - val_accuracy: 0.9875\n",
            "Epoch 82/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0519 - accuracy: 0.9815 - val_loss: 0.0491 - val_accuracy: 0.9812\n",
            "Epoch 83/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0542 - accuracy: 0.9826 - val_loss: 0.0758 - val_accuracy: 0.9812\n",
            "Epoch 84/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0573 - accuracy: 0.9823 - val_loss: 0.0783 - val_accuracy: 0.9812\n",
            "Epoch 85/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0448 - accuracy: 0.9859 - val_loss: 0.0846 - val_accuracy: 0.9875\n",
            "Epoch 86/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0608 - accuracy: 0.9810 - val_loss: 0.0599 - val_accuracy: 0.9812\n",
            "Epoch 87/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0531 - accuracy: 0.9812 - val_loss: 0.0622 - val_accuracy: 0.9875\n",
            "Epoch 88/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0563 - accuracy: 0.9828 - val_loss: 0.0691 - val_accuracy: 0.9875\n",
            "Epoch 89/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0526 - accuracy: 0.9841 - val_loss: 0.0928 - val_accuracy: 0.9625\n",
            "Epoch 90/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0524 - accuracy: 0.9826 - val_loss: 0.0670 - val_accuracy: 0.9750\n",
            "Epoch 91/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.0526 - accuracy: 0.9839 - val_loss: 0.0829 - val_accuracy: 0.9750\n",
            "Epoch 92/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0476 - accuracy: 0.9833 - val_loss: 0.0552 - val_accuracy: 0.9875\n",
            "Epoch 93/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0490 - accuracy: 0.9826 - val_loss: 0.0507 - val_accuracy: 0.9875\n",
            "Epoch 94/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0433 - accuracy: 0.9867 - val_loss: 0.0527 - val_accuracy: 0.9875\n",
            "Epoch 95/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0587 - accuracy: 0.9818 - val_loss: 0.0634 - val_accuracy: 0.9875\n",
            "Epoch 96/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0452 - accuracy: 0.9854 - val_loss: 0.0529 - val_accuracy: 0.9875\n",
            "Epoch 97/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0396 - accuracy: 0.9872 - val_loss: 0.0481 - val_accuracy: 0.9875\n",
            "Epoch 98/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0436 - accuracy: 0.9859 - val_loss: 0.0577 - val_accuracy: 0.9875\n",
            "Epoch 99/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0467 - accuracy: 0.9854 - val_loss: 0.0432 - val_accuracy: 0.9875\n",
            "Epoch 100/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0436 - accuracy: 0.9865 - val_loss: 0.0570 - val_accuracy: 0.9875\n",
            "Epoch 101/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0395 - accuracy: 0.9867 - val_loss: 0.0568 - val_accuracy: 0.9875\n",
            "Epoch 102/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.0388 - accuracy: 0.9888 - val_loss: 0.0556 - val_accuracy: 0.9875\n",
            "Epoch 103/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0486 - accuracy: 0.9841 - val_loss: 0.0635 - val_accuracy: 0.9875\n",
            "Epoch 104/300\n",
            "120/120 [==============================] - 2s 14ms/step - loss: 0.0439 - accuracy: 0.9854 - val_loss: 0.0946 - val_accuracy: 0.9688\n",
            "Epoch 105/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0428 - accuracy: 0.9849 - val_loss: 0.0867 - val_accuracy: 0.9688\n",
            "Epoch 106/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0458 - accuracy: 0.9867 - val_loss: 0.0549 - val_accuracy: 0.9875\n",
            "Epoch 107/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0484 - accuracy: 0.9846 - val_loss: 0.0503 - val_accuracy: 0.9875\n",
            "Epoch 108/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0430 - accuracy: 0.9859 - val_loss: 0.0608 - val_accuracy: 0.9875\n",
            "Epoch 109/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0440 - accuracy: 0.9857 - val_loss: 0.0889 - val_accuracy: 0.9812\n",
            "Epoch 110/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0382 - accuracy: 0.9870 - val_loss: 0.0498 - val_accuracy: 0.9875\n",
            "Epoch 111/300\n",
            "120/120 [==============================] - 2s 15ms/step - loss: 0.0412 - accuracy: 0.9844 - val_loss: 0.0448 - val_accuracy: 0.9875\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0430 - accuracy: 0.9875\n",
            "98.75 %\n",
            "------------------------------------\n",
            "Average accuracy 98.75 +/- 0.00\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ACC = []\n",
        "logs = ''\n",
        "\n",
        "for test_user in ['007']:\n",
        "    print('Processing results for user ' + test_user, end='... \\n')\n",
        "    \n",
        "    X_train = []\n",
        "    X_test = []\n",
        "    y_train = []\n",
        "    y_test = []\n",
        "    \n",
        "    first_time_train = True\n",
        "    first_time_test = True\n",
        "\n",
        "    for user in USERS:\n",
        "        x_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_X.joblib')\n",
        "        y_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_y.joblib')\n",
        "        X = joblib.load(x_path)\n",
        "        y = joblib.load(y_path)\n",
        "\n",
        "        if user == test_user:\n",
        "            if first_time_train == True:\n",
        "                first_time_train = False\n",
        "                X_test = X\n",
        "                y_test = y\n",
        "                \n",
        "            else:\n",
        "                X_test = np.append(X_test, X, axis=0)\n",
        "                y_test = np.append(y_test, y, axis=0)\n",
        "                \n",
        "        else:\n",
        "            if first_time_test == True:\n",
        "                first_time_test = False\n",
        "                X_train = X\n",
        "                y_train = y\n",
        "                \n",
        "            else:\n",
        "                X_train = np.append(X_train, X, axis=0)\n",
        "                y_train = np.append(y_train, y, axis=0)\n",
        "\n",
        "\n",
        "    X_train, y_train = shuffle(X_train, y_train)\n",
        "    \n",
        "    # y_train = to_categorical(y_train)\n",
        "    # y_test = to_categorical(y_test)\n",
        "\n",
        "    callback = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=30, \n",
        "        mode='min',\n",
        "        restore_best_weights=True,\n",
        "    ) \n",
        "\n",
        "    model = get_stacked_model()\n",
        "    model.fit(\n",
        "        np.split(X_train, 8, axis=-1), \n",
        "        y_train, \n",
        "        epochs=300, \n",
        "        validation_data=(np.split(X_test, 8, axis=-1), y_test),\n",
        "        batch_size=32, \n",
        "        callbacks=[callback]\n",
        "    )\n",
        "\n",
        "    y_pred = model.predict(np.split(X_test, 8, axis=-1))\n",
        "    _, accuracy = model.evaluate(np.split(X_test, 8, axis=-1), y_test, batch_size=32)\n",
        "\n",
        "    accuracy = accuracy * 100\n",
        "    print(f'%.2f %%' %(accuracy))\n",
        "    logs = logs + 'Accuracy for user ' + str(test_user) + '... ' + str(accuracy) + '\\n'\n",
        "    ACC.append(accuracy)\n",
        "    \n",
        "AVG_ACC = np.mean(ACC)\n",
        "STD = np.std(ACC)\n",
        "print('------------------------------------')\n",
        "print(f'Average accuracy %.2f +/- %.2f' %(AVG_ACC, STD))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNsNXgnEA69K"
      },
      "outputs": [],
      "source": [
        "line = '---------------------------------------\\n'\n",
        "log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
        "if not os.path.exists(log_dir):\n",
        "    os.mkdir(log_dir)\n",
        "f = open(os.path.join(log_dir, 'logs_dl_basic_cnn.txt'), 'a')\n",
        "f.write(CONFIG)\n",
        "f.write(logs)\n",
        "f.write(line)\n",
        "f.write(f'Average accuracy %.2f +/- %.2f' %(AVG_ACC, STD))\n",
        "f.write('\\n\\n')\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ugVrCD9qD1Xv",
        "outputId": "ca1adf60-9ac2-4b24-82ed-b3d55aba275f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: stack_cnn_glove/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: stack_cnn_glove/assets\n"
          ]
        }
      ],
      "source": [
        "model.save(\"stack_cnn_glove\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -cvf model.tar stack_cnn_glove"
      ],
      "metadata": {
        "id": "FACvudz1yhmk",
        "outputId": "53e94ac5-159c-4e45-d4cf-ea42ada4c032",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stack_cnn_glove/\n",
            "stack_cnn_glove/saved_model.pb\n",
            "stack_cnn_glove/variables/\n",
            "stack_cnn_glove/variables/variables.data-00000-of-00001\n",
            "stack_cnn_glove/variables/variables.index\n",
            "stack_cnn_glove/keras_metadata.pb\n",
            "stack_cnn_glove/assets/\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Dynamic_Hand_Gestures_DL_v1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "toc-autonumbering": false,
    "toc-showcode": true,
    "toc-showmarkdowntxt": false
  },
  "nbformat": 4,
  "nbformat_minor": 0
}