{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/atick-faisal/Hand-Gesture-Recognition/blob/main/Deep-Learning-Analysis/Dynamic_Hand_Gestures_DL_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NSI8PsLeyijV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import shutil\n",
    "import tarfile\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import butter, lfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATASET_ID      = '1p0CSRb9gax0sKqdyzOYVt-BXvZ4GtrBv'\n",
    "\n",
    "# -------------BASE DIR (MODIFY THIS TO YOUR NEED) ------------ #\n",
    "BASE_DIR        = '../'\n",
    "# BASE_DIR     = '/content/drive/MyDrive/Research/Hand Gesture/GitHub/'\n",
    "\n",
    "DATA_DIR        = 'Sensor-Data/'\n",
    "CHANNELS_DIR    = 'Channels/'\n",
    "FEATURES_DIR    = 'Features/'\n",
    "FIGURE_DIR      = 'Figures/'\n",
    "LOG_DIR         = 'Logs/'\n",
    "\n",
    "USERS           = ['001', '002', '003', '004', '005', '006', '007', '008', '009',\n",
    "                   '010', '011', '012', '013', '014', '015', '016', '017', '018',\n",
    "                   '019', '020', '021', '022', '023', '024', '025']\n",
    "GESTURES        = ['j', 'z', 'bad', 'deaf', 'fine', 'good', 'goodbye', 'hello', 'hungry',\n",
    "                   'me', 'no', 'please', 'sorry', 'thankyou', 'yes', 'you']\n",
    "\n",
    "WINDOW_LEN      = 150\n",
    "\n",
    "# ------------- FOR THE GREATER GOOD :) ------------- #\n",
    "DATASET_LEN     = 1120\n",
    "TRAIN_LEN       = 960\n",
    "TEST_LEN        = 160\n",
    "\n",
    "TEST_USER       = '001'\n",
    "EPOCHS          = 5\n",
    "\n",
    "CHANNELS_GROUP  = 'DYNAMIC_ACC_ONLY_'\n",
    "CUT_OFF         = 3.0\n",
    "ORDER           = 4\n",
    "FS              = 100\n",
    "\n",
    "CONFIG          = CHANNELS_GROUP + 'CUT_OFF_' + str(CUT_OFF) + '_ORDER_' + str(ORDER) + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#--------------------- Download util for Google Drive ------------------- #\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "        \n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "        \n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "def download_data(fid, destination):\n",
    "    print('cleaning already existing files ... ', end='')\n",
    "    try:\n",
    "        shutil.rmtree(destination)\n",
    "        print('√')\n",
    "    except:\n",
    "        print('✕')\n",
    "        \n",
    "    print('creating data directory ... ', end='')\n",
    "    os.mkdir(destination)\n",
    "    print('√')\n",
    "    \n",
    "    print('downloading dataset from the repository ... ', end='')\n",
    "    filename = os.path.join(destination, 'dataset.tar.xz')\n",
    "    try:\n",
    "        download_file_from_google_drive(fid, filename)\n",
    "        print('√')\n",
    "    except:\n",
    "        print('✕')\n",
    "        \n",
    "    print('extracting the dataset ... ', end='')\n",
    "    try:\n",
    "        tar = tarfile.open(filename)\n",
    "        tar.extractall(destination)\n",
    "        tar.close()\n",
    "        print('√')\n",
    "    except:\n",
    "        print('✕')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------- Comment This if already downloaded -------- #\n",
    "\n",
    "# destination = os.path.join(BASE_DIR, DATA_DIR)\n",
    "# download_data(DATASET_ID, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LowPassFilter(object): \n",
    "    def butter_lowpass(cutoff, fs, order):\n",
    "        nyq = 0.5 * fs\n",
    "        normal_cutoff = cutoff / nyq\n",
    "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "        return b, a\n",
    "\n",
    "    def apply(data, cutoff=CUT_OFF, fs=FS, order=ORDER):\n",
    "        b, a = LowPassFilter.butter_lowpass(cutoff, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dir(path):\n",
    "    print('cleaning already existing files ... ', end='')\n",
    "    try:\n",
    "        shutil.rmtree(path)\n",
    "        print('√')\n",
    "    except:\n",
    "        print('✕')\n",
    "    \n",
    "    print('creating ' + path + ' directory ... ', end='')\n",
    "    os.mkdir(path)\n",
    "    print('√')\n",
    "\n",
    "def extract_channels():\n",
    "    channels_dir = os.path.join(BASE_DIR, CHANNELS_DIR)\n",
    "    clean_dir(channels_dir)\n",
    "        \n",
    "    for user in USERS:\n",
    "        print('Processing data for user ' + user, end=' ')\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        first_time = True\n",
    "        \n",
    "        for gesture in GESTURES:\n",
    "              \n",
    "            user_dir = os.path.join(BASE_DIR, DATA_DIR, user)\n",
    "            gesture_dir = os.path.join(user_dir, gesture + '.csv')\n",
    "\n",
    "            dataset = pd.read_csv(gesture_dir)\n",
    "            \n",
    "            flx1 = dataset['flex_1'].to_numpy().reshape(-1, WINDOW_LEN)\n",
    "            flx2 = dataset['flex_2'].to_numpy().reshape(-1, WINDOW_LEN)\n",
    "            flx3 = dataset['flex_3'].to_numpy().reshape(-1, WINDOW_LEN)\n",
    "            flx4 = dataset['flex_4'].to_numpy().reshape(-1, WINDOW_LEN)\n",
    "            flx5 = dataset['flex_5'].to_numpy().reshape(-1, WINDOW_LEN)\n",
    "            \n",
    "            accx = dataset['ACCx'].to_numpy()\n",
    "            accy = dataset['ACCy'].to_numpy()\n",
    "            accz = dataset['ACCz'].to_numpy()\n",
    "            \n",
    "            accx = LowPassFilter.apply(accx).reshape(-1, WINDOW_LEN)\n",
    "            accy = LowPassFilter.apply(accy).reshape(-1, WINDOW_LEN)\n",
    "            accz = LowPassFilter.apply(accz).reshape(-1, WINDOW_LEN)\n",
    "            \n",
    "            gyrx = dataset['GYRx'].to_numpy()\n",
    "            gyry = dataset['GYRy'].to_numpy()\n",
    "            gyrz = dataset['GYRz'].to_numpy()\n",
    "            \n",
    "            gyrx = LowPassFilter.apply(gyrx).reshape(-1, WINDOW_LEN)\n",
    "            gyry = LowPassFilter.apply(gyry).reshape(-1, WINDOW_LEN)\n",
    "            gyrz = LowPassFilter.apply(gyrz).reshape(-1, WINDOW_LEN)\n",
    "            \n",
    "            accm = np.sqrt(accx ** 2 + accy ** 2 + accz ** 2)\n",
    "            gyrm = np.sqrt(gyrx ** 2 + gyry ** 2 + gyrz ** 2)\n",
    "            \n",
    "            g_idx = GESTURES.index(gesture)\n",
    "            labels = np.ones((accx.shape[0], 1)) * g_idx\n",
    "            \n",
    "            channels = np.stack([\n",
    "                accx, accy, accz\n",
    "            ], axis=-1)\n",
    "            \n",
    "            if first_time == True:\n",
    "                X = channels\n",
    "                y = labels\n",
    "                first_time = False\n",
    "            else:\n",
    "                X = np.append(X, channels, axis=0)\n",
    "                y = np.append(y, labels, axis=0)\n",
    "            \n",
    "        \n",
    "        x_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_X.joblib')\n",
    "        y_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_y.joblib')\n",
    "        joblib.dump(X, x_path)\n",
    "        joblib.dump(y, y_path)\n",
    "        \n",
    "        print('√')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning already existing files ... ✕\n",
      "creating ../Channels/ directory ... √\n",
      "Processing data for user 001 √\n",
      "Processing data for user 002 √\n",
      "Processing data for user 003 √\n",
      "Processing data for user 004 √\n",
      "Processing data for user 005 √\n",
      "Processing data for user 006 √\n",
      "Processing data for user 007 √\n",
      "Processing data for user 008 √\n",
      "Processing data for user 009 √\n",
      "Processing data for user 010 √\n",
      "Processing data for user 011 √\n",
      "Processing data for user 012 √\n",
      "Processing data for user 013 √\n",
      "Processing data for user 014 √\n",
      "Processing data for user 015 √\n",
      "Processing data for user 016 √\n",
      "Processing data for user 017 √\n",
      "Processing data for user 018 √\n",
      "Processing data for user 019 √\n",
      "Processing data for user 020 √\n",
      "Processing data for user 021 √\n",
      "Processing data for user 022 √\n",
      "Processing data for user 023 √\n",
      "Processing data for user 024 √\n",
      "Processing data for user 025 √\n"
     ]
    }
   ],
   "source": [
    "extract_channels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing results for user 001... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 002... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 003... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 004... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 005... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 006... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 007... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 008... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 009... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 010... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 011... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 012... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 013... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 014... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 015... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 016... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 017... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 018... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 019... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 020... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 021... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 022... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 023... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 024... (3840, 150, 3) (3840, 1)\n",
      "Processing results for user 025... (3840, 150, 3) (3840, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ACC = []\n",
    "logs = ''\n",
    "\n",
    "for test_user in USERS:\n",
    "    print('Processing results for user ' + test_user, end='... ')\n",
    "    \n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    \n",
    "    first_time_train = True\n",
    "    first_time_test = True\n",
    "\n",
    "    for user in USERS:\n",
    "        x_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_X.joblib')\n",
    "        y_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_y.joblib')\n",
    "        X = joblib.load(x_path)\n",
    "        y = joblib.load(y_path)\n",
    "\n",
    "        if user == test_user:\n",
    "            if first_time_train == True:\n",
    "                first_time_train = False\n",
    "                X_test = X\n",
    "                y_test = y\n",
    "                \n",
    "            else:\n",
    "                X_test = np.append(X_test, X, axis=0)\n",
    "                y_test = np.append(y_test, y, axis=0)\n",
    "                \n",
    "        else:\n",
    "            if first_time_test == True:\n",
    "                first_time_test = False\n",
    "                X_train = X\n",
    "                y_train = y\n",
    "                \n",
    "            else:\n",
    "                X_train = np.append(X_train, X, axis=0)\n",
    "                y_train = np.append(y_train, y, axis=0)\n",
    "\n",
    "\n",
    "#     X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "    print(X_train.shape, y_train.shape)\n",
    "\n",
    "#     avg_acc = (acc / EPOCHS) * 100\n",
    "#     print(f'%.2f %%' %(avg_acc))\n",
    "    \n",
    "#     logs = logs + 'Average accuracy for user ' + str(test_user) + '... ' + str(avg_acc) + '\\n'\n",
    "\n",
    "#     ACC.append(avg_acc)\n",
    "    \n",
    "# AVG_ACC = np.mean(ACC)\n",
    "# STD = np.std(ACC)\n",
    "# print('------------------------------------')\n",
    "# print(f'Average accuracy %.2f +/- %.2f' %(AVG_ACC, STD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN/iLVJqXsh3lWCp9FHTqjX",
   "include_colab_link": true,
   "name": "Dynamic_Hand_Gestures_DL_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
