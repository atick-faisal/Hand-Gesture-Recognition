{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/atick-faisal/Hand-Gesture-Recognition/blob/main/Deep-Learning-Analysis/Dynamic_Hand_Gestures_DL_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NSI8PsLeyijV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import shutil\n",
    "import tarfile\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATASET_ID      = '1p0CSRb9gax0sKqdyzOYVt-BXvZ4GtrBv'\n",
    "\n",
    "# -------------BASE DIR (MODIFY THIS TO YOUR NEED) ------------ #\n",
    "BASE_DIR        = '../'\n",
    "# BASE_DIR     = '/content/drive/MyDrive/Research/Hand Gesture/GitHub/'\n",
    "\n",
    "DATA_DIR        = 'Sensor-Data/'\n",
    "CHANNELS_DIR    = 'Channels/'\n",
    "FEATURES_DIR    = 'Features/'\n",
    "FIGURE_DIR      = 'Figures/'\n",
    "LOG_DIR         = 'Logs/'\n",
    "\n",
    "USERS           = ['001', '002', '003', '004', '005', '006', '007', '008', '009',\n",
    "                   '010', '011', '012', '013', '014', '015', '016', '017', '018',\n",
    "                   '019', '020', '021', '022', '023', '024', '025']\n",
    "GESTURES        = ['j', 'z', 'bad', 'deaf', 'fine', 'good', 'goodbye', 'hello', 'hungry',\n",
    "                   'me', 'no', 'please', 'sorry', 'thankyou', 'yes', 'you']\n",
    "\n",
    "WINDOW_LEN      = 150\n",
    "\n",
    "# ------------- FOR THE GREATER GOOD :) ------------- #\n",
    "DATASET_LEN     = 1120\n",
    "TRAIN_LEN       = 960\n",
    "TEST_LEN        = 160\n",
    "\n",
    "TEST_USER       = '001'\n",
    "EPOCHS          = 5\n",
    "\n",
    "CHANNELS_GROUP  = 'DYNAMIC_ACC_ONLY_'\n",
    "CUT_OFF         = 3.0\n",
    "ORDER           = 4\n",
    "FS              = 100\n",
    "\n",
    "CONFIG          = CHANNELS_GROUP + 'CUT_OFF_' + str(CUT_OFF) + '_ORDER_' + str(ORDER) + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#--------------------- Download util for Google Drive ------------------- #\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "        \n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "        \n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "def download_data(fid, destination):\n",
    "    print('cleaning already existing files ... ', end='')\n",
    "    try:\n",
    "        shutil.rmtree(destination)\n",
    "        print('√')\n",
    "    except:\n",
    "        print('✕')\n",
    "        \n",
    "    print('creating data directory ... ', end='')\n",
    "    os.mkdir(destination)\n",
    "    print('√')\n",
    "    \n",
    "    print('downloading dataset from the repository ... ', end='')\n",
    "    filename = os.path.join(destination, 'dataset.tar.xz')\n",
    "    try:\n",
    "        download_file_from_google_drive(fid, filename)\n",
    "        print('√')\n",
    "    except:\n",
    "        print('✕')\n",
    "        \n",
    "    print('extracting the dataset ... ', end='')\n",
    "    try:\n",
    "        tar = tarfile.open(filename)\n",
    "        tar.extractall(destination)\n",
    "        tar.close()\n",
    "        print('√')\n",
    "    except:\n",
    "        print('✕')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------- Comment This if already downloaded -------- #\n",
    "\n",
    "# destination = os.path.join(BASE_DIR, DATA_DIR)\n",
    "# download_data(DATASET_ID, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LowPassFilter(object): \n",
    "    def butter_lowpass(cutoff, fs, order):\n",
    "        nyq = 0.5 * fs\n",
    "        normal_cutoff = cutoff / nyq\n",
    "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "        return b, a\n",
    "\n",
    "    def apply(data, cutoff=CUT_OFF, fs=FS, order=ORDER):\n",
    "        b, a = LowPassFilter.butter_lowpass(cutoff, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dir(path):\n",
    "    print('cleaning already existing files ... ', end='')\n",
    "    try:\n",
    "        shutil.rmtree(path)\n",
    "        print('√')\n",
    "    except:\n",
    "        print('✕')\n",
    "    \n",
    "    print('creating ' + path + ' directory ... ', end='')\n",
    "    os.mkdir(path)\n",
    "    print('√')\n",
    "\n",
    "def extract_channels():\n",
    "    channels_dir = os.path.join(BASE_DIR, CHANNELS_DIR)\n",
    "    clean_dir(channels_dir)\n",
    "        \n",
    "    for user in USERS:\n",
    "        print('Processing data for user ' + user, end=' ')\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        first_time = True\n",
    "        \n",
    "        for gesture in GESTURES:\n",
    "              \n",
    "            user_dir = os.path.join(BASE_DIR, DATA_DIR, user)\n",
    "            gesture_dir = os.path.join(user_dir, gesture + '.csv')\n",
    "\n",
    "            dataset = pd.read_csv(gesture_dir)\n",
    "            \n",
    "#             flex = ['flex_1', 'flex_2', 'flex_3', 'flex_4', 'flex_5']\n",
    "#             max_flex = dataset[flex].max(axis=1)\n",
    "#             max_flex.replace(0, 0.0001, inplace=True)\n",
    "#             dataset[flex] = dataset[flex].divide(max_flex, axis=0)\n",
    "            \n",
    "            flx1 = dataset['flex_1'].to_numpy().reshape(-1, WINDOW_LEN)\n",
    "            flx2 = dataset['flex_2'].to_numpy().reshape(-1, WINDOW_LEN)\n",
    "            flx3 = dataset['flex_3'].to_numpy().reshape(-1, WINDOW_LEN)\n",
    "            flx4 = dataset['flex_4'].to_numpy().reshape(-1, WINDOW_LEN)\n",
    "            flx5 = dataset['flex_5'].to_numpy().reshape(-1, WINDOW_LEN)\n",
    "            \n",
    "            accx = dataset['ACCx'].to_numpy()\n",
    "            accy = dataset['ACCy'].to_numpy()\n",
    "            accz = dataset['ACCz'].to_numpy()\n",
    "            \n",
    "            accx = LowPassFilter.apply(accx).reshape(-1, WINDOW_LEN)\n",
    "            accy = LowPassFilter.apply(accy).reshape(-1, WINDOW_LEN)\n",
    "            accz = LowPassFilter.apply(accz).reshape(-1, WINDOW_LEN)\n",
    "            \n",
    "            gyrx = dataset['GYRx'].to_numpy()\n",
    "            gyry = dataset['GYRy'].to_numpy()\n",
    "            gyrz = dataset['GYRz'].to_numpy()\n",
    "            \n",
    "            gyrx = LowPassFilter.apply(gyrx).reshape(-1, WINDOW_LEN)\n",
    "            gyry = LowPassFilter.apply(gyry).reshape(-1, WINDOW_LEN)\n",
    "            gyrz = LowPassFilter.apply(gyrz).reshape(-1, WINDOW_LEN)\n",
    "            \n",
    "            accm = np.sqrt(accx ** 2 + accy ** 2 + accz ** 2)\n",
    "            gyrm = np.sqrt(gyrx ** 2 + gyry ** 2 + gyrz ** 2)\n",
    "            \n",
    "            g_idx = GESTURES.index(gesture)\n",
    "            labels = np.ones((accx.shape[0], 1)) * g_idx\n",
    "            \n",
    "            channels = np.stack([\n",
    "                flx1, flx2, flx3, flx4, flx5,\n",
    "                accx, accy, accz\n",
    "            ], axis=-1)\n",
    "            \n",
    "            if first_time == True:\n",
    "                X = channels\n",
    "                y = labels\n",
    "                first_time = False\n",
    "            else:\n",
    "                X = np.append(X, channels, axis=0)\n",
    "                y = np.append(y, labels, axis=0)\n",
    "            \n",
    "        \n",
    "        x_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_X.joblib')\n",
    "        y_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_y.joblib')\n",
    "        joblib.dump(X, x_path)\n",
    "        joblib.dump(y, y_path)\n",
    "        \n",
    "        print('√')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning already existing files ... √\n",
      "creating ../Channels/ directory ... √\n",
      "Processing data for user 001 √\n",
      "Processing data for user 002 √\n",
      "Processing data for user 003 √\n",
      "Processing data for user 004 √\n",
      "Processing data for user 005 √\n",
      "Processing data for user 006 √\n",
      "Processing data for user 007 √\n",
      "Processing data for user 008 √\n",
      "Processing data for user 009 √\n",
      "Processing data for user 010 √\n",
      "Processing data for user 011 √\n",
      "Processing data for user 012 √\n",
      "Processing data for user 013 √\n",
      "Processing data for user 014 √\n",
      "Processing data for user 015 √\n",
      "Processing data for user 016 √\n",
      "Processing data for user 017 √\n",
      "Processing data for user 018 √\n",
      "Processing data for user 019 √\n",
      "Processing data for user 020 √\n",
      "Processing data for user 021 √\n",
      "Processing data for user 022 √\n",
      "Processing data for user 023 √\n",
      "Processing data for user 024 √\n",
      "Processing data for user 025 √\n"
     ]
    }
   ],
   "source": [
    "extract_channels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape = (150, 8)):\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=input_shape))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(len(GESTURES), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing results for user 001... Epoch 1/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 8.8991 - accuracy: 0.4264\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.3674 - accuracy: 0.8730\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.1824 - accuracy: 0.9440\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.1178 - accuracy: 0.9638\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.1476 - accuracy: 0.9642\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.0977 - accuracy: 0.9719\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.0398 - accuracy: 0.9834\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.0520 - accuracy: 0.9846\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0918 - accuracy: 0.9772\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0866 - accuracy: 0.9754\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5569 - accuracy: 0.8250\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ACC = []\n",
    "logs = ''\n",
    "\n",
    "for test_user in ['001']:\n",
    "    print('Processing results for user ' + test_user, end='... ')\n",
    "    \n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    \n",
    "    first_time_train = True\n",
    "    first_time_test = True\n",
    "\n",
    "    for user in USERS:\n",
    "        x_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_X.joblib')\n",
    "        y_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_y.joblib')\n",
    "        X = joblib.load(x_path)\n",
    "        y = joblib.load(y_path)\n",
    "\n",
    "        if user == test_user:\n",
    "            if first_time_train == True:\n",
    "                first_time_train = False\n",
    "                X_test = X\n",
    "                y_test = y\n",
    "                \n",
    "            else:\n",
    "                X_test = np.append(X_test, X, axis=0)\n",
    "                y_test = np.append(y_test, y, axis=0)\n",
    "                \n",
    "        else:\n",
    "            if first_time_test == True:\n",
    "                first_time_test = False\n",
    "                X_train = X\n",
    "                y_train = y\n",
    "                \n",
    "            else:\n",
    "                X_train = np.append(X_train, X, axis=0)\n",
    "                y_train = np.append(y_train, y, axis=0)\n",
    "\n",
    "\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "\n",
    "    model = get_model()\n",
    "    model.fit(\n",
    "        X_train, y_train, epochs=10, batch_size=32\n",
    "    )\n",
    "    _, accuracy = model.evaluate(X_test, y_test, batch_size=32)\n",
    "\n",
    "#     avg_acc = (acc / EPOCHS) * 100\n",
    "#     print(f'%.2f %%' %(avg_acc))\n",
    "    \n",
    "#     logs = logs + 'Average accuracy for user ' + str(test_user) + '... ' + str(avg_acc) + '\\n'\n",
    "\n",
    "#     ACC.append(avg_acc)\n",
    "    \n",
    "# AVG_ACC = np.mean(ACC)\n",
    "# STD = np.std(ACC)\n",
    "# print('------------------------------------')\n",
    "# print(f'Average accuracy %.2f +/- %.2f' %(AVG_ACC, STD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN/iLVJqXsh3lWCp9FHTqjX",
   "include_colab_link": true,
   "name": "Dynamic_Hand_Gestures_DL_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
