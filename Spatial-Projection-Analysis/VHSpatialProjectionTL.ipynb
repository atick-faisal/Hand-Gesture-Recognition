{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "VHSpatialProjectionTL.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/Hand-Gesture-Recognition/blob/main/Spatial-Projection-Analysis/VHSpatialProjectionTL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3503e833-12b3-4666-988a-8857fa2b6ffb",
        "outputId": "2a18cfb3-a11c-42c9-c3cd-40a8f0c8dc6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import joblib\n",
        "import shutil\n",
        "import tarfile\n",
        "import requests\n",
        "import gdown\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score\n",
        "\n",
        "tf.__version__"
      ],
      "id": "3503e833-12b3-4666-988a-8857fa2b6ffb",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82afa666-0f98-4d53-999c-2e5c590efc7c"
      },
      "source": [
        "TEST_USER    = '003'\n",
        "\n",
        "DATASET_ID   = '1p0CSRb9gax0sKqdyzOYVt-BXvZ4GtrBv'\n",
        "\n",
        "# -------------BASE DIR (MODIFY THIS TO YOUR NEED) ------------ #\n",
        "BASE_DIR     = os.getcwd()\n",
        "# BASE_DIR     = '/content/drive/MyDrive/Research/Hand Gesture/GitHub/'\n",
        "\n",
        "DATA_DIR     = 'Sensor-Data/'\n",
        "BW_IMG_DIR   = 'BW-Spatial-Path-Images/'\n",
        "RGB_IMG_DIR  = 'RGB-Spatial-Path-Images/'\n",
        "IMG_SIZE     = (3, 3) # INCHES\n",
        "\n",
        "IMG_DIR      = 'BW-Spatial-Path-Images/'\n",
        "LOG_DIR      = 'Logs/'\n",
        "\n",
        "USERS        = ['001', '002', '003', '004', '005', '006', '007', '008', '009',\n",
        "                '010', '011', '012', '013', '014', '015', '016', '017', '018',\n",
        "                '019', '020', '021', '022', '023', '024', '025']\n",
        "\n",
        "# ------------------------------- Only Dynalic Gestures ------------------------------ #\n",
        "GESTURES     = ['j', 'z', 'bad', 'deaf', 'fine', 'good', 'goodbye', 'hello', 'hungry',\n",
        "                'me', 'no', 'please', 'sorry', 'thankyou', 'yes', 'you']\n",
        "\n",
        "PLANES       = ['XY', 'YZ', 'ZX', 'VH']\n",
        "\n",
        "DT           = 0.01\n",
        "LINEWIDTH    = 7\n",
        "\n",
        "BATCH_SIZE   = 32\n",
        "IMG_LEN      = 96\n",
        "IMG_SIZE     = (IMG_LEN, IMG_LEN)\n",
        "CHANNELS     = 3\n",
        "IMG_SHAPE    = IMG_SIZE + (CHANNELS,)\n",
        "\n",
        "# ------------- FOR THE GREATER GOOD :) ------------- #\n",
        "DATASET_LEN  = 4000\n",
        "TRAIN_LEN    = 3840\n",
        "TEST_LEN     = 160\n",
        "\n",
        "EPOCHS       = 15\n",
        "LR           = 0.001\n",
        "DECAY        = 0.0"
      ],
      "id": "82afa666-0f98-4d53-999c-2e5c590efc7c",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0915139-f6a5-4688-b470-d7f96ea66824"
      },
      "source": [
        "#--------------------- Download util for Google Drive ------------------- #\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "        \n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "        \n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "\n",
        "def download_data(fid, destination):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(destination)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('creating data directory ... ', end='')\n",
        "    os.mkdir(destination)\n",
        "    print('√')\n",
        "    \n",
        "    print('downloading dataset from the repository ... ', end='')\n",
        "    filename = os.path.join(destination, 'dataset.tar.xz')\n",
        "    try:\n",
        "        download_file_from_google_drive(fid, filename)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('extracting the dataset ... ', end='')\n",
        "    try:\n",
        "        tar = tarfile.open(filename)\n",
        "        tar.extractall(destination)\n",
        "        tar.close()\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')   "
      ],
      "id": "d0915139-f6a5-4688-b470-d7f96ea66824",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75b25287-7ee0-450d-a021-387539401c41"
      },
      "source": [
        "# ------- Comment This if already downloaded -------- #\n",
        "\n",
        "# destination = os.path.join(BASE_DIR, DATA_DIR)\n",
        "# download_data(DATASET_ID, destination)"
      ],
      "id": "75b25287-7ee0-450d-a021-387539401c41",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ae84acc-46dc-4389-aa4b-e24bfec908e5"
      },
      "source": [
        "# ------------- Spatial Path Image Generation ----------- #\n",
        "\n",
        "def clean_dir(path):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(path)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "    \n",
        "    print('creating ' + path + ' directory ... ', end='')\n",
        "    os.mkdir(path)\n",
        "    print('√')\n",
        "    \n",
        "def get_user_acceleration_angle(gx, gy, gz, lx, ly, lz):\n",
        "\n",
        "    # Calculates angle between linear acceleration and gravity\n",
        "    # Argumnet(s):\n",
        "    #    - gx, gy, gz : Gravity vector components\n",
        "    #    - lx, ly, lz : Linear acceleration components\n",
        "\n",
        "    n = gx * lx + gy * ly + gz * lz\n",
        "    d = np.sqrt(gx ** 2 + gy ** 2 + gz ** 2) * np.sqrt(lx ** 2 + ly ** 2 + lz ** 2)\n",
        "\n",
        "    # Division by zero is not allowed\n",
        "    # Replacing all 0s with 0.000001\n",
        "    #d = np.where(d == 0, 0.000001, d)\n",
        "\n",
        "    theta = np.arccos(np.divide(n, d))\n",
        "    \n",
        "    return np.nan_to_num(theta)\n",
        "    \n",
        "# ----------- Spatial Path Vector Calculation ----------- #\n",
        "\n",
        "def get_displacement(acc):\n",
        "    v = np.zeros(acc.shape)\n",
        "    d = np.zeros(acc.shape)\n",
        "    for i in range(acc.shape[0] - 1):\n",
        "        v[i + 1] = v[i] + acc[i] * DT\n",
        "        d[i + 1] = v[i] * DT + 0.5 * acc[i] * DT * DT\n",
        "        \n",
        "    return d\n",
        "\n",
        "def write_image(x, y, path):\n",
        "    fig, ax = plt.subplots(frameon=True, figsize=(3, 3))\n",
        "    ax.axis('off')\n",
        "    plt.plot(x, y, '-k', linewidth=LINEWIDTH)\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "def generate_bw_images():\n",
        "    count = 0\n",
        "    image_dir = os.path.join(BASE_DIR, BW_IMG_DIR)\n",
        "    clean_dir(image_dir)\n",
        "    \n",
        "    for plane in PLANES:\n",
        "        print('processing spatial path images for ' + plane + ' plane ... ', end='')\n",
        "        plane_dir = os.path.join(image_dir, plane)\n",
        "        os.mkdir(plane_dir)\n",
        "        \n",
        "        for gesture in GESTURES:\n",
        "            os.mkdir(os.path.join(plane_dir, gesture))\n",
        "    \n",
        "            for user in USERS:\n",
        "                user_dir = os.path.join(BASE_DIR, DATA_DIR, user)\n",
        "                gesture_dir = os.path.join(user_dir, gesture + '.csv')\n",
        "                \n",
        "                accx = pd.read_csv(gesture_dir)['ACCx'].to_numpy()\n",
        "                accy = pd.read_csv(gesture_dir)['ACCy'].to_numpy()\n",
        "                accz = pd.read_csv(gesture_dir)['ACCz'].to_numpy()\n",
        "                \n",
        "                lacx = pd.read_csv(gesture_dir)['ACCx_body'].to_numpy()\n",
        "                lacy = pd.read_csv(gesture_dir)['ACCy_body'].to_numpy()\n",
        "                lacz = pd.read_csv(gesture_dir)['ACCz_body'].to_numpy()\n",
        "                \n",
        "                grax = accx - lacx\n",
        "                gray = accy - lacy\n",
        "                graz = accz - lacz\n",
        "                \n",
        "                theta = get_user_acceleration_angle(grax, gray, graz, lacx, lacy, lacz)\n",
        "                lm = np.sqrt(lacx ** 2 + lacy ** 2 + lacz ** 2)\n",
        "\n",
        "                accv = lm * np.cos(theta)\n",
        "                acch = lm * np.sin(theta)\n",
        "\n",
        "                x = get_displacement(accx).reshape(-1, 150)\n",
        "                y = get_displacement(accy).reshape(-1, 150)\n",
        "                z = get_displacement(accz).reshape(-1, 150)\n",
        "                v = get_displacement(accv).reshape(-1, 150)\n",
        "                h = get_displacement(acch).reshape(-1, 150)\n",
        "\n",
        "                for i in range(x.shape[0]):\n",
        "                    image_name = 'u' + user + '_g' + '{:0>2d}'.format(GESTURES.index(gesture)) + \\\n",
        "                                 '_s' + '{:0>7d}'.format(count) + '_p' + plane + '.jpg'\n",
        "                    \n",
        "                    path = os.path.join(BASE_DIR, BW_IMG_DIR, plane, gesture, image_name)\n",
        "                    \n",
        "                    if plane == 'XY':\n",
        "                        write_image(x[i, :], y[i, :], path)\n",
        "                    elif plane == 'YZ':\n",
        "                        write_image(y[i, :], z[i, :], path)\n",
        "                    elif plane == 'ZX':\n",
        "                        write_image(z[i, :], x[i, :], path)\n",
        "                    else:\n",
        "                        write_image(h[i, :], v[i, :], path)\n",
        "\n",
        "                    count = count + 1\n",
        "            \n",
        "        print('√')"
      ],
      "id": "6ae84acc-46dc-4389-aa4b-e24bfec908e5",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e227de8-b903-43a0-9a30-8628eb630b80",
        "outputId": "04264d95-d0c9-4ecb-93a2-0b87a13c7f2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "generate_bw_images()"
      ],
      "id": "3e227de8-b903-43a0-9a30-8628eb630b80",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cleaning already existing files ... √\n",
            "creating /content/BW-Spatial-Path-Images/ directory ... √\n",
            "processing spatial path images for XY plane ... √\n",
            "processing spatial path images for YZ plane ... √\n",
            "processing spatial path images for ZX plane ... √\n",
            "processing spatial path images for VH plane ... √\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1abd85aa-2917-47f9-8d76-80f02203c6f4"
      },
      "source": [
        "def load_data(plane):\n",
        "    X_train = np.zeros((TRAIN_LEN, IMG_LEN, IMG_LEN, CHANNELS))\n",
        "    X_test = np.zeros((TEST_LEN, IMG_LEN, IMG_LEN, CHANNELS))\n",
        "    y_train = np.zeros((TRAIN_LEN, 1))\n",
        "    y_test = np.zeros((TEST_LEN, 1))\n",
        "    \n",
        "    train_count = 0\n",
        "    test_count = 0\n",
        "        \n",
        "    for gesture in GESTURES:\n",
        "        print('loading data for ' + gesture + ' gesture on the ' + plane + ' plane ... ', end='')\n",
        "        path = os.path.join(BASE_DIR, IMG_DIR, plane, gesture)\n",
        "        for filename in os.listdir(path):\n",
        "            img = cv2.imread(\n",
        "                os.path.join(path, filename),\n",
        "                cv2.IMREAD_GRAYSCALE\n",
        "            )\n",
        "            resized = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            if resized.ndim < 3:\n",
        "                resized = np.expand_dims(resized, axis=-1)\n",
        "                \n",
        "            if filename[1:4] != TEST_USER:\n",
        "                X_train[train_count, :] = resized\n",
        "                y_train[train_count, 0] = GESTURES.index(gesture)\n",
        "                train_count = train_count + 1\n",
        "            else:\n",
        "                X_test[test_count, :] = resized\n",
        "                y_test[test_count, 0] = GESTURES.index(gesture)\n",
        "                test_count = test_count + 1\n",
        "                \n",
        "        print('√')\n",
        "        \n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def load_and_save_data(plane):\n",
        "    X = np.zeros((DATASET_LEN, IMG_LEN, IMG_LEN, CHANNELS))\n",
        "    y = np.zeros((DATASET_LEN, 1))\n",
        "    \n",
        "    train_count = 0\n",
        "    test_count  = TRAIN_LEN\n",
        "        \n",
        "    for gesture in GESTURES:\n",
        "        print('loading data for ' + gesture + ' gesture on the ' + plane + ' plane ... ', end='')\n",
        "        path = os.path.join(BASE_DIR, IMG_DIR, plane, gesture)\n",
        "        for filename in os.listdir(path):\n",
        "            img = cv2.imread(os.path.join(path, filename))\n",
        "            resized = cv2.resize(img, IMG_SIZE)\n",
        "            if filename[1:4] != TEST_USER:\n",
        "                X[train_count, :] = resized\n",
        "                y[train_count, 0] = GESTURES.index(gesture)\n",
        "                train_count = train_count + 1\n",
        "            else:\n",
        "                X[test_count, :] = resized\n",
        "                y[test_count, 0] = GESTURES.index(gesture)\n",
        "                test_count = test_count + 1\n",
        "                \n",
        "        print('√')\n",
        "\n",
        "    joblib.dump(X, BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    joblib.dump(y, BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "\n",
        "def load_data_from_joblib(plane):\n",
        "    print('Loading data for ' + plane + ' plane ... ', end='')\n",
        "    X = joblib.load(BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    y = joblib.load(BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    test_user = int(TEST_USER)\n",
        "    X_train = X[:TRAIN_LEN, :, :, :]\n",
        "    y_train = y[:TRAIN_LEN, :]\n",
        "    X_test = X[TRAIN_LEN:, :, :, :]\n",
        "    y_test = y[TRAIN_LEN:, :]\n",
        "\n",
        "    print('√')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "id": "1abd85aa-2917-47f9-8d76-80f02203c6f4",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06d00fb2-4063-412b-8e1c-3d211bd5752a"
      },
      "source": [
        "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
        "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.3),\n",
        "])\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "base_model.trainable = False\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(len(GESTURES))"
      ],
      "id": "06d00fb2-4063-412b-8e1c-3d211bd5752a",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfbcbdc3-c1df-4aef-9196-8948b0cf20b7"
      },
      "source": [
        "def get_model():\n",
        "    inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
        "    x = data_augmentation(inputs)\n",
        "    x = preprocess_input(inputs)\n",
        "    x = base_model(x, training=False)\n",
        "    x = global_average_layer(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    outputs = prediction_layer(x)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "    return model"
      ],
      "id": "cfbcbdc3-c1df-4aef-9196-8948b0cf20b7",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a541e0e3-a3f6-46d3-b4b9-dcdf8eb6fd84",
        "outputId": "8391cf7c-2407-4f63-9030-e264387e8446",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_xy = get_model()\n",
        "X_train_xy, X_test_xy, y_train_xy, y_test_xy = load_data('XY')\n",
        "X_train_xy, y_train_xy = shuffle(X_train_xy, y_train_xy)\n",
        "history_xy = model_xy.fit(X_train_xy, y_train_xy, validation_data=(X_test_xy, y_test_xy), epochs=EPOCHS)"
      ],
      "id": "a541e0e3-a3f6-46d3-b4b9-dcdf8eb6fd84",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading data for j gesture on the XY plane ... √\n",
            "loading data for z gesture on the XY plane ... √\n",
            "loading data for bad gesture on the XY plane ... √\n",
            "loading data for deaf gesture on the XY plane ... √\n",
            "loading data for fine gesture on the XY plane ... √\n",
            "loading data for good gesture on the XY plane ... √\n",
            "loading data for goodbye gesture on the XY plane ... √\n",
            "loading data for hello gesture on the XY plane ... √\n",
            "loading data for hungry gesture on the XY plane ... √\n",
            "loading data for me gesture on the XY plane ... √\n",
            "loading data for no gesture on the XY plane ... √\n",
            "loading data for please gesture on the XY plane ... √\n",
            "loading data for sorry gesture on the XY plane ... √\n",
            "loading data for thankyou gesture on the XY plane ... √\n",
            "loading data for yes gesture on the XY plane ... √\n",
            "loading data for you gesture on the XY plane ... √\n",
            "Epoch 1/15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f18dd71-4731-478d-b260-6a4e79c46ee4"
      },
      "source": [
        "y_pred_xy = model_xy.predict(X_test_xy)\n",
        "y_pred = np.argmax(y_pred_xy, axis=1)\n",
        "print(classification_report(y_test_xy.ravel(), y_pred, zero_division=0))\n",
        "prc_xy = precision_score(y_test_xy.ravel(), y_pred, zero_division=0, average=None)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "del X_train_xy, X_test_xy, y_train_xy, y_test_xy"
      ],
      "id": "7f18dd71-4731-478d-b260-6a4e79c46ee4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l15M5jxtew5H"
      },
      "source": [
        "model_yz = get_model()\n",
        "X_train_yz, X_test_yz, y_train_yz, y_test_yz = load_data('YZ')\n",
        "X_train_yz, y_train_yz = shuffle(X_train_yz, y_train_yz)\n",
        "history_yz = model_yz.fit(X_train_yz, y_train_yz, validation_data=(X_test_yz, y_test_yz), epochs=EPOCHS)"
      ],
      "id": "l15M5jxtew5H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChN1NG9_ezSf"
      },
      "source": [
        "y_pred_yz = model_yz.predict(X_test_yz)\n",
        "y_pred = np.argmax(y_pred_yz, axis=1)\n",
        "print(classification_report(y_test_yz.ravel(), y_pred, zero_division=0))\n",
        "prc_yz = precision_score(y_test_yz.ravel(), y_pred, zero_division=0, average=None)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "del X_train_yz, X_test_yz, y_train_yz, y_test_yz"
      ],
      "id": "ChN1NG9_ezSf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P3xqIHXe2Pi"
      },
      "source": [
        "model_zx = get_model()\n",
        "X_train_zx, X_test_zx, y_train_zx, y_test_zx = load_data('ZX')\n",
        "X_train_zx, y_train_zx = shuffle(X_train_zx, y_train_zx)\n",
        "history_zx = model_zx.fit(X_train_zx, y_train_zx, validation_data=(X_test_zx, y_test_zx), epochs=EPOCHS)"
      ],
      "id": "6P3xqIHXe2Pi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufP2NBNBe67G"
      },
      "source": [
        "y_pred_zx = model_zx.predict(X_test_zx)\n",
        "y_pred = np.argmax(y_pred_zx, axis=1)\n",
        "print(classification_report(y_test_zx.ravel(), y_pred, zero_division=0))\n",
        "prc_zx = precision_score(y_test_zx.ravel(), y_pred, zero_division=0, average=None)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "del X_train_zx, X_test_zx, y_train_zx"
      ],
      "id": "ufP2NBNBe67G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O62qCoa5e7pF"
      },
      "source": [
        "model_vh = get_model()\n",
        "X_train_vh, X_test_vh, y_train_vh, y_test_vh = load_data('VH')\n",
        "X_train_vh, y_train_vh = shuffle(X_train_vh, y_train_vh)\n",
        "history_vh = model_vh.fit(X_train_vh, y_train_vh, validation_data=(X_test_vh, y_test_vh), epochs=EPOCHS)"
      ],
      "id": "O62qCoa5e7pF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEHVZa9JfBco"
      },
      "source": [
        "y_pred_vh = model_vh.predict(X_test_vh)\n",
        "y_pred = np.argmax(y_pred_vh, axis=1)\n",
        "print(classification_report(y_test_vh.ravel(), y_pred, zero_division=0))\n",
        "prc_vh = precision_score(y_test_vh.ravel(), y_pred, zero_division=0, average=None)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "del X_train_vh, X_test_vh, y_train_vh"
      ],
      "id": "GEHVZa9JfBco",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gP_MCDsfE6n"
      },
      "source": [
        "y_total = y_pred_xy + y_pred_yz + y_pred_zx + y_pred_vh\n",
        "y_pred = np.argmax(y_total, axis=1)\n",
        "report = classification_report(y_test_zx.ravel(), y_pred, zero_division=0)\n",
        "print(report)"
      ],
      "id": "8gP_MCDsfE6n",
      "execution_count": null,
      "outputs": []
    }
  ]
}