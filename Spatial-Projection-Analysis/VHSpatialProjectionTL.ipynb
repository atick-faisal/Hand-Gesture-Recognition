{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "VHSpatialProjectionTL.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/Hand-Gesture-Recognition/blob/main/Spatial-Projection-Analysis/VHSpatialProjectionTL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3503e833-12b3-4666-988a-8857fa2b6ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "43fdf447-de5e-40df-acd6-840c9b812225"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import joblib\n",
        "import shutil\n",
        "import tarfile\n",
        "import requests\n",
        "import gdown\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score\n",
        "\n",
        "tf.__version__"
      ],
      "id": "3503e833-12b3-4666-988a-8857fa2b6ffb",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82afa666-0f98-4d53-999c-2e5c590efc7c"
      },
      "source": [
        "TEST_USER    = '004'\n",
        "\n",
        "DATASET_ID   = '1p0CSRb9gax0sKqdyzOYVt-BXvZ4GtrBv'\n",
        "\n",
        "# -------------BASE DIR (MODIFY THIS TO YOUR NEED) ------------ #\n",
        "BASE_DIR     = os.getcwd()\n",
        "# BASE_DIR     = '/content/drive/MyDrive/Research/Hand Gesture/GitHub/'\n",
        "\n",
        "DATA_DIR     = 'Sensor-Data/'\n",
        "BW_IMG_DIR   = 'BW-Spatial-Path-Images/'\n",
        "RGB_IMG_DIR  = 'RGB-Spatial-Path-Images/'\n",
        "IMG_SIZE     = (3, 3) # INCHES\n",
        "\n",
        "IMG_DIR      = 'BW-Spatial-Path-Images/'\n",
        "LOG_DIR      = 'Logs/'\n",
        "\n",
        "USERS        = ['001', '002', '003', '004', '005', '006', '007', '008', '009',\n",
        "                '010', '011', '012', '013', '014', '015', '016', '017', '018',\n",
        "                '019', '020', '021', '022', '023', '024', '025']\n",
        "\n",
        "# ------------------------------- Only Dynalic Gestures ------------------------------ #\n",
        "GESTURES     = ['j', 'z', 'bad', 'deaf', 'fine', 'good', 'goodbye', 'hello', 'hungry',\n",
        "                'me', 'no', 'please', 'sorry', 'thankyou', 'yes', 'you']\n",
        "\n",
        "PLANES       = ['XY', 'YZ', 'ZX', 'VH']\n",
        "\n",
        "DT           = 0.01\n",
        "LINEWIDTH    = 7\n",
        "\n",
        "BATCH_SIZE   = 32\n",
        "IMG_LEN      = 48\n",
        "IMG_SIZE     = (IMG_LEN, IMG_LEN)\n",
        "CHANNELS     = 3\n",
        "IMG_SHAPE    = IMG_SIZE + (CHANNELS,)\n",
        "\n",
        "# ------------- FOR THE GREATER GOOD :) ------------- #\n",
        "DATASET_LEN  = 4000\n",
        "TRAIN_LEN    = 3840\n",
        "TEST_LEN     = 160\n",
        "\n",
        "EPOCHS       = 15\n",
        "LR           = 0.001\n",
        "DECAY        = 0.0"
      ],
      "id": "82afa666-0f98-4d53-999c-2e5c590efc7c",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0915139-f6a5-4688-b470-d7f96ea66824"
      },
      "source": [
        "#--------------------- Download util for Google Drive ------------------- #\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "        \n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "        \n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "\n",
        "def download_data(fid, destination):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(destination)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('creating data directory ... ', end='')\n",
        "    os.mkdir(destination)\n",
        "    print('√')\n",
        "    \n",
        "    print('downloading dataset from the repository ... ', end='')\n",
        "    filename = os.path.join(destination, 'dataset.tar.xz')\n",
        "    try:\n",
        "        download_file_from_google_drive(fid, filename)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('extracting the dataset ... ', end='')\n",
        "    try:\n",
        "        tar = tarfile.open(filename)\n",
        "        tar.extractall(destination)\n",
        "        tar.close()\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')   "
      ],
      "id": "d0915139-f6a5-4688-b470-d7f96ea66824",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75b25287-7ee0-450d-a021-387539401c41"
      },
      "source": [
        "# ------- Comment This if already downloaded -------- #\n",
        "\n",
        "# destination = os.path.join(BASE_DIR, DATA_DIR)\n",
        "# download_data(DATASET_ID, destination)"
      ],
      "id": "75b25287-7ee0-450d-a021-387539401c41",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ae84acc-46dc-4389-aa4b-e24bfec908e5"
      },
      "source": [
        "# ------------- Spatial Path Image Generation ----------- #\n",
        "\n",
        "def clean_dir(path):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(path)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "    \n",
        "    print('creating ' + path + ' directory ... ', end='')\n",
        "    os.mkdir(path)\n",
        "    print('√')\n",
        "    \n",
        "def get_user_acceleration_angle(gx, gy, gz, lx, ly, lz):\n",
        "\n",
        "    # Calculates angle between linear acceleration and gravity\n",
        "    # Argumnet(s):\n",
        "    #    - gx, gy, gz : Gravity vector components\n",
        "    #    - lx, ly, lz : Linear acceleration components\n",
        "\n",
        "    n = gx * lx + gy * ly + gz * lz\n",
        "    d = np.sqrt(gx ** 2 + gy ** 2 + gz ** 2) * np.sqrt(lx ** 2 + ly ** 2 + lz ** 2)\n",
        "\n",
        "    # Division by zero is not allowed\n",
        "    # Replacing all 0s with 0.000001\n",
        "    #d = np.where(d == 0, 0.000001, d)\n",
        "\n",
        "    theta = np.arccos(np.divide(n, d))\n",
        "    \n",
        "    return np.nan_to_num(theta)\n",
        "    \n",
        "# ----------- Spatial Path Vector Calculation ----------- #\n",
        "\n",
        "def get_displacement(acc):\n",
        "    v = np.zeros(acc.shape)\n",
        "    d = np.zeros(acc.shape)\n",
        "    for i in range(acc.shape[0] - 1):\n",
        "        v[i + 1] = v[i] + acc[i] * DT\n",
        "        d[i + 1] = v[i] * DT + 0.5 * acc[i] * DT * DT\n",
        "        \n",
        "    return d\n",
        "\n",
        "def write_image(x, y, path):\n",
        "    fig, ax = plt.subplots(frameon=True, figsize=(3, 3))\n",
        "    ax.axis('off')\n",
        "    plt.plot(x, y, '-k', linewidth=LINEWIDTH)\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "def generate_bw_images():\n",
        "    count = 0\n",
        "    image_dir = os.path.join(BASE_DIR, BW_IMG_DIR)\n",
        "    clean_dir(image_dir)\n",
        "    \n",
        "    for plane in PLANES:\n",
        "        print('processing spatial path images for ' + plane + ' plane ... ', end='')\n",
        "        plane_dir = os.path.join(image_dir, plane)\n",
        "        os.mkdir(plane_dir)\n",
        "        \n",
        "        for gesture in GESTURES:\n",
        "            os.mkdir(os.path.join(plane_dir, gesture))\n",
        "    \n",
        "            for user in USERS:\n",
        "                user_dir = os.path.join(BASE_DIR, DATA_DIR, user)\n",
        "                gesture_dir = os.path.join(user_dir, gesture + '.csv')\n",
        "                \n",
        "                accx = pd.read_csv(gesture_dir)['ACCx'].to_numpy()\n",
        "                accy = pd.read_csv(gesture_dir)['ACCy'].to_numpy()\n",
        "                accz = pd.read_csv(gesture_dir)['ACCz'].to_numpy()\n",
        "                \n",
        "                lacx = pd.read_csv(gesture_dir)['ACCx_body'].to_numpy()\n",
        "                lacy = pd.read_csv(gesture_dir)['ACCy_body'].to_numpy()\n",
        "                lacz = pd.read_csv(gesture_dir)['ACCz_body'].to_numpy()\n",
        "                \n",
        "                grax = accx - lacx\n",
        "                gray = accy - lacy\n",
        "                graz = accz - lacz\n",
        "                \n",
        "                theta = get_user_acceleration_angle(grax, gray, graz, lacx, lacy, lacz)\n",
        "                lm = np.sqrt(lacx ** 2 + lacy ** 2 + lacz ** 2)\n",
        "\n",
        "                accv = lm * np.cos(theta)\n",
        "                acch = lm * np.sin(theta)\n",
        "\n",
        "                x = get_displacement(accx).reshape(-1, 150)\n",
        "                y = get_displacement(accy).reshape(-1, 150)\n",
        "                z = get_displacement(accz).reshape(-1, 150)\n",
        "                v = get_displacement(accv).reshape(-1, 150)\n",
        "                h = get_displacement(acch).reshape(-1, 150)\n",
        "\n",
        "                for i in range(x.shape[0]):\n",
        "                    image_name = 'u' + user + '_g' + '{:0>2d}'.format(GESTURES.index(gesture)) + \\\n",
        "                                 '_s' + '{:0>7d}'.format(count) + '_p' + plane + '.jpg'\n",
        "                    \n",
        "                    path = os.path.join(BASE_DIR, BW_IMG_DIR, plane, gesture, image_name)\n",
        "                    \n",
        "                    if plane == 'XY':\n",
        "                        write_image(x[i, :], y[i, :], path)\n",
        "                    elif plane == 'YZ':\n",
        "                        write_image(y[i, :], z[i, :], path)\n",
        "                    elif plane == 'ZX':\n",
        "                        write_image(z[i, :], x[i, :], path)\n",
        "                    else:\n",
        "                        write_image(h[i, :], v[i, :], path)\n",
        "\n",
        "                    count = count + 1\n",
        "            \n",
        "        print('√')"
      ],
      "id": "6ae84acc-46dc-4389-aa4b-e24bfec908e5",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e227de8-b903-43a0-9a30-8628eb630b80"
      },
      "source": [
        "# generate_bw_images()"
      ],
      "id": "3e227de8-b903-43a0-9a30-8628eb630b80",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1abd85aa-2917-47f9-8d76-80f02203c6f4"
      },
      "source": [
        "def load_data(plane):\n",
        "    X_train = np.zeros((TRAIN_LEN, IMG_LEN, IMG_LEN, CHANNELS))\n",
        "    X_test = np.zeros((TEST_LEN, IMG_LEN, IMG_LEN, CHANNELS))\n",
        "    y_train = np.zeros((TRAIN_LEN, 1))\n",
        "    y_test = np.zeros((TEST_LEN, 1))\n",
        "    \n",
        "    train_count = 0\n",
        "    test_count = 0\n",
        "        \n",
        "    for gesture in GESTURES:\n",
        "        print('loading data for ' + gesture + ' gesture on the ' + plane + ' plane ... ', end='')\n",
        "        path = os.path.join(BASE_DIR, IMG_DIR, plane, gesture)\n",
        "        for filename in os.listdir(path):\n",
        "            img = cv2.imread(\n",
        "                os.path.join(path, filename),\n",
        "                cv2.IMREAD_GRAYSCALE\n",
        "            )\n",
        "            resized = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            if resized.ndim < 3:\n",
        "                resized = np.expand_dims(resized, axis=-1)\n",
        "                \n",
        "            if filename[1:4] != TEST_USER:\n",
        "                X_train[train_count, :] = resized\n",
        "                y_train[train_count, 0] = GESTURES.index(gesture)\n",
        "                train_count = train_count + 1\n",
        "            else:\n",
        "                X_test[test_count, :] = resized\n",
        "                y_test[test_count, 0] = GESTURES.index(gesture)\n",
        "                test_count = test_count + 1\n",
        "                \n",
        "        print('√')\n",
        "        \n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def load_and_save_data(plane):\n",
        "    X = np.zeros((DATASET_LEN, IMG_LEN, IMG_LEN, CHANNELS))\n",
        "    y = np.zeros((DATASET_LEN, 1))\n",
        "    \n",
        "    train_count = 0\n",
        "    test_count  = TRAIN_LEN\n",
        "        \n",
        "    for gesture in GESTURES:\n",
        "        print('loading data for ' + gesture + ' gesture on the ' + plane + ' plane ... ', end='')\n",
        "        path = os.path.join(BASE_DIR, IMG_DIR, plane, gesture)\n",
        "        for filename in os.listdir(path):\n",
        "            img = cv2.imread(os.path.join(path, filename))\n",
        "            resized = cv2.resize(img, IMG_SIZE)\n",
        "            if filename[1:4] != TEST_USER:\n",
        "                X[train_count, :] = resized\n",
        "                y[train_count, 0] = GESTURES.index(gesture)\n",
        "                train_count = train_count + 1\n",
        "            else:\n",
        "                X[test_count, :] = resized\n",
        "                y[test_count, 0] = GESTURES.index(gesture)\n",
        "                test_count = test_count + 1\n",
        "                \n",
        "        print('√')\n",
        "\n",
        "    joblib.dump(X, BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    joblib.dump(y, BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "\n",
        "def load_data_from_joblib(plane):\n",
        "    print('Loading data for ' + plane + ' plane ... ', end='')\n",
        "    X = joblib.load(BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    y = joblib.load(BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    test_user = int(TEST_USER)\n",
        "    X_train = X[:TRAIN_LEN, :, :, :]\n",
        "    y_train = y[:TRAIN_LEN, :]\n",
        "    X_test = X[TRAIN_LEN:, :, :, :]\n",
        "    y_test = y[TRAIN_LEN:, :]\n",
        "\n",
        "    print('√')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "id": "1abd85aa-2917-47f9-8d76-80f02203c6f4",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06d00fb2-4063-412b-8e1c-3d211bd5752a",
        "outputId": "8a5de39c-2fe6-45df-f439-c5098f61b456",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
        "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.3),\n",
        "])\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "base_model.trainable = False\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(len(GESTURES))"
      ],
      "id": "06d00fb2-4063-412b-8e1c-3d211bd5752a",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfbcbdc3-c1df-4aef-9196-8948b0cf20b7"
      },
      "source": [
        "# def get_model():\n",
        "#     inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
        "#     x = data_augmentation(inputs)\n",
        "#     x = preprocess_input(inputs)\n",
        "#     x = base_model(x, training=False)\n",
        "#     x = global_average_layer(x)\n",
        "#     x = tf.keras.layers.Dropout(0.2)(x)\n",
        "#     outputs = prediction_layer(x)\n",
        "#     model = tf.keras.Model(inputs, outputs)\n",
        "#     model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
        "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#               metrics=['accuracy'])\n",
        "#     return model\n",
        "\n",
        "def get_model():\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Input(shape=IMG_SHAPE))\n",
        "    model.add(tf.keras.layers.experimental.preprocessing.Rescaling(1./255.0, offset=0))\n",
        "    model.add(tf.keras.layers.Conv2D(8, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.0))\n",
        "    model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.0))\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPool2D(2, 2))\n",
        "    model.add(tf.keras.layers.Dropout(0.0))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(len(GESTURES)))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "    \n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "id": "cfbcbdc3-c1df-4aef-9196-8948b0cf20b7",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a541e0e3-a3f6-46d3-b4b9-dcdf8eb6fd84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff26ec87-e51e-450c-9319-736826d1a9e0"
      },
      "source": [
        "model_xy = get_model()\n",
        "X_train_xy, X_test_xy, y_train_xy, y_test_xy = load_data('XY')\n",
        "X_train_xy, y_train_xy = shuffle(X_train_xy, y_train_xy)\n",
        "history_xy = model_xy.fit(X_train_xy, y_train_xy, validation_data=(X_test_xy, y_test_xy), epochs=EPOCHS)"
      ],
      "id": "a541e0e3-a3f6-46d3-b4b9-dcdf8eb6fd84",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rescaling_1 (Rescaling)      (None, 48, 48, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 46, 46, 8)         224       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 23, 23, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 23, 23, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 21, 21, 16)        1168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 32)          4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                2064      \n",
            "=================================================================\n",
            "Total params: 73,760\n",
            "Trainable params: 73,760\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "loading data for j gesture on the XY plane ... √\n",
            "loading data for z gesture on the XY plane ... √\n",
            "loading data for bad gesture on the XY plane ... √\n",
            "loading data for deaf gesture on the XY plane ... √\n",
            "loading data for fine gesture on the XY plane ... √\n",
            "loading data for good gesture on the XY plane ... √\n",
            "loading data for goodbye gesture on the XY plane ... √\n",
            "loading data for hello gesture on the XY plane ... √\n",
            "loading data for hungry gesture on the XY plane ... √\n",
            "loading data for me gesture on the XY plane ... √\n",
            "loading data for no gesture on the XY plane ... √\n",
            "loading data for please gesture on the XY plane ... √\n",
            "loading data for sorry gesture on the XY plane ... √\n",
            "loading data for thankyou gesture on the XY plane ... √\n",
            "loading data for yes gesture on the XY plane ... √\n",
            "loading data for you gesture on the XY plane ... √\n",
            "Epoch 1/15\n",
            "120/120 [==============================] - 3s 5ms/step - loss: 2.4435 - accuracy: 0.2073 - val_loss: 3.0363 - val_accuracy: 0.0938\n",
            "Epoch 2/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 1.5912 - accuracy: 0.4667 - val_loss: 3.3737 - val_accuracy: 0.1937\n",
            "Epoch 3/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 1.2384 - accuracy: 0.5810 - val_loss: 3.7907 - val_accuracy: 0.2062\n",
            "Epoch 4/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 1.0599 - accuracy: 0.6240 - val_loss: 3.5838 - val_accuracy: 0.2438\n",
            "Epoch 5/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.9387 - accuracy: 0.6680 - val_loss: 3.8757 - val_accuracy: 0.2562\n",
            "Epoch 6/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.8658 - accuracy: 0.6805 - val_loss: 4.5312 - val_accuracy: 0.2500\n",
            "Epoch 7/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.8089 - accuracy: 0.7122 - val_loss: 4.9732 - val_accuracy: 0.2500\n",
            "Epoch 8/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.7252 - accuracy: 0.7482 - val_loss: 5.0451 - val_accuracy: 0.2688\n",
            "Epoch 9/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.7002 - accuracy: 0.7474 - val_loss: 5.1889 - val_accuracy: 0.2688\n",
            "Epoch 10/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.6647 - accuracy: 0.7599 - val_loss: 5.4617 - val_accuracy: 0.2625\n",
            "Epoch 11/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.6567 - accuracy: 0.7625 - val_loss: 5.5218 - val_accuracy: 0.2625\n",
            "Epoch 12/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.5962 - accuracy: 0.7820 - val_loss: 6.4005 - val_accuracy: 0.2688\n",
            "Epoch 13/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.5653 - accuracy: 0.7984 - val_loss: 6.0181 - val_accuracy: 0.2812\n",
            "Epoch 14/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.5524 - accuracy: 0.7906 - val_loss: 6.6970 - val_accuracy: 0.2750\n",
            "Epoch 15/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.8159 - val_loss: 6.7480 - val_accuracy: 0.2750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f18dd71-4731-478d-b260-6a4e79c46ee4",
        "outputId": "b663c484-4b67-4d10-d103-d1103ec8c939",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred_xy = model_xy.predict(X_test_xy)\n",
        "y_pred = np.argmax(y_pred_xy, axis=1)\n",
        "print(classification_report(y_test_xy.ravel(), y_pred, zero_division=0))\n",
        "prc_xy = precision_score(y_test_xy.ravel(), y_pred, zero_division=0, average=None)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "del X_train_xy, X_test_xy, y_train_xy, y_test_xy"
      ],
      "id": "7f18dd71-4731-478d-b260-6a4e79c46ee4",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.91      1.00      0.95        10\n",
            "         1.0       1.00      1.00      1.00        10\n",
            "         2.0       0.00      0.00      0.00        10\n",
            "         3.0       0.00      0.00      0.00        10\n",
            "         4.0       0.00      0.00      0.00        10\n",
            "         5.0       0.00      0.00      0.00        10\n",
            "         6.0       1.00      0.10      0.18        10\n",
            "         7.0       0.29      0.20      0.24        10\n",
            "         8.0       0.00      0.00      0.00        10\n",
            "         9.0       0.33      0.70      0.45        10\n",
            "        10.0       0.00      0.00      0.00        10\n",
            "        11.0       0.00      0.00      0.00        10\n",
            "        12.0       0.00      0.00      0.00        10\n",
            "        13.0       1.00      0.10      0.18        10\n",
            "        14.0       0.43      0.30      0.35        10\n",
            "        15.0       0.12      1.00      0.22        10\n",
            "\n",
            "    accuracy                           0.28       160\n",
            "   macro avg       0.32      0.28      0.22       160\n",
            "weighted avg       0.32      0.28      0.22       160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l15M5jxtew5H",
        "outputId": "b50f1a5a-099e-427e-9d35-ff3f1b208297",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_yz = get_model()\n",
        "X_train_yz, X_test_yz, y_train_yz, y_test_yz = load_data('YZ')\n",
        "X_train_yz, y_train_yz = shuffle(X_train_yz, y_train_yz)\n",
        "history_yz = model_yz.fit(X_train_yz, y_train_yz, validation_data=(X_test_yz, y_test_yz), epochs=EPOCHS)"
      ],
      "id": "l15M5jxtew5H",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rescaling (Rescaling)        (None, 48, 48, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 46, 46, 8)         224       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 23, 23, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 23, 23, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 21, 21, 16)        1168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 32)          4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                2064      \n",
            "=================================================================\n",
            "Total params: 73,760\n",
            "Trainable params: 73,760\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "loading data for j gesture on the YZ plane ... √\n",
            "loading data for z gesture on the YZ plane ... √\n",
            "loading data for bad gesture on the YZ plane ... √\n",
            "loading data for deaf gesture on the YZ plane ... √\n",
            "loading data for fine gesture on the YZ plane ... √\n",
            "loading data for good gesture on the YZ plane ... √\n",
            "loading data for goodbye gesture on the YZ plane ... √\n",
            "loading data for hello gesture on the YZ plane ... √\n",
            "loading data for hungry gesture on the YZ plane ... √\n",
            "loading data for me gesture on the YZ plane ... √\n",
            "loading data for no gesture on the YZ plane ... √\n",
            "loading data for please gesture on the YZ plane ... √\n",
            "loading data for sorry gesture on the YZ plane ... √\n",
            "loading data for thankyou gesture on the YZ plane ... √\n",
            "loading data for yes gesture on the YZ plane ... √\n",
            "loading data for you gesture on the YZ plane ... √\n",
            "Epoch 1/15\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 2.3301 - accuracy: 0.2529 - val_loss: 2.6794 - val_accuracy: 0.3063\n",
            "Epoch 2/15\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 1.5246 - accuracy: 0.5117 - val_loss: 2.5531 - val_accuracy: 0.3063\n",
            "Epoch 3/15\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 1.2293 - accuracy: 0.5961 - val_loss: 2.3970 - val_accuracy: 0.3938\n",
            "Epoch 4/15\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 1.0843 - accuracy: 0.6396 - val_loss: 2.5584 - val_accuracy: 0.3125\n",
            "Epoch 5/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.9469 - accuracy: 0.6935 - val_loss: 2.8442 - val_accuracy: 0.3250\n",
            "Epoch 6/15\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.8768 - accuracy: 0.7003 - val_loss: 2.6941 - val_accuracy: 0.3688\n",
            "Epoch 7/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.7928 - accuracy: 0.7263 - val_loss: 2.6118 - val_accuracy: 0.2875\n",
            "Epoch 8/15\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.7302 - accuracy: 0.7370 - val_loss: 2.7122 - val_accuracy: 0.3438\n",
            "Epoch 9/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.6774 - accuracy: 0.7589 - val_loss: 2.8900 - val_accuracy: 0.3500\n",
            "Epoch 10/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.7695 - val_loss: 2.8804 - val_accuracy: 0.3313\n",
            "Epoch 11/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.7875 - val_loss: 2.9884 - val_accuracy: 0.3688\n",
            "Epoch 12/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7992 - val_loss: 2.7990 - val_accuracy: 0.3375\n",
            "Epoch 13/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.8042 - val_loss: 2.7716 - val_accuracy: 0.3875\n",
            "Epoch 14/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.8125 - val_loss: 3.1204 - val_accuracy: 0.3750\n",
            "Epoch 15/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.8276 - val_loss: 3.3184 - val_accuracy: 0.3500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChN1NG9_ezSf",
        "outputId": "5a409057-5a70-454d-89bf-695e5c6761fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred_yz = model_yz.predict(X_test_yz)\n",
        "y_pred = np.argmax(y_pred_yz, axis=1)\n",
        "print(classification_report(y_test_yz.ravel(), y_pred, zero_division=0))\n",
        "prc_yz = precision_score(y_test_yz.ravel(), y_pred, zero_division=0, average=None)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "del X_train_yz, X_test_yz, y_train_yz, y_test_yz"
      ],
      "id": "ChN1NG9_ezSf",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.55      0.60      0.57        10\n",
            "         1.0       0.56      1.00      0.71        10\n",
            "         2.0       0.00      0.00      0.00        10\n",
            "         3.0       0.00      0.00      0.00        10\n",
            "         4.0       0.00      0.00      0.00        10\n",
            "         5.0       1.00      0.10      0.18        10\n",
            "         6.0       0.15      0.20      0.17        10\n",
            "         7.0       0.43      0.30      0.35        10\n",
            "         8.0       0.00      0.00      0.00        10\n",
            "         9.0       0.32      0.90      0.47        10\n",
            "        10.0       0.00      0.00      0.00        10\n",
            "        11.0       0.00      0.00      0.00        10\n",
            "        12.0       0.06      0.10      0.08        10\n",
            "        13.0       0.71      1.00      0.83        10\n",
            "        14.0       0.77      1.00      0.87        10\n",
            "        15.0       0.15      0.40      0.22        10\n",
            "\n",
            "    accuracy                           0.35       160\n",
            "   macro avg       0.29      0.35      0.28       160\n",
            "weighted avg       0.29      0.35      0.28       160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P3xqIHXe2Pi",
        "outputId": "eb8eea1c-efad-42e1-f5d9-53ab0872a45b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_zx = get_model()\n",
        "X_train_zx, X_test_zx, y_train_zx, y_test_zx = load_data('ZX')\n",
        "X_train_zx, y_train_zx = shuffle(X_train_zx, y_train_zx)\n",
        "history_zx = model_zx.fit(X_train_zx, y_train_zx, validation_data=(X_test_zx, y_test_zx), epochs=EPOCHS)"
      ],
      "id": "6P3xqIHXe2Pi",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rescaling (Rescaling)        (None, 48, 48, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 46, 46, 8)         224       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 23, 23, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 23, 23, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 21, 21, 16)        1168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 32)          4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                2064      \n",
            "=================================================================\n",
            "Total params: 73,760\n",
            "Trainable params: 73,760\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "loading data for j gesture on the ZX plane ... √\n",
            "loading data for z gesture on the ZX plane ... √\n",
            "loading data for bad gesture on the ZX plane ... √\n",
            "loading data for deaf gesture on the ZX plane ... √\n",
            "loading data for fine gesture on the ZX plane ... √\n",
            "loading data for good gesture on the ZX plane ... √\n",
            "loading data for goodbye gesture on the ZX plane ... √\n",
            "loading data for hello gesture on the ZX plane ... √\n",
            "loading data for hungry gesture on the ZX plane ... √\n",
            "loading data for me gesture on the ZX plane ... √\n",
            "loading data for no gesture on the ZX plane ... √\n",
            "loading data for please gesture on the ZX plane ... √\n",
            "loading data for sorry gesture on the ZX plane ... √\n",
            "loading data for thankyou gesture on the ZX plane ... √\n",
            "loading data for yes gesture on the ZX plane ... √\n",
            "loading data for you gesture on the ZX plane ... √\n",
            "Epoch 1/15\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 2.0870 - accuracy: 0.3469 - val_loss: 3.0062 - val_accuracy: 0.1813\n",
            "Epoch 2/15\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 1.4443 - accuracy: 0.5378 - val_loss: 3.6615 - val_accuracy: 0.2125\n",
            "Epoch 3/15\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 1.2043 - accuracy: 0.6026 - val_loss: 3.4533 - val_accuracy: 0.1875\n",
            "Epoch 4/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 1.0676 - accuracy: 0.6417 - val_loss: 4.1155 - val_accuracy: 0.2188\n",
            "Epoch 5/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.9730 - accuracy: 0.6607 - val_loss: 3.6464 - val_accuracy: 0.2062\n",
            "Epoch 6/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.8817 - accuracy: 0.6984 - val_loss: 3.7622 - val_accuracy: 0.2375\n",
            "Epoch 7/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.8251 - accuracy: 0.7125 - val_loss: 4.0702 - val_accuracy: 0.2125\n",
            "Epoch 8/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.7778 - accuracy: 0.7237 - val_loss: 4.2336 - val_accuracy: 0.2313\n",
            "Epoch 9/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.7220 - accuracy: 0.7427 - val_loss: 4.2151 - val_accuracy: 0.2500\n",
            "Epoch 10/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.7008 - accuracy: 0.7497 - val_loss: 4.5138 - val_accuracy: 0.2750\n",
            "Epoch 11/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.6512 - accuracy: 0.7648 - val_loss: 5.0635 - val_accuracy: 0.2500\n",
            "Epoch 12/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.7737 - val_loss: 4.7820 - val_accuracy: 0.2250\n",
            "Epoch 13/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.7865 - val_loss: 5.3376 - val_accuracy: 0.2812\n",
            "Epoch 14/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.8039 - val_loss: 5.7336 - val_accuracy: 0.2375\n",
            "Epoch 15/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.8107 - val_loss: 5.9684 - val_accuracy: 0.2188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufP2NBNBe67G",
        "outputId": "015aee2b-4a67-48b2-cadd-546ffb6ddf3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred_zx = model_zx.predict(X_test_zx)\n",
        "y_pred = np.argmax(y_pred_zx, axis=1)\n",
        "print(classification_report(y_test_zx.ravel(), y_pred, zero_division=0))\n",
        "prc_zx = precision_score(y_test_zx.ravel(), y_pred, zero_division=0, average=None)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "del X_train_zx, X_test_zx, y_train_zx"
      ],
      "id": "ufP2NBNBe67G",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        10\n",
            "         1.0       1.00      1.00      1.00        10\n",
            "         2.0       1.00      0.10      0.18        10\n",
            "         3.0       0.00      0.00      0.00        10\n",
            "         4.0       0.00      0.00      0.00        10\n",
            "         5.0       0.50      0.20      0.29        10\n",
            "         6.0       0.60      0.30      0.40        10\n",
            "         7.0       0.25      0.10      0.14        10\n",
            "         8.0       0.00      0.00      0.00        10\n",
            "         9.0       0.02      0.10      0.03        10\n",
            "        10.0       0.00      0.00      0.00        10\n",
            "        11.0       0.00      0.00      0.00        10\n",
            "        12.0       0.00      0.00      0.00        10\n",
            "        13.0       0.00      0.00      0.00        10\n",
            "        14.0       0.48      1.00      0.65        10\n",
            "        15.0       0.37      0.70      0.48        10\n",
            "\n",
            "    accuracy                           0.22       160\n",
            "   macro avg       0.26      0.22      0.20       160\n",
            "weighted avg       0.26      0.22      0.20       160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O62qCoa5e7pF",
        "outputId": "9d350c7f-3e6c-459d-91ee-9b88acbe0738",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_vh = get_model()\n",
        "X_train_vh, X_test_vh, y_train_vh, y_test_vh = load_data('VH')\n",
        "X_train_vh, y_train_vh = shuffle(X_train_vh, y_train_vh)\n",
        "history_vh = model_vh.fit(X_train_vh, y_train_vh, validation_data=(X_test_vh, y_test_vh), epochs=EPOCHS)"
      ],
      "id": "O62qCoa5e7pF",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rescaling (Rescaling)        (None, 48, 48, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 46, 46, 8)         224       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 23, 23, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 23, 23, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 21, 21, 16)        1168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 32)          4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                2064      \n",
            "=================================================================\n",
            "Total params: 73,760\n",
            "Trainable params: 73,760\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "loading data for j gesture on the VH plane ... √\n",
            "loading data for z gesture on the VH plane ... √\n",
            "loading data for bad gesture on the VH plane ... √\n",
            "loading data for deaf gesture on the VH plane ... √\n",
            "loading data for fine gesture on the VH plane ... √\n",
            "loading data for good gesture on the VH plane ... √\n",
            "loading data for goodbye gesture on the VH plane ... √\n",
            "loading data for hello gesture on the VH plane ... √\n",
            "loading data for hungry gesture on the VH plane ... √\n",
            "loading data for me gesture on the VH plane ... √\n",
            "loading data for no gesture on the VH plane ... √\n",
            "loading data for please gesture on the VH plane ... √\n",
            "loading data for sorry gesture on the VH plane ... √\n",
            "loading data for thankyou gesture on the VH plane ... √\n",
            "loading data for yes gesture on the VH plane ... √\n",
            "loading data for you gesture on the VH plane ... √\n",
            "Epoch 1/15\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 2.0673 - accuracy: 0.3206 - val_loss: 2.7725 - val_accuracy: 0.2625\n",
            "Epoch 2/15\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 1.1555 - accuracy: 0.5810 - val_loss: 2.7960 - val_accuracy: 0.2625\n",
            "Epoch 3/15\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.9236 - accuracy: 0.6646 - val_loss: 3.3150 - val_accuracy: 0.3438\n",
            "Epoch 4/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.7751 - accuracy: 0.7318 - val_loss: 3.0760 - val_accuracy: 0.3438\n",
            "Epoch 5/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.7581 - val_loss: 2.9725 - val_accuracy: 0.3812\n",
            "Epoch 6/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.6009 - accuracy: 0.7794 - val_loss: 2.9832 - val_accuracy: 0.3750\n",
            "Epoch 7/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.7969 - val_loss: 2.6246 - val_accuracy: 0.4062\n",
            "Epoch 8/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.8182 - val_loss: 3.3415 - val_accuracy: 0.4500\n",
            "Epoch 9/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.8268 - val_loss: 2.9960 - val_accuracy: 0.4062\n",
            "Epoch 10/15\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.4199 - accuracy: 0.8378 - val_loss: 3.1781 - val_accuracy: 0.4437\n",
            "Epoch 11/15\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.4015 - accuracy: 0.8435 - val_loss: 3.4473 - val_accuracy: 0.4187\n",
            "Epoch 12/15\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3545 - accuracy: 0.8604 - val_loss: 4.1470 - val_accuracy: 0.4187\n",
            "Epoch 13/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.3512 - accuracy: 0.8594 - val_loss: 3.2311 - val_accuracy: 0.4313\n",
            "Epoch 14/15\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3245 - accuracy: 0.8716 - val_loss: 3.8949 - val_accuracy: 0.4062\n",
            "Epoch 15/15\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.2962 - accuracy: 0.8789 - val_loss: 4.9134 - val_accuracy: 0.4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEHVZa9JfBco",
        "outputId": "eaa411fe-5eec-49b3-8ece-7c6e65c436b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred_vh = model_vh.predict(X_test_vh)\n",
        "y_pred = np.argmax(y_pred_vh, axis=1)\n",
        "print(classification_report(y_test_vh.ravel(), y_pred, zero_division=0))\n",
        "prc_vh = precision_score(y_test_vh.ravel(), y_pred, zero_division=0, average=None)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "del X_train_vh, X_test_vh, y_train_vh"
      ],
      "id": "GEHVZa9JfBco",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00        10\n",
            "         1.0       1.00      1.00      1.00        10\n",
            "         2.0       0.57      0.80      0.67        10\n",
            "         3.0       0.00      0.00      0.00        10\n",
            "         4.0       0.00      0.00      0.00        10\n",
            "         5.0       0.45      0.50      0.48        10\n",
            "         6.0       1.00      0.20      0.33        10\n",
            "         7.0       0.56      0.50      0.53        10\n",
            "         8.0       0.00      0.00      0.00        10\n",
            "         9.0       0.53      1.00      0.69        10\n",
            "        10.0       0.00      0.00      0.00        10\n",
            "        11.0       0.00      0.00      0.00        10\n",
            "        12.0       0.33      0.10      0.15        10\n",
            "        13.0       0.75      0.30      0.43        10\n",
            "        14.0       0.00      0.00      0.00        10\n",
            "        15.0       0.16      1.00      0.28        10\n",
            "\n",
            "    accuracy                           0.40       160\n",
            "   macro avg       0.40      0.40      0.35       160\n",
            "weighted avg       0.40      0.40      0.35       160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gP_MCDsfE6n",
        "outputId": "82fe7414-21fd-4126-8e49-cdbd1661a821",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_total = y_pred_xy + y_pred_yz + y_pred_zx + y_pred_vh\n",
        "y_pred = np.argmax(y_total, axis=1)\n",
        "report = classification_report(y_test_zx.ravel(), y_pred, zero_division=0)\n",
        "print(report)"
      ],
      "id": "8gP_MCDsfE6n",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00        10\n",
            "         1.0       1.00      1.00      1.00        10\n",
            "         2.0       0.00      0.00      0.00        10\n",
            "         3.0       0.00      0.00      0.00        10\n",
            "         4.0       0.00      0.00      0.00        10\n",
            "         5.0       0.14      0.10      0.12        10\n",
            "         6.0       1.00      0.90      0.95        10\n",
            "         7.0       0.80      0.40      0.53        10\n",
            "         8.0       0.00      0.00      0.00        10\n",
            "         9.0       0.31      1.00      0.48        10\n",
            "        10.0       0.00      0.00      0.00        10\n",
            "        11.0       0.00      0.00      0.00        10\n",
            "        12.0       0.00      0.00      0.00        10\n",
            "        13.0       1.00      0.40      0.57        10\n",
            "        14.0       1.00      1.00      1.00        10\n",
            "        15.0       0.14      1.00      0.24        10\n",
            "\n",
            "    accuracy                           0.42       160\n",
            "   macro avg       0.40      0.42      0.37       160\n",
            "weighted avg       0.40      0.42      0.37       160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8XYOxiHkm6s"
      },
      "source": [
        ""
      ],
      "id": "G8XYOxiHkm6s",
      "execution_count": 18,
      "outputs": []
    }
  ]
}