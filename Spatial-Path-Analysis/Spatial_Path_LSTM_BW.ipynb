{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Spatial_Path_LSTM_BW.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tamil-chrome",
        "outputId": "44c787e6-d6d4-4c23-cc74-81457d57b964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import joblib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, LSTM, Dense, Dropout, MaxPool2D, Flatten\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score\n",
        "\n",
        "tf.__version__"
      ],
      "id": "tamil-chrome",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hss8UyF2dfSV",
        "outputId": "8a4e3ec1-6bb5-4020-ecf4-8ded1f9c1beb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "Hss8UyF2dfSV",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "casual-stack"
      },
      "source": [
        "# -------- TEST USER ----------- #\n",
        "\n",
        "TEST_USER      = '001'\n",
        "\n",
        "# BASE_DIR       = '../'\n",
        "BASE_DIR       = '/content/drive/MyDrive/Research/Hand Gesture/GitHub/'\n",
        "IMG_DIR        = 'BW-Spatial-Path-Images/'\n",
        "LOG_DIR        = 'Logs/'\n",
        "\n",
        "USERS          = ['001', '002', '003', '004', '005', '006', '007']\n",
        "\n",
        "# ------------------------------- Only Dynalic Gestures ------------------------------ #\n",
        "GESTURES       = ['j', 'z', 'bad', 'deaf', 'fine', 'good', 'goodbye', 'hello', 'hungry',\n",
        "                  'me', 'no', 'please', 'sorry', 'thankyou', 'yes', 'you']\n",
        "\n",
        "PLANES         = ['XY', 'YZ', 'ZX']\n",
        "\n",
        "BATCH_SIZE     = 32\n",
        "IMG_LEN        = 40\n",
        "IMG_SIZE       = (IMG_LEN, IMG_LEN)\n",
        "\n",
        "# ------------- FOR THE GREATER GOOD :) ------------- #\n",
        "DATASET_LEN    = 1120\n",
        "TRAIN_LEN      = 960\n",
        "TEST_LEN       = 160\n",
        "\n",
        "EPOCHS         = 7\n",
        "LEARNING_RATE  = 0.0001\n",
        "DECAY          = 0.0\n",
        "\n",
        "CONFIG         = '_L_7_S_40x40_E_7'\n",
        "\n",
        "XY_WEIGHTS     = np.array([0.91, 0.75, 0.61, 0.63, 0.51, 0.66, 0.81, 0.65, 0.65, 0.31,\n",
        "                           0.66, 0.29, 0.34, 0.64, 0.64, 0.31])\n",
        "YZ_WEIGHTS     = np.array([0.73, 0.71, 0.70, 0.79, 0.76, 0.38, 0.80, 0.61, 0.58, 0.73,\n",
        "                           0.49, 0.26, 0.26, 0.52, 0.59, 0.54])\n",
        "ZX_WEIGHTS     = np.array([0.33, 0.66, 0.51, 0.54, 0.37, 0.51, 0.71, 0.30, 0.75, 0.41,\n",
        "                           0.40, 0.27, 0.24, 0.61, 0.36, 0.49])"
      ],
      "id": "casual-stack",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stylish-banner"
      },
      "source": [
        "def load_data(plane):\n",
        "    X_train = np.zeros((TRAIN_LEN, IMG_LEN, IMG_LEN, 1))\n",
        "    X_test = np.zeros((TEST_LEN, IMG_LEN, IMG_LEN, 1))\n",
        "    y_train = np.zeros((TRAIN_LEN, 1))\n",
        "    y_test = np.zeros((TEST_LEN, 1))\n",
        "    \n",
        "    train_count = 0\n",
        "    test_count = 0\n",
        "        \n",
        "    for gesture in GESTURES:\n",
        "        print('loading data for ' + gesture + ' gesture on the ' + plane + ' plane ... ', end='')\n",
        "        path = os.path.join(BASE_DIR, IMG_DIR, plane, gesture)\n",
        "        for filename in os.listdir(path):\n",
        "            img = cv2.imread(os.path.join(path, filename), cv2.IMREAD_GRAYSCALE)\n",
        "            resized = cv2.resize(img, IMG_SIZE)\n",
        "            if filename[1:4] != TEST_USER:\n",
        "                X_train[train_count, :] = np.expand_dims(resized, axis=-1)\n",
        "                y_train[train_count, 0] = GESTURES.index(gesture)\n",
        "                train_count = train_count + 1\n",
        "            else:\n",
        "                X_test[test_count, :] = np.expand_dims(resized, axis=-1)\n",
        "                y_test[test_count, 0] = GESTURES.index(gesture)\n",
        "                test_count = test_count + 1\n",
        "                \n",
        "        print('√')\n",
        "        \n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "def load_and_save_data(plane):\n",
        "    X = np.zeros((DATASET_LEN, IMG_LEN, IMG_LEN, 1))\n",
        "    y = np.zeros((DATASET_LEN, 1))\n",
        "    \n",
        "    count = 0\n",
        "        \n",
        "    for gesture in GESTURES:\n",
        "        print('loading data for ' + gesture + ' gesture on the ' + plane + ' plane ... ', end='')\n",
        "        path = os.path.join(BASE_DIR, IMG_DIR, plane, gesture)\n",
        "        for filename in os.listdir(path):\n",
        "            img = cv2.imread(os.path.join(path, filename), cv2.IMREAD_GRAYSCALE)\n",
        "            resized = cv2.resize(img, IMG_SIZE)\n",
        "            X[count, :] = np.expand_dims(resized, axis=-1)\n",
        "            y[count, 0] = GESTURES.index(gesture)\n",
        "            count = count + 1\n",
        "                \n",
        "        print('√')\n",
        "\n",
        "    joblib.dump(X, BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    joblib.dump(y, BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "\n",
        "def load_data_from_joblib(plane):\n",
        "    print('Loading data for ' + plane + ' plane ... ', end='')\n",
        "    X = joblib.load(BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    y = joblib.load(BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    test_user = int(TEST_USER)\n",
        "    X_test = X[((test_user - 1) * TEST_LEN) : (test_user * TEST_LEN), :, :, :]\n",
        "    y_test = y[((test_user - 1) * TEST_LEN) : (test_user * TEST_LEN), :]\n",
        "    X_train = np.delete(X, np.arange((test_user - 1) * TEST_LEN, test_user * TEST_LEN), axis=0)\n",
        "    y_train = np.delete(y, np.arange((test_user - 1) * TEST_LEN, test_user * TEST_LEN), axis=0)\n",
        "\n",
        "    print('√')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "id": "stylish-banner",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40HJPZ21GLiN"
      },
      "source": [
        "# LOAD AND SAVE DATA\n",
        "# load_and_save_data('XY')\n",
        "# load_and_save_data('YZ')\n",
        "# load_and_save_data('ZX')"
      ],
      "id": "40HJPZ21GLiN",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "extra-disclosure"
      },
      "source": [
        "# X_train_xy, X_test_xy, y_train_xy, y_test_xy = load_data('XY')\n",
        "# X_train_yz, X_test_yz, y_train_yz, y_test_yz = load_data('YZ')\n",
        "# X_train_zx, X_test_zx, y_train_zx, y_test_zx = load_data('ZX')"
      ],
      "id": "extra-disclosure",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEubcZCvI9wF",
        "outputId": "34a6dc82-7145-40d2-d140-5a7681baa72f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train_xy, X_test_xy, y_train_xy, y_test_xy = load_data_from_joblib('XY')\n",
        "X_train_yz, X_test_yz, y_train_yz, y_test_yz = load_data_from_joblib('YZ')\n",
        "X_train_zx, X_test_zx, y_train_zx, y_test_zx = load_data_from_joblib('ZX')"
      ],
      "id": "AEubcZCvI9wF",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data for XY plane ... √\n",
            "Loading data for YZ plane ... √\n",
            "Loading data for ZX plane ... √\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "conditional-advisory"
      },
      "source": [
        "IMG_SHAPE = IMG_SIZE + (1,)\n",
        "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./255.0, offset= 0, input_shape=IMG_SHAPE)"
      ],
      "id": "conditional-advisory",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upper-tobago"
      },
      "source": [
        "def get_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(rescale)\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(16))\n",
        "    \n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE, decay=DECAY),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "id": "upper-tobago",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "distinct-appendix",
        "outputId": "6a683bea-afda-4a23-ccf3-246780d75841",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_xy = get_model()\n",
        "X_train_xy, y_train_xy = shuffle(X_train_xy, y_train_xy)\n",
        "history_xy = model_xy.fit(X_train_xy, y_train_xy, validation_data=(X_test_xy, y_test_xy), epochs=EPOCHS)"
      ],
      "id": "distinct-appendix",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 2.7496 - accuracy: 0.0708 - val_loss: 3.3731 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/7\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 2.6811 - accuracy: 0.1125 - val_loss: 3.5658 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/7\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 2.6561 - accuracy: 0.0957 - val_loss: 3.5281 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/7\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 2.6113 - accuracy: 0.1477 - val_loss: 3.5042 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/7\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 2.4848 - accuracy: 0.1881 - val_loss: 3.8530 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/7\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 2.3406 - accuracy: 0.2269 - val_loss: 3.8742 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/7\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 2.1990 - accuracy: 0.2701 - val_loss: 4.2837 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "constitutional-genre"
      },
      "source": [
        "# prob_xy = tf.keras.Sequential([model_xy, tf.keras.layers.Softmax()])\n",
        "# y_pred_xy = prob_xy.predict(X_test_xy)\n",
        "y_pred_xy = model_xy.predict(X_test_xy)\n",
        "y_pred = np.argmax(y_pred_xy, axis=1)\n",
        "print(classification_report(y_test_xy.ravel(), y_pred, zero_division=0))\n",
        "prc_xy = precision_score(y_test_xy.ravel(), y_pred, zero_division=0, average=None)\n",
        "keras.backend.clear_session()"
      ],
      "id": "constitutional-genre",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emotional-chrome"
      },
      "source": [
        "model_yz = get_model()\n",
        "X_train_yz, y_train_yz = shuffle(X_train_yz, y_train_yz)\n",
        "history_yz = model_yz.fit(X_train_yz, y_train_yz, validation_data=(X_test_yz, y_test_yz), epochs=EPOCHS)"
      ],
      "id": "emotional-chrome",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boring-insurance"
      },
      "source": [
        "# prob_yz = tf.keras.Sequential([model_yz, tf.keras.layers.Softmax()])\n",
        "# y_pred_yz = prob_yz.predict(X_test_yz)\n",
        "y_pred_yz = model_yz.predict(X_test_yz)\n",
        "y_pred = np.argmax(y_pred_yz, axis=1)\n",
        "print(classification_report(y_test_yz.ravel(), y_pred, zero_division=0))\n",
        "prc_yz = precision_score(y_test_yz.ravel(), y_pred, zero_division=0, average=None)\n",
        "tf.keras.backend.clear_session()"
      ],
      "id": "boring-insurance",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joint-evaluation"
      },
      "source": [
        "model_zx = get_model()\n",
        "X_train_zx, y_train_zx = shuffle(X_train_zx, y_train_zx)\n",
        "history_zx = model_zx.fit(X_train_zx, y_train_zx, validation_data=(X_test_zx, y_test_zx), epochs=EPOCHS)"
      ],
      "id": "joint-evaluation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "designed-still"
      },
      "source": [
        "# prob_zx = tf.keras.Sequential([model_zx, tf.keras.layers.Softmax()])\n",
        "# y_pred_zx = prob_zx.predict(X_test_zx)\n",
        "y_pred_zx = model_zx.predict(X_test_zx)\n",
        "y_pred = np.argmax(y_pred_zx, axis=1)\n",
        "print(classification_report(y_test_zx.ravel(), y_pred, zero_division=0))\n",
        "prc_zx = precision_score(y_test_zx.ravel(), y_pred, zero_division=0, average=None)\n",
        "tf.keras.backend.clear_session()"
      ],
      "id": "designed-still",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "selective-geography"
      },
      "source": [
        "y_total = y_pred_xy + y_pred_yz + y_pred_zx\n",
        "y_pred = np.argmax(y_total, axis=1)\n",
        "report = classification_report(y_test_xy.ravel(), y_pred, zero_division=0)\n",
        "print(report)"
      ],
      "id": "selective-geography",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "collected-palmer"
      },
      "source": [
        "config = '\\n\\nTEST_USER ' + TEST_USER + ' T: ' + str(int(time.time())) + '\\n'\n",
        "underline = '=====================================\\n'\n",
        "log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
        "if not os.path.exists(log_dir):\n",
        "    os.mkdir(log_dir)\n",
        "f = open(os.path.join(log_dir, 'logs_splstm_bw' + CONFIG + '.txt'), 'a')\n",
        "f.write(config)\n",
        "f.write(underline)\n",
        "f.write(report)\n",
        "f.close()"
      ],
      "id": "collected-palmer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "intellectual-lunch"
      },
      "source": [
        "# config = TEST_USER + ' :'\n",
        "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
        "# if not os.path.exists(log_dir):\n",
        "#     os.mkdir(log_dir)\n",
        "# f = open(os.path.join(log_dir, 'prc_sptl_bw_xy' + CONFIG + '.txt'), 'a')\n",
        "# f.write(config)\n",
        "# f.write(np.array2string(prc_xy, precision=2, max_line_width=100) + '\\n')\n",
        "# f.close()"
      ],
      "id": "intellectual-lunch",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trying-thread"
      },
      "source": [
        "# config = TEST_USER + ' :'\n",
        "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
        "# if not os.path.exists(log_dir):\n",
        "#     os.mkdir(log_dir)\n",
        "# f = open(os.path.join(log_dir, 'prc_sptl_bw_yz' + CONFIG + '.txt'), 'a')\n",
        "# f.write(config)\n",
        "# f.write(np.array2string(prc_yz, precision=2, max_line_width=100) + '\\n')\n",
        "# f.close()"
      ],
      "id": "trying-thread",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "general-plant"
      },
      "source": [
        "# config = TEST_USER + ' :'\n",
        "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
        "# if not os.path.exists(log_dir):\n",
        "#     os.mkdir(log_dir)\n",
        "# f = open(os.path.join(log_dir, 'prc_sptl_bw_zx' + CONFIG + '.txt'), 'a')\n",
        "# f.write(config)\n",
        "# f.write(np.array2string(prc_zx, precision=2, max_line_width=100) + '\\n')\n",
        "# f.close()"
      ],
      "id": "general-plant",
      "execution_count": null,
      "outputs": []
    }
  ]
}