{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "returning-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "associate-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ID   = '1p0CSRb9gax0sKqdyzOYVt-BXvZ4GtrBv'\n",
    "\n",
    "# -------------BASE DIR (MODIFY THIS TO YOUR NEED) ------------ #\n",
    "BASE_DIR     = '../Dataset/'\n",
    "\n",
    "DATA_DIR     = 'Sensor-Data/'\n",
    "BW_IMG_DIR   = 'BW-Spatial-Path-Images/'\n",
    "RGB_IMG_DIR  = 'RGB-Spatial-Path-Images/'\n",
    "IMG_SIZE     = (3, 3) # INCHES\n",
    "\n",
    "USERS        = ['001', '002', '003', '004', '005', '006', '007', '008', '009',\n",
    "                '010', '011', '012', '013', '014', '015', '016', '017', '018',\n",
    "                '019', '020', '021', '022', '023', '024', '025']\n",
    "# ------------------------------- Only Dynalic Gestures ------------------------------ #\n",
    "GESTURES     = ['j', 'z', 'bad', 'deaf', 'fine', 'good', 'goodbye', 'hello', 'hungry',\n",
    "                'me', 'no', 'please', 'sorry', 'thankyou', 'yes', 'you']\n",
    "\n",
    "PLANES       = ['XY', 'YZ', 'ZX']\n",
    "\n",
    "DT           = 0.01\n",
    "SHAPES       = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lesbian-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------- Download util for Google Drive ------------------- #\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "        \n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "        \n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "def download_data(fid, destination):\n",
    "    print('cleaning already existing files ... ', end='')\n",
    "    try:\n",
    "        shutil.rmtree(destination)\n",
    "        print('√')\n",
    "    except:\n",
    "        print('✕')\n",
    "        \n",
    "    print('creating data directory ... ', end='')\n",
    "    os.mkdir(destination)\n",
    "    print('√')\n",
    "    \n",
    "    print('downloading dataset from the repository ... ', end='')\n",
    "    filename = os.path.join(destination, 'dataset.tar.xz')\n",
    "    try:\n",
    "        download_file_from_google_drive(fid, filename)\n",
    "        print('√')\n",
    "    except:\n",
    "        print('✕')\n",
    "        \n",
    "    print('extracting the dataset ... ', end='')\n",
    "    try:\n",
    "        tar = tarfile.open(filename)\n",
    "        tar.extractall(destination)\n",
    "        tar.close()\n",
    "        print('√')\n",
    "    except:\n",
    "        print('✕')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "standing-posting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning already existing files ... ✕\n",
      "creating data directory ... √\n",
      "downloading dataset from the repository ... √\n",
      "extracting the dataset ... √\n"
     ]
    }
   ],
   "source": [
    "# ------- Comment This if already downloaded -------- #\n",
    "\n",
    "destination = os.path.join(BASE_DIR, DATA_DIR)\n",
    "download_data(DATASET_ID, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prostate-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- Spatial Path Image Generation ----------- #\n",
    "\n",
    "def clean_dir(path):\n",
    "    print('cleaning already existing files ... ', end='')\n",
    "    try:\n",
    "        shutil.rmtree(path)\n",
    "        print('√')\n",
    "    except:\n",
    "        print('✕')\n",
    "    \n",
    "    print('creating ' + path + ' directory ... ', end='')\n",
    "    os.mkdir(path)\n",
    "    print('√')\n",
    "    \n",
    "# ----------- Spatial Path Vector Calculation ----------- #\n",
    "\n",
    "def get_displacement(acc):\n",
    "    v = np.zeros(acc.shape)\n",
    "    d = np.zeros(acc.shape)\n",
    "    for i in range(acc.shape[0] - 1):\n",
    "        v[i + 1] = v[i] + acc[i] * DT\n",
    "        d[i + 1] = v[i] * DT + 0.5 * acc[i] * DT * DT\n",
    "        \n",
    "    return d\n",
    "\n",
    "def write_image(x, y, path):\n",
    "    fig, ax = plt.subplots(frameon=True, figsize=(3, 3))\n",
    "    ax.axis('off')\n",
    "    plt.scatter(x, y, s=SHAPES, c='black')\n",
    "    # plt.savefig(path)\n",
    "    plt.show()\n",
    "\n",
    "def generate_bw_images():\n",
    "    count = 0\n",
    "    image_dir = os.path.join(BASE_DIR, BW_IMG_DIR)\n",
    "    clean_dir(image_dir)\n",
    "    \n",
    "    for plane in PLANES:\n",
    "        print('processing spatial path images for ' + plane + ' plane ... ', end='')\n",
    "        plane_dir = os.path.join(image_dir, plane)\n",
    "        os.mkdir(plane_dir)\n",
    "        \n",
    "        for gesture in GESTURES:\n",
    "            os.mkdir(os.path.join(plane_dir, gesture))\n",
    "    \n",
    "            for user in USERS:\n",
    "                user_dir = os.path.join(BASE_DIR, DATA_DIR, user)\n",
    "                gesture_dir = os.path.join(user_dir, gesture + '.csv')\n",
    "                \n",
    "                accx = pd.read_csv(gesture_dir)['ACCx'].to_numpy()\n",
    "                accy = pd.read_csv(gesture_dir)['ACCy'].to_numpy()\n",
    "                accz = pd.read_csv(gesture_dir)['ACCz'].to_numpy()\n",
    "\n",
    "                x = get_displacement(accx).reshape(-1, 150)\n",
    "                y = get_displacement(accy).reshape(-1, 150)\n",
    "                z = get_displacement(accz).reshape(-1, 150)\n",
    "\n",
    "                for i in range(x.shape[0]):\n",
    "                    image_name = 'u' + user + '_g' + '{:0>2d}'.format(GESTURES.index(gesture)) + \\\n",
    "                                 '_s' + '{:0>7d}'.format(count) + '_p' + plane + '.jpg'\n",
    "                    path = os.path.join(BASE_DIR, BW_IMG_DIR, plane, gesture, image_name)\n",
    "                    \n",
    "                    if plane == 'XY':\n",
    "                        write_image(x[i, :], y[i, :], path)\n",
    "                    elif plane == 'YZ':\n",
    "                        write_image(y[i, :], z[i, :], path)\n",
    "                    else:\n",
    "                        write_image(z[i, :], x[i, :], path)\n",
    "\n",
    "                    count = count + 1\n",
    "            \n",
    "        print('√')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "promotional-lancaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning already existing files ... √\n",
      "creating ../BW-Spatial-Path-Images/ directory ... √\n",
      "processing spatial path images for XY plane ... √\n",
      "processing spatial path images for YZ plane ... √\n",
      "processing spatial path images for ZX plane ... √\n"
     ]
    }
   ],
   "source": [
    "generate_bw_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "flexible-palestine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning already existing files ... ✕\n",
      "creating ../Dataset/BW-Spatial-Path-Images/ directory ... √\n",
      "processing spatial path images for XY plane ... "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = 0\n",
    "image_dir = os.path.join(BASE_DIR, BW_IMG_DIR)\n",
    "clean_dir(image_dir)\n",
    "\n",
    "for plane in PLANES:\n",
    "    print('processing spatial path images for ' + plane + ' plane ... ', end='')\n",
    "    plane_dir = os.path.join(image_dir, plane)\n",
    "    os.mkdir(plane_dir)\n",
    "    \n",
    "    for gesture in GESTURES:\n",
    "        os.mkdir(os.path.join(plane_dir, gesture))\n",
    "\n",
    "        for user in USERS:\n",
    "            user_dir = os.path.join(BASE_DIR, DATA_DIR, user)\n",
    "            gesture_dir = os.path.join(user_dir, gesture + '.csv')\n",
    "            \n",
    "            accx = pd.read_csv(gesture_dir)['ACCx'].to_numpy()\n",
    "            accy = pd.read_csv(gesture_dir)['ACCy'].to_numpy()\n",
    "            accz = pd.read_csv(gesture_dir)['ACCz'].to_numpy()\n",
    "\n",
    "            x = get_displacement(accx).reshape(-1, 150)\n",
    "            y = get_displacement(accy).reshape(-1, 150)\n",
    "            z = get_displacement(accz).reshape(-1, 150)\n",
    "\n",
    "            for i in range(x.shape[0]):\n",
    "                image_name = 'u' + user + '_g' + '{:0>2d}'.format(GESTURES.index(gesture)) + \\\n",
    "                                '_s' + '{:0>7d}'.format(count) + '_p' + plane + '.jpg'\n",
    "                path = os.path.join(BASE_DIR, BW_IMG_DIR, plane, gesture, image_name)\n",
    "                \n",
    "                if plane == 'XY':\n",
    "                    write_image(x[i, :], y[i, :], path)\n",
    "                elif plane == 'YZ':\n",
    "                    write_image(y[i, :], z[i, :], path)\n",
    "                else:\n",
    "                    write_image(z[i, :], x[i, :], path)\n",
    "\n",
    "                count = count + 1\n",
    "\n",
    "                break\n",
    "            break\n",
    "        break\n",
    "    break\n",
    "        \n",
    "    print('√')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7283cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
