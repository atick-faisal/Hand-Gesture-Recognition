{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spatial_Path_TL_TF_Data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNfZuQmuQw43nDXyuINCbyU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/Hand-Gesture-Recognition/blob/main/Spatial-Path-Analysis/Spatial_Path_TL_TF_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnYaMyzfcRXP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6319ce7-883f-4603-ee87-c50a76740c16"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import joblib\n",
        "import shutil\n",
        "import tarfile\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9kuwY70EAfb"
      },
      "source": [
        "TEST_USER    = '003'\n",
        "\n",
        "DATASET_ID   = '1p0CSRb9gax0sKqdyzOYVt-BXvZ4GtrBv'\n",
        "\n",
        "# -------------BASE DIR (MODIFY THIS TO YOUR NEED) ------------ #\n",
        "BASE_DIR     = os.getcwd()\n",
        "# BASE_DIR     = '/content/drive/MyDrive/Research/Hand Gesture/GitHub/'\n",
        "\n",
        "DATA_DIR     = 'Sensor-Data/'\n",
        "BW_IMG_DIR   = 'BW-Spatial-Path-Images/'\n",
        "RGB_IMG_DIR  = 'RGB-Spatial-Path-Images/'\n",
        "IMG_SIZE     = (3, 3) # INCHES\n",
        "\n",
        "IMG_DIR      = 'BW-Spatial-Path-Images/'\n",
        "LOG_DIR      = 'Logs/'\n",
        "\n",
        "USERS        = ['001', '002', '003', '004', '005', '006', '007', '008', '009',\n",
        "                '010', '011', '012', '013', '014', '015', '016', '017', '018',\n",
        "                '019', '020', '021', '022', '023', '024', '025']\n",
        "# ------------------------------- Only Dynalic Gestures ------------------------------ #\n",
        "GESTURES     = ['j', 'z', 'bad', 'deaf', 'fine', 'good', 'goodbye', 'hello', 'hungry',\n",
        "                'me', 'no', 'please', 'sorry', 'thankyou', 'yes', 'you']\n",
        "\n",
        "PLANES       = ['XY', 'YZ', 'ZX']\n",
        "\n",
        "DT           = 0.01\n",
        "LINEWIDTH    = 7\n",
        "\n",
        "BATCH_SIZE     = 32\n",
        "IMG_LEN        = 96\n",
        "IMG_SIZE       = (IMG_LEN, IMG_LEN)\n",
        "CHANNELS       = 1\n",
        "\n",
        "# ------------- FOR THE GREATER GOOD :) ------------- #\n",
        "DATASET_LEN    = 4000\n",
        "TRAIN_LEN      = 3840\n",
        "TEST_LEN       = 160\n",
        "\n",
        "EPOCHS         = 15\n",
        "LEARNING_RATE  = 0.001\n",
        "DECAY          = 0.0\n",
        "\n",
        "CONFIG         = '_L_7_S_160x160_E_7'\n",
        "\n",
        "XY_WEIGHTS     = np.array([0.91, 0.75, 0.61, 0.63, 0.51, 0.66, 0.81, 0.65, 0.65, 0.31,\n",
        "                           0.66, 0.29, 0.34, 0.64, 0.64, 0.31])\n",
        "YZ_WEIGHTS     = np.array([0.73, 0.71, 0.70, 0.79, 0.76, 0.38, 0.80, 0.61, 0.58, 0.73,\n",
        "                           0.49, 0.26, 0.26, 0.52, 0.59, 0.54])\n",
        "ZX_WEIGHTS     = np.array([0.33, 0.66, 0.51, 0.54, 0.37, 0.51, 0.71, 0.30, 0.75, 0.41,\n",
        "                           0.40, 0.27, 0.24, 0.61, 0.36, 0.49])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79vdHTpuEOKH"
      },
      "source": [
        "#--------------------- Download util for Google Drive ------------------- #\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "        \n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "        \n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "\n",
        "def download_data(fid, destination):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(destination)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('creating data directory ... ', end='')\n",
        "    os.mkdir(destination)\n",
        "    print('√')\n",
        "    \n",
        "    print('downloading dataset from the repository ... ', end='')\n",
        "    filename = os.path.join(destination, 'dataset.tar.xz')\n",
        "    try:\n",
        "        download_file_from_google_drive(fid, filename)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('extracting the dataset ... ', end='')\n",
        "    try:\n",
        "        tar = tarfile.open(filename)\n",
        "        tar.extractall(destination)\n",
        "        tar.close()\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')   "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vJSFeMMEa_m"
      },
      "source": [
        "# ------- Comment This if already downloaded -------- #\n",
        "\n",
        "# destination = os.path.join(BASE_DIR, DATA_DIR)\n",
        "# download_data(DATASET_ID, destination)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iUDD3WCEdph"
      },
      "source": [
        "# ------------- Spatial Path Image Generation ----------- #\n",
        "\n",
        "def clean_dir(path):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(path)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "    \n",
        "    print('creating ' + path + ' directory ... ', end='')\n",
        "    os.mkdir(path)\n",
        "    print('√')\n",
        "    \n",
        "# ----------- Spatial Path Vector Calculation ----------- #\n",
        "\n",
        "def get_displacement(acc):\n",
        "    v = np.zeros(acc.shape)\n",
        "    d = np.zeros(acc.shape)\n",
        "    for i in range(acc.shape[0] - 1):\n",
        "        v[i + 1] = v[i] + acc[i] * DT\n",
        "        d[i + 1] = v[i] * DT + 0.5 * acc[i] * DT * DT\n",
        "        \n",
        "    return d\n",
        "\n",
        "def write_image(x, y, path):\n",
        "    fig, ax = plt.subplots(frameon=True, figsize=(3, 3))\n",
        "    ax.axis('off')\n",
        "    plt.plot(x, y, '-k', linewidth=LINEWIDTH)\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "def generate_bw_images():\n",
        "    count = 0\n",
        "    image_dir = os.path.join(BASE_DIR, BW_IMG_DIR)\n",
        "    clean_dir(image_dir)\n",
        "    \n",
        "    for plane in PLANES:\n",
        "        print('processing spatial path images for ' + plane + ' plane ... ', end='')\n",
        "        plane_dir = os.path.join(image_dir, plane)\n",
        "        os.mkdir(plane_dir)\n",
        "        \n",
        "        for gesture in GESTURES:\n",
        "            os.mkdir(os.path.join(plane_dir, gesture))\n",
        "    \n",
        "            for user in USERS:\n",
        "                user_dir = os.path.join(BASE_DIR, DATA_DIR, user)\n",
        "                gesture_dir = os.path.join(user_dir, gesture + '.csv')\n",
        "                \n",
        "                accx = pd.read_csv(gesture_dir)['ACCx'].to_numpy()\n",
        "                accy = pd.read_csv(gesture_dir)['ACCy'].to_numpy()\n",
        "                accz = pd.read_csv(gesture_dir)['ACCz'].to_numpy()\n",
        "\n",
        "                x = get_displacement(accx).reshape(-1, 150)\n",
        "                y = get_displacement(accy).reshape(-1, 150)\n",
        "                z = get_displacement(accz).reshape(-1, 150)\n",
        "\n",
        "                for i in range(x.shape[0]):\n",
        "                    image_name = 'u' + user + '_g' + '{:0>2d}'.format(GESTURES.index(gesture)) + \\\n",
        "                                 '_s' + '{:0>7d}'.format(count) + '_p' + plane + '.jpg'\n",
        "                    path = os.path.join(BASE_DIR, BW_IMG_DIR, plane, gesture, image_name)\n",
        "                    \n",
        "                    if plane == 'XY':\n",
        "                        write_image(x[i, :], y[i, :], path)\n",
        "                    elif plane == 'YZ':\n",
        "                        write_image(y[i, :], z[i, :], path)\n",
        "                    else:\n",
        "                        write_image(z[i, :], x[i, :], path)\n",
        "\n",
        "                    count = count + 1\n",
        "            \n",
        "        print('√')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWBEae-zEk25"
      },
      "source": [
        "# generate_bw_images()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3rTb3wLEosc"
      },
      "source": [
        "def load_data(plane):\n",
        "    X_train = np.zeros((TRAIN_LEN, IMG_LEN, IMG_LEN, CHANNELS))\n",
        "    X_test = np.zeros((TEST_LEN, IMG_LEN, IMG_LEN, CHANNELS))\n",
        "    y_train = np.zeros((TRAIN_LEN, 1))\n",
        "    y_test = np.zeros((TEST_LEN, 1))\n",
        "    \n",
        "    train_count = 0\n",
        "    test_count = 0\n",
        "        \n",
        "    for gesture in GESTURES:\n",
        "        print('loading data for ' + gesture + ' gesture on the ' + plane + ' plane ... ', end='')\n",
        "        path = os.path.join(BASE_DIR, IMG_DIR, plane, gesture)\n",
        "        for filename in os.listdir(path):\n",
        "            img = cv2.imread(\n",
        "                os.path.join(path, filename),\n",
        "                cv2.IMREAD_GRAYSCALE\n",
        "            )\n",
        "            resized = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "            if resized.ndim < 3:\n",
        "                resized = np.expand_dims(resized, axis=-1)\n",
        "                \n",
        "            if filename[1:4] != TEST_USER:\n",
        "                X_train[train_count, :] = resized\n",
        "                y_train[train_count, 0] = GESTURES.index(gesture)\n",
        "                train_count = train_count + 1\n",
        "            else:\n",
        "                X_test[test_count, :] = resized\n",
        "                y_test[test_count, 0] = GESTURES.index(gesture)\n",
        "                test_count = test_count + 1\n",
        "                \n",
        "        print('√')\n",
        "        \n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def load_and_save_data(plane):\n",
        "    X = np.zeros((DATASET_LEN, IMG_LEN, IMG_LEN, CHANNELS))\n",
        "    y = np.zeros((DATASET_LEN, 1))\n",
        "    \n",
        "    train_count = 0\n",
        "    test_count  = TRAIN_LEN\n",
        "        \n",
        "    for gesture in GESTURES:\n",
        "        print('loading data for ' + gesture + ' gesture on the ' + plane + ' plane ... ', end='')\n",
        "        path = os.path.join(BASE_DIR, IMG_DIR, plane, gesture)\n",
        "        for filename in os.listdir(path):\n",
        "            img = cv2.imread(os.path.join(path, filename))\n",
        "            resized = cv2.resize(img, IMG_SIZE)\n",
        "            if filename[1:4] != TEST_USER:\n",
        "                X[train_count, :] = resized\n",
        "                y[train_count, 0] = GESTURES.index(gesture)\n",
        "                train_count = train_count + 1\n",
        "            else:\n",
        "                X[test_count, :] = resized\n",
        "                y[test_count, 0] = GESTURES.index(gesture)\n",
        "                test_count = test_count + 1\n",
        "                \n",
        "        print('√')\n",
        "\n",
        "    joblib.dump(X, BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    joblib.dump(y, BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "\n",
        "def load_data_from_joblib(plane):\n",
        "    print('Loading data for ' + plane + ' plane ... ', end='')\n",
        "    X = joblib.load(BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    y = joblib.load(BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    test_user = int(TEST_USER)\n",
        "    X_train = X[:TRAIN_LEN, :, :, :]\n",
        "    y_train = y[:TRAIN_LEN, :]\n",
        "    X_test = X[TRAIN_LEN:, :, :, :]\n",
        "    y_test = y[TRAIN_LEN:, :]\n",
        "\n",
        "    print('√')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk1UHBMpKF8G"
      },
      "source": [
        "# preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
        "# rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
        "# data_augmentation = tf.keras.Sequential([\n",
        "#   tf.keras.layers.experimental.preprocessing.RandomRotation(0.3),\n",
        "# ])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0outzPnzKGUx"
      },
      "source": [
        "IMG_SHAPE = IMG_SIZE + (CHANNELS,)\n",
        "# base_model = tf.keras.applications.EfficientNetB3(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "# base_model.trainable = False"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TcOKiAlKH7D"
      },
      "source": [
        "# global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "# prediction_layer = tf.keras.layers.Dense(len(GESTURES))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBy1328x38KL",
        "outputId": "5d119a79-9704-4aaa-80e9-b1339a54eaf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a = np.ones((3, 3, 1))\n",
        "a.ndim"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adXEpjPSKXj9"
      },
      "source": [
        "# def get_model():\n",
        "#     inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
        "#     # x = data_augmentation(inputs)\n",
        "#     x = preprocess_input(inputs)\n",
        "#     x = base_model(x, training=False)\n",
        "#     x = global_average_layer(x)\n",
        "#     x = tf.keras.layers.Dropout(0.2)(x)\n",
        "#     outputs = prediction_layer(x)\n",
        "#     model = tf.keras.Model(inputs, outputs)\n",
        "#     model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, decay=DECAY),\n",
        "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#               metrics=['accuracy'])\n",
        "#     return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H9TD7srxTGA"
      },
      "source": [
        "def get_model():\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Input(shape=IMG_SHAPE))\n",
        "    model.add(tf.keras.layers.experimental.preprocessing.Rescaling(1./255.0, offset=0))\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.0))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.0))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPool2D(2, 2))\n",
        "    model.add(tf.keras.layers.Dropout(0.0))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.7))\n",
        "    model.add(tf.keras.layers.Dense(len(GESTURES)))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHULgmSQKZO3",
        "outputId": "f8a69b4e-499c-4361-d433-ef13d632a1d1"
      },
      "source": [
        "model_xy = get_model()\n",
        "X_train_xy, X_test_xy, y_train_xy, y_test_xy = load_data('XY')\n",
        "X_train_xy, y_train_xy = shuffle(X_train_xy, y_train_xy)\n",
        "history_xy = model_xy.fit(X_train_xy, y_train_xy, validation_data=(X_test_xy, y_test_xy), epochs=EPOCHS)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "loading data for j gesture on the XY plane ... √\n",
            "loading data for z gesture on the XY plane ... √\n",
            "loading data for bad gesture on the XY plane ... √\n",
            "loading data for deaf gesture on the XY plane ... √\n",
            "loading data for fine gesture on the XY plane ... √\n",
            "loading data for good gesture on the XY plane ... √\n",
            "loading data for goodbye gesture on the XY plane ... √\n",
            "loading data for hello gesture on the XY plane ... √\n",
            "loading data for hungry gesture on the XY plane ... √\n",
            "loading data for me gesture on the XY plane ... √\n",
            "loading data for no gesture on the XY plane ... √\n",
            "loading data for please gesture on the XY plane ... √\n",
            "loading data for sorry gesture on the XY plane ... √\n",
            "loading data for thankyou gesture on the XY plane ... √\n",
            "loading data for yes gesture on the XY plane ... √\n",
            "loading data for you gesture on the XY plane ... √\n",
            "Epoch 1/15\n",
            "120/120 [==============================] - 2s 11ms/step - loss: 2.2781 - accuracy: 0.2654 - val_loss: 1.7143 - val_accuracy: 0.5188\n",
            "Epoch 2/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 1.4936 - accuracy: 0.5018 - val_loss: 1.3095 - val_accuracy: 0.5250\n",
            "Epoch 3/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 1.1893 - accuracy: 0.5859 - val_loss: 1.2460 - val_accuracy: 0.5688\n",
            "Epoch 4/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 1.0253 - accuracy: 0.6328 - val_loss: 1.0564 - val_accuracy: 0.6875\n",
            "Epoch 5/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.8933 - accuracy: 0.6875 - val_loss: 1.0068 - val_accuracy: 0.6812\n",
            "Epoch 6/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.8096 - accuracy: 0.7039 - val_loss: 0.8892 - val_accuracy: 0.7188\n",
            "Epoch 7/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.7176 - accuracy: 0.7427 - val_loss: 0.8394 - val_accuracy: 0.6938\n",
            "Epoch 8/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.6719 - accuracy: 0.7529 - val_loss: 0.8884 - val_accuracy: 0.7188\n",
            "Epoch 9/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.6162 - accuracy: 0.7792 - val_loss: 0.8039 - val_accuracy: 0.7250\n",
            "Epoch 10/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.5447 - accuracy: 0.7987 - val_loss: 0.7925 - val_accuracy: 0.7375\n",
            "Epoch 11/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.4981 - accuracy: 0.8130 - val_loss: 0.7161 - val_accuracy: 0.8125\n",
            "Epoch 12/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.5037 - accuracy: 0.8143 - val_loss: 0.6258 - val_accuracy: 0.8313\n",
            "Epoch 13/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.4602 - accuracy: 0.8255 - val_loss: 0.6055 - val_accuracy: 0.8125\n",
            "Epoch 14/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.4193 - accuracy: 0.8398 - val_loss: 0.6239 - val_accuracy: 0.8188\n",
            "Epoch 15/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.3944 - accuracy: 0.8513 - val_loss: 0.5929 - val_accuracy: 0.8250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfLP6x-O8fum",
        "outputId": "6ccb55fb-3bc4-4be6-fecd-2c8bf877d440",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_xy.summary()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rescaling_1 (Rescaling)      (None, 96, 96, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 94, 94, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 47, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 47, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 45, 45, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 20, 20, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               1638656   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                4112      \n",
            "=================================================================\n",
            "Total params: 1,698,512\n",
            "Trainable params: 1,698,512\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV5fDKKPQEIq",
        "outputId": "18c31e25-cc11-4e99-c9c9-8320410b0777"
      },
      "source": [
        "y_pred_xy = model_xy.predict(X_test_xy)\n",
        "y_pred = np.argmax(y_pred_xy, axis=1)\n",
        "print(classification_report(y_test_xy.ravel(), y_pred, zero_division=0))\n",
        "prc_xy = precision_score(y_test_xy.ravel(), y_pred, zero_division=0, average=None)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "del X_train_xy, X_test_xy, y_train_xy, y_test_xy"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.90      0.95        10\n",
            "         1.0       1.00      0.80      0.89        10\n",
            "         2.0       0.78      0.70      0.74        10\n",
            "         3.0       0.91      1.00      0.95        10\n",
            "         4.0       0.90      0.90      0.90        10\n",
            "         5.0       0.69      0.90      0.78        10\n",
            "         6.0       0.80      0.80      0.80        10\n",
            "         7.0       0.90      0.90      0.90        10\n",
            "         8.0       0.91      1.00      0.95        10\n",
            "         9.0       0.89      0.80      0.84        10\n",
            "        10.0       1.00      0.90      0.95        10\n",
            "        11.0       0.67      0.20      0.31        10\n",
            "        12.0       0.78      0.70      0.74        10\n",
            "        13.0       0.90      0.90      0.90        10\n",
            "        14.0       0.62      1.00      0.77        10\n",
            "        15.0       0.62      0.80      0.70        10\n",
            "\n",
            "    accuracy                           0.82       160\n",
            "   macro avg       0.84      0.82      0.82       160\n",
            "weighted avg       0.84      0.82      0.82       160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCIbJnjzQEql",
        "outputId": "df8a9ad6-c4c9-4367-9fc1-e389b47aee2f"
      },
      "source": [
        "model_yz = get_model()\n",
        "X_train_yz, X_test_yz, y_train_yz, y_test_yz = load_data('YZ')\n",
        "X_train_yz, y_train_yz = shuffle(X_train_yz, y_train_yz)\n",
        "history_yz = model_yz.fit(X_train_yz, y_train_yz, validation_data=(X_test_yz, y_test_yz), epochs=EPOCHS)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "loading data for j gesture on the YZ plane ... √\n",
            "loading data for z gesture on the YZ plane ... √\n",
            "loading data for bad gesture on the YZ plane ... √\n",
            "loading data for deaf gesture on the YZ plane ... √\n",
            "loading data for fine gesture on the YZ plane ... √\n",
            "loading data for good gesture on the YZ plane ... √\n",
            "loading data for goodbye gesture on the YZ plane ... √\n",
            "loading data for hello gesture on the YZ plane ... √\n",
            "loading data for hungry gesture on the YZ plane ... √\n",
            "loading data for me gesture on the YZ plane ... √\n",
            "loading data for no gesture on the YZ plane ... √\n",
            "loading data for please gesture on the YZ plane ... √\n",
            "loading data for sorry gesture on the YZ plane ... √\n",
            "loading data for thankyou gesture on the YZ plane ... √\n",
            "loading data for yes gesture on the YZ plane ... √\n",
            "loading data for you gesture on the YZ plane ... √\n",
            "Epoch 1/15\n",
            "120/120 [==============================] - 2s 11ms/step - loss: 2.1102 - accuracy: 0.3333 - val_loss: 1.7753 - val_accuracy: 0.3688\n",
            "Epoch 2/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 1.3972 - accuracy: 0.5521 - val_loss: 1.5622 - val_accuracy: 0.4125\n",
            "Epoch 3/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 1.1431 - accuracy: 0.6234 - val_loss: 1.3804 - val_accuracy: 0.4875\n",
            "Epoch 4/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.9748 - accuracy: 0.6750 - val_loss: 1.2170 - val_accuracy: 0.4812\n",
            "Epoch 5/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.8304 - accuracy: 0.7206 - val_loss: 1.4012 - val_accuracy: 0.5437\n",
            "Epoch 6/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.7302 - accuracy: 0.7516 - val_loss: 1.2137 - val_accuracy: 0.5813\n",
            "Epoch 7/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.6354 - accuracy: 0.7745 - val_loss: 1.0777 - val_accuracy: 0.5625\n",
            "Epoch 8/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.5925 - accuracy: 0.7789 - val_loss: 1.1686 - val_accuracy: 0.5938\n",
            "Epoch 9/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.5017 - accuracy: 0.8130 - val_loss: 1.2521 - val_accuracy: 0.5813\n",
            "Epoch 10/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.4785 - accuracy: 0.8227 - val_loss: 1.1321 - val_accuracy: 0.5938\n",
            "Epoch 11/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.4415 - accuracy: 0.8359 - val_loss: 1.1169 - val_accuracy: 0.5688\n",
            "Epoch 12/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.4103 - accuracy: 0.8508 - val_loss: 1.1976 - val_accuracy: 0.6125\n",
            "Epoch 13/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.3783 - accuracy: 0.8620 - val_loss: 1.1261 - val_accuracy: 0.5938\n",
            "Epoch 14/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.3442 - accuracy: 0.8776 - val_loss: 1.2054 - val_accuracy: 0.5938\n",
            "Epoch 15/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.3238 - accuracy: 0.8870 - val_loss: 1.1930 - val_accuracy: 0.5875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEqamoFSQKwy",
        "outputId": "03bdd412-553f-49a6-dc41-ccde034ccba3"
      },
      "source": [
        "# prob_yz = tf.keras.Sequential([model_yz, tf.keras.layers.Softmax()])\n",
        "# y_pred_yz = prob_yz.predict(X_test_yz)\n",
        "y_pred_yz = model_yz.predict(X_test_yz)\n",
        "y_pred = np.argmax(y_pred_yz, axis=1)\n",
        "print(classification_report(y_test_yz.ravel(), y_pred, zero_division=0))\n",
        "prc_yz = precision_score(y_test_yz.ravel(), y_pred, zero_division=0, average=None)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "del X_train_yz, X_test_yz, y_train_yz, y_test_yz"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.53      0.90      0.67        10\n",
            "         1.0       0.90      0.90      0.90        10\n",
            "         2.0       0.75      0.30      0.43        10\n",
            "         3.0       0.53      0.80      0.64        10\n",
            "         4.0       0.77      1.00      0.87        10\n",
            "         5.0       0.67      0.40      0.50        10\n",
            "         6.0       0.33      0.20      0.25        10\n",
            "         7.0       0.83      1.00      0.91        10\n",
            "         8.0       0.14      0.10      0.12        10\n",
            "         9.0       0.82      0.90      0.86        10\n",
            "        10.0       0.42      0.80      0.55        10\n",
            "        11.0       0.25      0.10      0.14        10\n",
            "        12.0       0.58      0.70      0.64        10\n",
            "        13.0       1.00      0.90      0.95        10\n",
            "        14.0       0.00      0.00      0.00        10\n",
            "        15.0       0.50      0.40      0.44        10\n",
            "\n",
            "    accuracy                           0.59       160\n",
            "   macro avg       0.56      0.59      0.55       160\n",
            "weighted avg       0.56      0.59      0.55       160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNrCzFGIQLaR",
        "outputId": "1cb6c7f5-bda2-4617-8e2e-1197001cc5f9"
      },
      "source": [
        "model_zx = get_model()\n",
        "X_train_zx, X_test_zx, y_train_zx, y_test_zx = load_data('ZX')\n",
        "X_train_zx, y_train_zx = shuffle(X_train_zx, y_train_zx)\n",
        "history_zx = model_zx.fit(X_train_zx, y_train_zx, validation_data=(X_test_zx, y_test_zx), epochs=EPOCHS)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "loading data for j gesture on the ZX plane ... √\n",
            "loading data for z gesture on the ZX plane ... √\n",
            "loading data for bad gesture on the ZX plane ... √\n",
            "loading data for deaf gesture on the ZX plane ... √\n",
            "loading data for fine gesture on the ZX plane ... √\n",
            "loading data for good gesture on the ZX plane ... √\n",
            "loading data for goodbye gesture on the ZX plane ... √\n",
            "loading data for hello gesture on the ZX plane ... √\n",
            "loading data for hungry gesture on the ZX plane ... √\n",
            "loading data for me gesture on the ZX plane ... √\n",
            "loading data for no gesture on the ZX plane ... √\n",
            "loading data for please gesture on the ZX plane ... √\n",
            "loading data for sorry gesture on the ZX plane ... √\n",
            "loading data for thankyou gesture on the ZX plane ... √\n",
            "loading data for yes gesture on the ZX plane ... √\n",
            "loading data for you gesture on the ZX plane ... √\n",
            "Epoch 1/15\n",
            "120/120 [==============================] - 2s 12ms/step - loss: 2.0053 - accuracy: 0.3716 - val_loss: 1.9957 - val_accuracy: 0.2750\n",
            "Epoch 2/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 1.3876 - accuracy: 0.5539 - val_loss: 1.7393 - val_accuracy: 0.3562\n",
            "Epoch 3/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 1.1540 - accuracy: 0.6055 - val_loss: 1.5338 - val_accuracy: 0.4812\n",
            "Epoch 4/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.9721 - accuracy: 0.6724 - val_loss: 1.5623 - val_accuracy: 0.5188\n",
            "Epoch 5/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.8637 - accuracy: 0.7049 - val_loss: 1.4238 - val_accuracy: 0.5625\n",
            "Epoch 6/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.7912 - accuracy: 0.7247 - val_loss: 1.2569 - val_accuracy: 0.5813\n",
            "Epoch 7/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.7176 - accuracy: 0.7523 - val_loss: 1.2771 - val_accuracy: 0.6062\n",
            "Epoch 8/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.6632 - accuracy: 0.7677 - val_loss: 1.3858 - val_accuracy: 0.5875\n",
            "Epoch 9/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.6201 - accuracy: 0.7852 - val_loss: 1.2303 - val_accuracy: 0.6000\n",
            "Epoch 10/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.5620 - accuracy: 0.8078 - val_loss: 1.2861 - val_accuracy: 0.6062\n",
            "Epoch 11/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.5174 - accuracy: 0.8169 - val_loss: 1.3605 - val_accuracy: 0.6250\n",
            "Epoch 12/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.4976 - accuracy: 0.8174 - val_loss: 1.2470 - val_accuracy: 0.6313\n",
            "Epoch 13/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.4651 - accuracy: 0.8297 - val_loss: 1.2814 - val_accuracy: 0.6500\n",
            "Epoch 14/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.4253 - accuracy: 0.8443 - val_loss: 1.4368 - val_accuracy: 0.6187\n",
            "Epoch 15/15\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.3828 - accuracy: 0.8635 - val_loss: 1.6266 - val_accuracy: 0.6562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qanPbY7QNVl",
        "outputId": "88d742a3-1668-4631-caa9-35cd09f25a9b"
      },
      "source": [
        "# prob_zx = tf.keras.Sequential([model_zx, tf.keras.layers.Softmax()])\n",
        "# y_pred_zx = prob_zx.predict(X_test_zx)\n",
        "y_pred_zx = model_zx.predict(X_test_zx)\n",
        "y_pred = np.argmax(y_pred_zx, axis=1)\n",
        "print(classification_report(y_test_zx.ravel(), y_pred, zero_division=0))\n",
        "prc_zx = precision_score(y_test_zx.ravel(), y_pred, zero_division=0, average=None)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "del X_train_zx, X_test_zx, y_train_zx"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.80      0.84        10\n",
            "         1.0       0.67      0.20      0.31        10\n",
            "         2.0       0.59      1.00      0.74        10\n",
            "         3.0       0.80      0.80      0.80        10\n",
            "         4.0       0.31      0.80      0.44        10\n",
            "         5.0       1.00      1.00      1.00        10\n",
            "         6.0       0.90      0.90      0.90        10\n",
            "         7.0       0.27      0.30      0.29        10\n",
            "         8.0       1.00      0.90      0.95        10\n",
            "         9.0       0.60      0.60      0.60        10\n",
            "        10.0       0.71      0.50      0.59        10\n",
            "        11.0       0.67      0.40      0.50        10\n",
            "        12.0       0.00      0.00      0.00        10\n",
            "        13.0       1.00      0.90      0.95        10\n",
            "        14.0       0.57      0.80      0.67        10\n",
            "        15.0       0.75      0.60      0.67        10\n",
            "\n",
            "    accuracy                           0.66       160\n",
            "   macro avg       0.67      0.66      0.64       160\n",
            "weighted avg       0.67      0.66      0.64       160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7_SrZBlQQZg",
        "outputId": "e761c7b5-1e57-43ca-d792-3ef77fd455a5"
      },
      "source": [
        "y_total = y_pred_xy + y_pred_yz + y_pred_zx\n",
        "y_pred = np.argmax(y_total, axis=1)\n",
        "report = classification_report(y_test_zx.ravel(), y_pred, zero_division=0)\n",
        "print(report)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00        10\n",
            "         1.0       1.00      1.00      1.00        10\n",
            "         2.0       1.00      1.00      1.00        10\n",
            "         3.0       1.00      1.00      1.00        10\n",
            "         4.0       1.00      1.00      1.00        10\n",
            "         5.0       0.91      1.00      0.95        10\n",
            "         6.0       1.00      1.00      1.00        10\n",
            "         7.0       1.00      1.00      1.00        10\n",
            "         8.0       1.00      1.00      1.00        10\n",
            "         9.0       0.91      1.00      0.95        10\n",
            "        10.0       0.91      1.00      0.95        10\n",
            "        11.0       0.64      0.70      0.67        10\n",
            "        12.0       0.86      0.60      0.71        10\n",
            "        13.0       1.00      1.00      1.00        10\n",
            "        14.0       0.91      1.00      0.95        10\n",
            "        15.0       1.00      0.80      0.89        10\n",
            "\n",
            "    accuracy                           0.94       160\n",
            "   macro avg       0.95      0.94      0.94       160\n",
            "weighted avg       0.95      0.94      0.94       160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtC2WFNk7hVF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}