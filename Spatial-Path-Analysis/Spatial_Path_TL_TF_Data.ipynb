{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spatial_Path_TL_TF_Data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOk7A/d1EPFR7fv6j0KJBSP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/Hand-Gesture-Recognition/blob/main/Spatial-Path-Analysis/Spatial_Path_TL_TF_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnYaMyzfcRXP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0ab2bc2e-7de4-4651-e7bf-3000c7f7103f"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import joblib\n",
        "import shutil\n",
        "import tarfile\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9kuwY70EAfb"
      },
      "source": [
        "TEST_USER    = '003'\n",
        "\n",
        "DATASET_ID   = '1p0CSRb9gax0sKqdyzOYVt-BXvZ4GtrBv'\n",
        "\n",
        "# -------------BASE DIR (MODIFY THIS TO YOUR NEED) ------------ #\n",
        "BASE_DIR     = os.getcwd()\n",
        "# BASE_DIR     = '/content/drive/MyDrive/Research/Hand Gesture/GitHub/'\n",
        "\n",
        "DATA_DIR     = 'Sensor-Data/'\n",
        "BW_IMG_DIR   = 'BW-Spatial-Path-Images/'\n",
        "RGB_IMG_DIR  = 'RGB-Spatial-Path-Images/'\n",
        "IMG_SIZE     = (3, 3) # INCHES\n",
        "\n",
        "IMG_DIR      = 'BW-Spatial-Path-Images/'\n",
        "LOG_DIR      = 'Logs/'\n",
        "\n",
        "USERS        = ['001', '002', '003', '004', '005', '006', '007', '008', '009',\n",
        "                '010', '011', '012', '013', '014', '015', '016', '017', '018',\n",
        "                '019', '020', '021', '022', '023', '024', '025']\n",
        "# ------------------------------- Only Dynalic Gestures ------------------------------ #\n",
        "GESTURES     = ['j', 'z', 'bad', 'deaf', 'fine', 'good', 'goodbye', 'hello', 'hungry',\n",
        "                'me', 'no', 'please', 'sorry', 'thankyou', 'yes', 'you']\n",
        "\n",
        "PLANES       = ['XY', 'YZ', 'ZX']\n",
        "\n",
        "DT           = 0.01\n",
        "LINEWIDTH    = 7\n",
        "\n",
        "BATCH_SIZE     = 32\n",
        "IMG_LEN        = 96\n",
        "IMG_SIZE       = (IMG_LEN, IMG_LEN)\n",
        "\n",
        "# ------------- FOR THE GREATER GOOD :) ------------- #\n",
        "DATASET_LEN    = 4000\n",
        "TRAIN_LEN      = 3840\n",
        "TEST_LEN       = 160\n",
        "\n",
        "EPOCHS         = 15\n",
        "LEARNING_RATE  = 0.001\n",
        "DECAY          = 0.0\n",
        "\n",
        "CONFIG         = '_L_7_S_160x160_E_7'\n",
        "\n",
        "XY_WEIGHTS     = np.array([0.91, 0.75, 0.61, 0.63, 0.51, 0.66, 0.81, 0.65, 0.65, 0.31,\n",
        "                           0.66, 0.29, 0.34, 0.64, 0.64, 0.31])\n",
        "YZ_WEIGHTS     = np.array([0.73, 0.71, 0.70, 0.79, 0.76, 0.38, 0.80, 0.61, 0.58, 0.73,\n",
        "                           0.49, 0.26, 0.26, 0.52, 0.59, 0.54])\n",
        "ZX_WEIGHTS     = np.array([0.33, 0.66, 0.51, 0.54, 0.37, 0.51, 0.71, 0.30, 0.75, 0.41,\n",
        "                           0.40, 0.27, 0.24, 0.61, 0.36, 0.49])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79vdHTpuEOKH"
      },
      "source": [
        "#--------------------- Download util for Google Drive ------------------- #\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "        \n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "        \n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "\n",
        "def download_data(fid, destination):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(destination)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('creating data directory ... ', end='')\n",
        "    os.mkdir(destination)\n",
        "    print('√')\n",
        "    \n",
        "    print('downloading dataset from the repository ... ', end='')\n",
        "    filename = os.path.join(destination, 'dataset.tar.xz')\n",
        "    try:\n",
        "        download_file_from_google_drive(fid, filename)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('extracting the dataset ... ', end='')\n",
        "    try:\n",
        "        tar = tarfile.open(filename)\n",
        "        tar.extractall(destination)\n",
        "        tar.close()\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')   "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vJSFeMMEa_m"
      },
      "source": [
        "# ------- Comment This if already downloaded -------- #\n",
        "\n",
        "# destination = os.path.join(BASE_DIR, DATA_DIR)\n",
        "# download_data(DATASET_ID, destination)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iUDD3WCEdph"
      },
      "source": [
        "# ------------- Spatial Path Image Generation ----------- #\n",
        "\n",
        "def clean_dir(path):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(path)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "    \n",
        "    print('creating ' + path + ' directory ... ', end='')\n",
        "    os.mkdir(path)\n",
        "    print('√')\n",
        "    \n",
        "# ----------- Spatial Path Vector Calculation ----------- #\n",
        "\n",
        "def get_displacement(acc):\n",
        "    v = np.zeros(acc.shape)\n",
        "    d = np.zeros(acc.shape)\n",
        "    for i in range(acc.shape[0] - 1):\n",
        "        v[i + 1] = v[i] + acc[i] * DT\n",
        "        d[i + 1] = v[i] * DT + 0.5 * acc[i] * DT * DT\n",
        "        \n",
        "    return d\n",
        "\n",
        "def write_image(x, y, path):\n",
        "    fig, ax = plt.subplots(frameon=True, figsize=(3, 3))\n",
        "    ax.axis('off')\n",
        "    plt.plot(x, y, '-k', linewidth=LINEWIDTH)\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "def generate_bw_images():\n",
        "    count = 0\n",
        "    image_dir = os.path.join(BASE_DIR, BW_IMG_DIR)\n",
        "    clean_dir(image_dir)\n",
        "    \n",
        "    for plane in PLANES:\n",
        "        print('processing spatial path images for ' + plane + ' plane ... ', end='')\n",
        "        plane_dir = os.path.join(image_dir, plane)\n",
        "        os.mkdir(plane_dir)\n",
        "        \n",
        "        for gesture in GESTURES:\n",
        "            os.mkdir(os.path.join(plane_dir, gesture))\n",
        "    \n",
        "            for user in USERS:\n",
        "                user_dir = os.path.join(BASE_DIR, DATA_DIR, user)\n",
        "                gesture_dir = os.path.join(user_dir, gesture + '.csv')\n",
        "                \n",
        "                accx = pd.read_csv(gesture_dir)['ACCx'].to_numpy()\n",
        "                accy = pd.read_csv(gesture_dir)['ACCy'].to_numpy()\n",
        "                accz = pd.read_csv(gesture_dir)['ACCz'].to_numpy()\n",
        "\n",
        "                x = get_displacement(accx).reshape(-1, 150)\n",
        "                y = get_displacement(accy).reshape(-1, 150)\n",
        "                z = get_displacement(accz).reshape(-1, 150)\n",
        "\n",
        "                for i in range(x.shape[0]):\n",
        "                    image_name = 'u' + user + '_g' + '{:0>2d}'.format(GESTURES.index(gesture)) + \\\n",
        "                                 '_s' + '{:0>7d}'.format(count) + '_p' + plane + '.jpg'\n",
        "                    path = os.path.join(BASE_DIR, BW_IMG_DIR, plane, gesture, image_name)\n",
        "                    \n",
        "                    if plane == 'XY':\n",
        "                        write_image(x[i, :], y[i, :], path)\n",
        "                    elif plane == 'YZ':\n",
        "                        write_image(y[i, :], z[i, :], path)\n",
        "                    else:\n",
        "                        write_image(z[i, :], x[i, :], path)\n",
        "\n",
        "                    count = count + 1\n",
        "            \n",
        "        print('√')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWBEae-zEk25"
      },
      "source": [
        "# generate_bw_images()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3rTb3wLEosc"
      },
      "source": [
        "def load_data(plane):\n",
        "    X_train = np.zeros((TRAIN_LEN, IMG_LEN, IMG_LEN, 3))\n",
        "    X_test = np.zeros((TEST_LEN, IMG_LEN, IMG_LEN, 3))\n",
        "    y_train = np.zeros((TRAIN_LEN, 1))\n",
        "    y_test = np.zeros((TEST_LEN, 1))\n",
        "    \n",
        "    train_count = 0\n",
        "    test_count = 0\n",
        "        \n",
        "    for gesture in GESTURES:\n",
        "        print('loading data for ' + gesture + ' gesture on the ' + plane + ' plane ... ', end='')\n",
        "        path = os.path.join(BASE_DIR, IMG_DIR, plane, gesture)\n",
        "        for filename in os.listdir(path):\n",
        "            img = cv2.imread(os.path.join(path, filename))\n",
        "            resized = cv2.resize(img, IMG_SIZE)\n",
        "            if filename[1:4] != TEST_USER:\n",
        "                X_train[train_count, :] = resized\n",
        "                y_train[train_count, 0] = GESTURES.index(gesture)\n",
        "                train_count = train_count + 1\n",
        "            else:\n",
        "                X_test[test_count, :] = resized\n",
        "                y_test[test_count, 0] = GESTURES.index(gesture)\n",
        "                test_count = test_count + 1\n",
        "                \n",
        "        print('√')\n",
        "        \n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def load_and_save_data(plane):\n",
        "    X = np.zeros((DATASET_LEN, IMG_LEN, IMG_LEN, 3))\n",
        "    y = np.zeros((DATASET_LEN, 1))\n",
        "    \n",
        "    train_count = 0\n",
        "    test_count  = TRAIN_LEN\n",
        "        \n",
        "    for gesture in GESTURES:\n",
        "        print('loading data for ' + gesture + ' gesture on the ' + plane + ' plane ... ', end='')\n",
        "        path = os.path.join(BASE_DIR, IMG_DIR, plane, gesture)\n",
        "        for filename in os.listdir(path):\n",
        "            img = cv2.imread(os.path.join(path, filename))\n",
        "            resized = cv2.resize(img, IMG_SIZE)\n",
        "            if filename[1:4] != TEST_USER:\n",
        "                X[train_count, :] = resized\n",
        "                y[train_count, 0] = GESTURES.index(gesture)\n",
        "                train_count = train_count + 1\n",
        "            else:\n",
        "                X[test_count, :] = resized\n",
        "                y[test_count, 0] = GESTURES.index(gesture)\n",
        "                test_count = test_count + 1\n",
        "                \n",
        "        print('√')\n",
        "\n",
        "    joblib.dump(X, BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    joblib.dump(y, BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "\n",
        "def load_data_from_joblib(plane):\n",
        "    print('Loading data for ' + plane + ' plane ... ', end='')\n",
        "    X = joblib.load(BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    y = joblib.load(BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    test_user = int(TEST_USER)\n",
        "    X_train = X[:TRAIN_LEN, :, :, :]\n",
        "    y_train = y[:TRAIN_LEN, :]\n",
        "    X_test = X[TRAIN_LEN:, :, :, :]\n",
        "    y_test = y[TRAIN_LEN:, :]\n",
        "\n",
        "    print('√')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk1UHBMpKF8G"
      },
      "source": [
        "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
        "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.3),\n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0outzPnzKGUx"
      },
      "source": [
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "base_model = tf.keras.applications.EfficientNetB3(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "base_model.trainable = False"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TcOKiAlKH7D"
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(len(GESTURES))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adXEpjPSKXj9"
      },
      "source": [
        "def get_model():\n",
        "    inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
        "    # x = data_augmentation(inputs)\n",
        "    x = preprocess_input(inputs)\n",
        "    x = base_model(x, training=False)\n",
        "    x = global_average_layer(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    outputs = prediction_layer(x)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, decay=DECAY),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHULgmSQKZO3",
        "outputId": "181bf34f-80cc-446a-d6b9-380bbf5ea536"
      },
      "source": [
        "model_xy = get_model()\n",
        "X_train_xy, X_test_xy, y_train_xy, y_test_xy = load_data('XY')\n",
        "X_train_xy, y_train_xy = shuffle(X_train_xy, y_train_xy)\n",
        "history_xy = model_xy.fit(X_train_xy, y_train_xy, validation_data=(X_test_xy, y_test_xy), epochs=EPOCHS)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading data for j gesture on the XY plane ... √\n",
            "loading data for z gesture on the XY plane ... √\n",
            "loading data for bad gesture on the XY plane ... √\n",
            "loading data for deaf gesture on the XY plane ... √\n",
            "loading data for fine gesture on the XY plane ... √\n",
            "loading data for good gesture on the XY plane ... √\n",
            "loading data for goodbye gesture on the XY plane ... √\n",
            "loading data for hello gesture on the XY plane ... √\n",
            "loading data for hungry gesture on the XY plane ... √\n",
            "loading data for me gesture on the XY plane ... √\n",
            "loading data for no gesture on the XY plane ... √\n",
            "loading data for please gesture on the XY plane ... √\n",
            "loading data for sorry gesture on the XY plane ... √\n",
            "loading data for thankyou gesture on the XY plane ... √\n",
            "loading data for yes gesture on the XY plane ... √\n",
            "loading data for you gesture on the XY plane ... √\n",
            "Epoch 1/15\n",
            "120/120 [==============================] - 14s 48ms/step - loss: 1.7047 - accuracy: 0.4849 - val_loss: 1.2779 - val_accuracy: 0.6125\n",
            "Epoch 2/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 1.1450 - accuracy: 0.6318 - val_loss: 1.0411 - val_accuracy: 0.6812\n",
            "Epoch 3/15\n",
            "120/120 [==============================] - 4s 32ms/step - loss: 0.9781 - accuracy: 0.6885 - val_loss: 0.9777 - val_accuracy: 0.6875\n",
            "Epoch 4/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.8766 - accuracy: 0.7182 - val_loss: 0.9096 - val_accuracy: 0.6875\n",
            "Epoch 5/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.8101 - accuracy: 0.7398 - val_loss: 0.8681 - val_accuracy: 0.7188\n",
            "Epoch 6/15\n",
            "120/120 [==============================] - 4s 32ms/step - loss: 0.7573 - accuracy: 0.7477 - val_loss: 0.8143 - val_accuracy: 0.7188\n",
            "Epoch 7/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.7109 - accuracy: 0.7747 - val_loss: 0.8219 - val_accuracy: 0.7000\n",
            "Epoch 8/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.6837 - accuracy: 0.7815 - val_loss: 0.7881 - val_accuracy: 0.7188\n",
            "Epoch 9/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.6533 - accuracy: 0.7870 - val_loss: 0.7416 - val_accuracy: 0.7437\n",
            "Epoch 10/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.6328 - accuracy: 0.7995 - val_loss: 0.7283 - val_accuracy: 0.7812\n",
            "Epoch 11/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.6070 - accuracy: 0.8008 - val_loss: 0.7158 - val_accuracy: 0.7563\n",
            "Epoch 12/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.5851 - accuracy: 0.8013 - val_loss: 0.7077 - val_accuracy: 0.7750\n",
            "Epoch 13/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.5770 - accuracy: 0.8055 - val_loss: 0.6869 - val_accuracy: 0.7688\n",
            "Epoch 14/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.5629 - accuracy: 0.8151 - val_loss: 0.7044 - val_accuracy: 0.7437\n",
            "Epoch 15/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.5466 - accuracy: 0.8185 - val_loss: 0.7094 - val_accuracy: 0.7312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV5fDKKPQEIq",
        "outputId": "34d7ce4b-92d0-4599-d6fa-1ecba92a3d59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred_xy = model_xy.predict(X_test_xy)\n",
        "y_pred = np.argmax(y_pred_xy, axis=1)\n",
        "print(classification_report(y_test_xy.ravel(), y_pred, zero_division=0))\n",
        "prc_xy = precision_score(y_test_xy.ravel(), y_pred, zero_division=0, average=None)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "del X_train_xy, X_test_xy, y_train_xy, y_test_xy"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.90      0.95        10\n",
            "         1.0       1.00      0.70      0.82        10\n",
            "         2.0       0.40      0.20      0.27        10\n",
            "         3.0       0.64      0.70      0.67        10\n",
            "         4.0       1.00      0.90      0.95        10\n",
            "         5.0       0.88      0.70      0.78        10\n",
            "         6.0       0.89      0.80      0.84        10\n",
            "         7.0       0.47      0.80      0.59        10\n",
            "         8.0       0.91      1.00      0.95        10\n",
            "         9.0       1.00      0.70      0.82        10\n",
            "        10.0       1.00      0.80      0.89        10\n",
            "        11.0       0.50      0.60      0.55        10\n",
            "        12.0       0.57      0.40      0.47        10\n",
            "        13.0       0.82      0.90      0.86        10\n",
            "        14.0       0.56      0.90      0.69        10\n",
            "        15.0       0.54      0.70      0.61        10\n",
            "\n",
            "    accuracy                           0.73       160\n",
            "   macro avg       0.76      0.73      0.73       160\n",
            "weighted avg       0.76      0.73      0.73       160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCIbJnjzQEql",
        "outputId": "d44913ba-959a-43c7-b2cd-88bcde2b539f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_yz = get_model()\n",
        "X_train_yz, X_test_yz, y_train_yz, y_test_yz = load_data('YZ')\n",
        "X_train_yz, y_train_yz = shuffle(X_train_yz, y_train_yz)\n",
        "history_yz = model_yz.fit(X_train_yz, y_train_yz, validation_data=(X_test_yz, y_test_yz), epochs=EPOCHS)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading data for j gesture on the YZ plane ... √\n",
            "loading data for z gesture on the YZ plane ... √\n",
            "loading data for bad gesture on the YZ plane ... √\n",
            "loading data for deaf gesture on the YZ plane ... √\n",
            "loading data for fine gesture on the YZ plane ... √\n",
            "loading data for good gesture on the YZ plane ... √\n",
            "loading data for goodbye gesture on the YZ plane ... √\n",
            "loading data for hello gesture on the YZ plane ... √\n",
            "loading data for hungry gesture on the YZ plane ... √\n",
            "loading data for me gesture on the YZ plane ... √\n",
            "loading data for no gesture on the YZ plane ... √\n",
            "loading data for please gesture on the YZ plane ... √\n",
            "loading data for sorry gesture on the YZ plane ... √\n",
            "loading data for thankyou gesture on the YZ plane ... √\n",
            "loading data for yes gesture on the YZ plane ... √\n",
            "loading data for you gesture on the YZ plane ... √\n",
            "Epoch 1/15\n",
            "120/120 [==============================] - 12s 47ms/step - loss: 2.4588 - accuracy: 0.3346 - val_loss: 1.6019 - val_accuracy: 0.4938\n",
            "Epoch 2/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 1.3597 - accuracy: 0.5654 - val_loss: 1.3111 - val_accuracy: 0.5500\n",
            "Epoch 3/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 1.0548 - accuracy: 0.6542 - val_loss: 0.9987 - val_accuracy: 0.6313\n",
            "Epoch 4/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.8885 - accuracy: 0.6971 - val_loss: 0.8568 - val_accuracy: 0.6500\n",
            "Epoch 5/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.8054 - accuracy: 0.7333 - val_loss: 0.7625 - val_accuracy: 0.6938\n",
            "Epoch 6/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.7361 - accuracy: 0.7570 - val_loss: 0.7130 - val_accuracy: 0.7125\n",
            "Epoch 7/15\n",
            "120/120 [==============================] - 4s 32ms/step - loss: 0.6832 - accuracy: 0.7669 - val_loss: 0.7068 - val_accuracy: 0.7437\n",
            "Epoch 8/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.6514 - accuracy: 0.7846 - val_loss: 0.6387 - val_accuracy: 0.7188\n",
            "Epoch 9/15\n",
            "120/120 [==============================] - 4s 32ms/step - loss: 0.6209 - accuracy: 0.7945 - val_loss: 0.6109 - val_accuracy: 0.7563\n",
            "Epoch 10/15\n",
            "120/120 [==============================] - 4s 32ms/step - loss: 0.5859 - accuracy: 0.8010 - val_loss: 0.5990 - val_accuracy: 0.7750\n",
            "Epoch 11/15\n",
            "120/120 [==============================] - 4s 32ms/step - loss: 0.5672 - accuracy: 0.8052 - val_loss: 0.6022 - val_accuracy: 0.7688\n",
            "Epoch 12/15\n",
            "120/120 [==============================] - 4s 32ms/step - loss: 0.5537 - accuracy: 0.8167 - val_loss: 0.5801 - val_accuracy: 0.7812\n",
            "Epoch 13/15\n",
            "120/120 [==============================] - 4s 32ms/step - loss: 0.5332 - accuracy: 0.8167 - val_loss: 0.5679 - val_accuracy: 0.7812\n",
            "Epoch 14/15\n",
            "120/120 [==============================] - 4s 32ms/step - loss: 0.5222 - accuracy: 0.8266 - val_loss: 0.5482 - val_accuracy: 0.7875\n",
            "Epoch 15/15\n",
            "120/120 [==============================] - 4s 32ms/step - loss: 0.5075 - accuracy: 0.8221 - val_loss: 0.5818 - val_accuracy: 0.7812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEqamoFSQKwy",
        "outputId": "21ac9eb3-0421-41c0-dcbb-4859ca01a435",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# prob_yz = tf.keras.Sequential([model_yz, tf.keras.layers.Softmax()])\n",
        "# y_pred_yz = prob_yz.predict(X_test_yz)\n",
        "y_pred_yz = model_yz.predict(X_test_yz)\n",
        "y_pred = np.argmax(y_pred_yz, axis=1)\n",
        "print(classification_report(y_test_yz.ravel(), y_pred, zero_division=0))\n",
        "prc_yz = precision_score(y_test_yz.ravel(), y_pred, zero_division=0, average=None)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "del X_train_yz, X_test_yz, y_train_yz, y_test_yz"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.90      0.95        10\n",
            "         1.0       1.00      1.00      1.00        10\n",
            "         2.0       0.91      1.00      0.95        10\n",
            "         3.0       0.91      1.00      0.95        10\n",
            "         4.0       1.00      1.00      1.00        10\n",
            "         5.0       0.56      0.90      0.69        10\n",
            "         6.0       0.78      0.70      0.74        10\n",
            "         7.0       0.91      1.00      0.95        10\n",
            "         8.0       1.00      0.20      0.33        10\n",
            "         9.0       0.90      0.90      0.90        10\n",
            "        10.0       0.59      1.00      0.74        10\n",
            "        11.0       0.47      0.80      0.59        10\n",
            "        12.0       0.00      0.00      0.00        10\n",
            "        13.0       0.83      1.00      0.91        10\n",
            "        14.0       0.62      0.50      0.56        10\n",
            "        15.0       0.86      0.60      0.71        10\n",
            "\n",
            "    accuracy                           0.78       160\n",
            "   macro avg       0.77      0.78      0.75       160\n",
            "weighted avg       0.77      0.78      0.75       160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNrCzFGIQLaR",
        "outputId": "a3929b4f-7de9-471b-ba21-17c72b44b956",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_zx = get_model()\n",
        "X_train_zx, X_test_zx, y_train_zx, y_test_zx = load_data('ZX')\n",
        "X_train_zx, y_train_zx = shuffle(X_train_zx, y_train_zx)\n",
        "history_zx = model_zx.fit(X_train_zx, y_train_zx, validation_data=(X_test_zx, y_test_zx), epochs=EPOCHS)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading data for j gesture on the ZX plane ... √\n",
            "loading data for z gesture on the ZX plane ... √\n",
            "loading data for bad gesture on the ZX plane ... √\n",
            "loading data for deaf gesture on the ZX plane ... √\n",
            "loading data for fine gesture on the ZX plane ... √\n",
            "loading data for good gesture on the ZX plane ... √\n",
            "loading data for goodbye gesture on the ZX plane ... √\n",
            "loading data for hello gesture on the ZX plane ... √\n",
            "loading data for hungry gesture on the ZX plane ... √\n",
            "loading data for me gesture on the ZX plane ... √\n",
            "loading data for no gesture on the ZX plane ... √\n",
            "loading data for please gesture on the ZX plane ... √\n",
            "loading data for sorry gesture on the ZX plane ... √\n",
            "loading data for thankyou gesture on the ZX plane ... √\n",
            "loading data for yes gesture on the ZX plane ... √\n",
            "loading data for you gesture on the ZX plane ... √\n",
            "Epoch 1/15\n",
            "120/120 [==============================] - 12s 46ms/step - loss: 2.8106 - accuracy: 0.3021 - val_loss: 2.5549 - val_accuracy: 0.3625\n",
            "Epoch 2/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 1.6124 - accuracy: 0.5065 - val_loss: 2.0982 - val_accuracy: 0.4000\n",
            "Epoch 3/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 1.2669 - accuracy: 0.5904 - val_loss: 1.8579 - val_accuracy: 0.4375\n",
            "Epoch 4/15\n",
            "120/120 [==============================] - 4s 32ms/step - loss: 1.1091 - accuracy: 0.6315 - val_loss: 1.7305 - val_accuracy: 0.4750\n",
            "Epoch 5/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.9942 - accuracy: 0.6734 - val_loss: 1.7531 - val_accuracy: 0.4812\n",
            "Epoch 6/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.9036 - accuracy: 0.7005 - val_loss: 1.6245 - val_accuracy: 0.5188\n",
            "Epoch 7/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.8460 - accuracy: 0.7214 - val_loss: 1.6087 - val_accuracy: 0.5000\n",
            "Epoch 8/15\n",
            "120/120 [==============================] - 4s 31ms/step - loss: 0.7929 - accuracy: 0.7375 - val_loss: 1.5951 - val_accuracy: 0.5125\n",
            "Epoch 9/15\n",
            "120/120 [==============================] - 4s 32ms/step - loss: 0.7702 - accuracy: 0.7365 - val_loss: 1.5939 - val_accuracy: 0.5063\n",
            "Epoch 10/15\n",
            "120/120 [==============================] - 4s 32ms/step - loss: 0.7357 - accuracy: 0.7591 - val_loss: 1.5418 - val_accuracy: 0.5188\n",
            "Epoch 11/15\n",
            "120/120 [==============================] - 4s 32ms/step - loss: 0.7026 - accuracy: 0.7589 - val_loss: 1.6309 - val_accuracy: 0.5188\n",
            "Epoch 12/15\n",
            "120/120 [==============================] - 4s 32ms/step - loss: 0.6788 - accuracy: 0.7721 - val_loss: 1.5405 - val_accuracy: 0.5375\n",
            "Epoch 13/15\n",
            "120/120 [==============================] - 4s 32ms/step - loss: 0.6562 - accuracy: 0.7758 - val_loss: 1.5631 - val_accuracy: 0.5000\n",
            "Epoch 14/15\n",
            "120/120 [==============================] - 4s 33ms/step - loss: 0.6392 - accuracy: 0.7839 - val_loss: 1.4751 - val_accuracy: 0.5312\n",
            "Epoch 15/15\n",
            "120/120 [==============================] - 4s 32ms/step - loss: 0.6224 - accuracy: 0.7839 - val_loss: 1.4160 - val_accuracy: 0.5500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qanPbY7QNVl",
        "outputId": "2f266993-46d3-4aed-fb3e-5a9f15bcf614",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# prob_zx = tf.keras.Sequential([model_zx, tf.keras.layers.Softmax()])\n",
        "# y_pred_zx = prob_zx.predict(X_test_zx)\n",
        "y_pred_zx = model_zx.predict(X_test_zx)\n",
        "y_pred = np.argmax(y_pred_zx, axis=1)\n",
        "print(classification_report(y_test_zx.ravel(), y_pred, zero_division=0))\n",
        "prc_zx = precision_score(y_test_zx.ravel(), y_pred, zero_division=0, average=None)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "del X_train_zx, X_test_zx, y_train_zx"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.42      1.00      0.59        10\n",
            "         1.0       0.43      0.30      0.35        10\n",
            "         2.0       0.71      1.00      0.83        10\n",
            "         3.0       0.67      0.20      0.31        10\n",
            "         4.0       0.36      0.90      0.51        10\n",
            "         5.0       1.00      1.00      1.00        10\n",
            "         6.0       0.71      0.50      0.59        10\n",
            "         7.0       0.54      0.70      0.61        10\n",
            "         8.0       1.00      0.10      0.18        10\n",
            "         9.0       0.57      0.80      0.67        10\n",
            "        10.0       0.80      0.40      0.53        10\n",
            "        11.0       0.20      0.10      0.13        10\n",
            "        12.0       0.00      0.00      0.00        10\n",
            "        13.0       0.47      0.70      0.56        10\n",
            "        14.0       0.62      0.50      0.56        10\n",
            "        15.0       0.86      0.60      0.71        10\n",
            "\n",
            "    accuracy                           0.55       160\n",
            "   macro avg       0.58      0.55      0.51       160\n",
            "weighted avg       0.58      0.55      0.51       160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7_SrZBlQQZg",
        "outputId": "23f7be49-8dda-45be-9072-75168796d91f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_total = y_pred_xy + y_pred_yz + y_pred_zx\n",
        "y_pred = np.argmax(y_total, axis=1)\n",
        "report = classification_report(y_test_zx.ravel(), y_pred, zero_division=0)\n",
        "print(report)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00        10\n",
            "         1.0       0.83      1.00      0.91        10\n",
            "         2.0       1.00      1.00      1.00        10\n",
            "         3.0       0.91      1.00      0.95        10\n",
            "         4.0       1.00      1.00      1.00        10\n",
            "         5.0       1.00      1.00      1.00        10\n",
            "         6.0       1.00      0.80      0.89        10\n",
            "         7.0       1.00      1.00      1.00        10\n",
            "         8.0       1.00      1.00      1.00        10\n",
            "         9.0       0.83      1.00      0.91        10\n",
            "        10.0       1.00      1.00      1.00        10\n",
            "        11.0       0.62      0.50      0.56        10\n",
            "        12.0       0.60      0.60      0.60        10\n",
            "        13.0       1.00      1.00      1.00        10\n",
            "        14.0       0.91      1.00      0.95        10\n",
            "        15.0       1.00      0.80      0.89        10\n",
            "\n",
            "    accuracy                           0.92       160\n",
            "   macro avg       0.92      0.92      0.92       160\n",
            "weighted avg       0.92      0.92      0.92       160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}