{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/Hand-Gesture-Recognition/blob/dev/Spatial-Path-Analysis/Spatial_Path_Transfer_Learning_BW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tamil-chrome",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tamil-chrome",
        "outputId": "e94fb2de-9cf9-4b61-c5fc-dbb4e4d3ad1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import gc\n",
        "import cv2\n",
        "import time\n",
        "import joblib\n",
        "import shutil\n",
        "import tarfile\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, GlobalAvgPool2D, Dropout, Flatten, concatenate\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from scipy.signal import butter, lfilter\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MfafORnwZkyT",
      "metadata": {
        "id": "MfafORnwZkyT"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "casual-stack",
      "metadata": {
        "id": "casual-stack"
      },
      "outputs": [],
      "source": [
        "# -------- TEST USER ----------- #\n",
        "\n",
        "TEST_USER      = '010'\n",
        "DATASET_ID     = '1p0CSRb9gax0sKqdyzOYVt-BXvZ4GtrBv'\n",
        "\n",
        "# BASE_DIR       = '../Dataset/'\n",
        "\n",
        "# Google Drive\n",
        "BASE_DIR       = '.'\n",
        "DATA_DIR       = 'Sensor-Data/'\n",
        "BW_IMG_DIR     = 'BW-Spatial-Path-Images/'\n",
        "RGB_IMG_DIR    = 'RGB-Spatial-Path-Images/'\n",
        "CHANNELS_DIR   = 'Channels/'\n",
        "IMG_SIZE       = (3, 3) # INCHES\n",
        "\n",
        "IMG_DIR        = 'BW-Spatial-Path-Images/'\n",
        "LOG_DIR        = 'Logs/'\n",
        "\n",
        "USERS          = ['001', '002', '003', '004', '005', '006', '007', '008', '009',\n",
        "                  '010', '011', '012', '013', '014', '015', '016', '017', '018',\n",
        "                  '019', '020', '021', '022', '023', '024', '025']\n",
        "\n",
        "# ------------------------------- Only Dynalic Gestures ------------------------------ #\n",
        "GESTURES       = ['j', 'z', 'bad', 'deaf', 'fine', 'good', 'goodbye', 'hello', 'hungry',\n",
        "                  'me', 'no', 'please', 'sorry', 'thankyou', 'yes', 'you']\n",
        "\n",
        "PLANES         = ['XY', 'YZ', 'ZX']\n",
        "\n",
        "BATCH_SIZE     = 32\n",
        "IMG_LEN        = 160\n",
        "IMG_SIZE       = (IMG_LEN, IMG_LEN)\n",
        "\n",
        "# ------------- FOR THE GREATER GOOD :) ------------- #\n",
        "DATASET_LEN    = 4000\n",
        "TRAIN_LEN      = 3840\n",
        "TEST_LEN       = 160\n",
        "\n",
        "EPOCHS         = 50\n",
        "LEARNING_RATE  = 0.001\n",
        "DECAY          = 0.0\n",
        "\n",
        "DT             = 0.01\n",
        "SHAPES         = 100\n",
        "CUT_OFF        = 3.0\n",
        "ORDER          = 4\n",
        "FS             = 100\n",
        "\n",
        "WINDOW_LEN     = 150\n",
        "\n",
        "CONFIG         = '_L_7_S_160x160_E_7'\n",
        "CHANNELS_GROUP = 'DYNAMIC_ACC_ONLY_'\n",
        "\n",
        "XY_WEIGHTS     = np.array([0.91, 0.75, 0.61, 0.63, 0.51, 0.66, 0.81, 0.65, 0.65, 0.31,\n",
        "                           0.66, 0.29, 0.34, 0.64, 0.64, 0.31])\n",
        "YZ_WEIGHTS     = np.array([0.73, 0.71, 0.70, 0.79, 0.76, 0.38, 0.80, 0.61, 0.58, 0.73,\n",
        "                           0.49, 0.26, 0.26, 0.52, 0.59, 0.54])\n",
        "ZX_WEIGHTS     = np.array([0.33, 0.66, 0.51, 0.54, 0.37, 0.51, 0.71, 0.30, 0.75, 0.41,\n",
        "                           0.40, 0.27, 0.24, 0.61, 0.36, 0.49])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e65322ba",
      "metadata": {
        "id": "e65322ba"
      },
      "outputs": [],
      "source": [
        "class LowPassFilter(object): \n",
        "    def butter_lowpass(cutoff, fs, order):\n",
        "        nyq = 0.5 * fs\n",
        "        normal_cutoff = cutoff / nyq\n",
        "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "        return b, a\n",
        "\n",
        "    def apply(data, cutoff=CUT_OFF, fs=FS, order=ORDER):\n",
        "        b, a = LowPassFilter.butter_lowpass(cutoff, fs, order=order)\n",
        "        y = lfilter(b, a, data)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ksdY7MgcqHNr",
      "metadata": {
        "id": "ksdY7MgcqHNr"
      },
      "outputs": [],
      "source": [
        "#--------------------- Download util for Google Drive ------------------- #\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "        \n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "        \n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "\n",
        "def download_data(fid, destination):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(destination)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('creating data directory ... ', end='')\n",
        "    os.mkdir(destination)\n",
        "    print('√')\n",
        "    \n",
        "    print('downloading dataset from the repository ... ', end='')\n",
        "    filename = os.path.join(destination, 'dataset.tar.xz')\n",
        "    try:\n",
        "        download_file_from_google_drive(fid, filename)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('extracting the dataset ... ', end='')\n",
        "    try:\n",
        "        tar = tarfile.open(filename)\n",
        "        tar.extractall(destination)\n",
        "        tar.close()\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MtE4QJm-qOZY",
      "metadata": {
        "id": "MtE4QJm-qOZY"
      },
      "outputs": [],
      "source": [
        "# # ------- Comment This if already downloaded -------- #\n",
        "\n",
        "# destination = os.path.join(BASE_DIR, DATA_DIR)\n",
        "# download_data(DATASET_ID, destination)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d84aa1",
      "metadata": {
        "id": "f9d84aa1"
      },
      "outputs": [],
      "source": [
        "def clean_dir(path):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(path)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "    \n",
        "    print('creating ' + path + ' directory ... ', end='')\n",
        "    os.mkdir(path)\n",
        "    print('√')\n",
        "\n",
        "def extract_channels():\n",
        "    channels_dir = os.path.join(BASE_DIR, CHANNELS_DIR)\n",
        "    clean_dir(channels_dir)\n",
        "        \n",
        "    for user in USERS:\n",
        "    # for gesture in GESTURES:\n",
        "        print('Processing data for user ' + user, end=' ')\n",
        "        # print(f\"processing data for gesture {gesture} \", end=\"...\" )\n",
        "        \n",
        "        X = []\n",
        "        y = []\n",
        "        first_time = True\n",
        "        \n",
        "        for gesture in GESTURES:\n",
        "        # for user in USERS:\n",
        "              \n",
        "            user_dir = os.path.join(BASE_DIR, DATA_DIR, user)\n",
        "            gesture_dir = os.path.join(user_dir, gesture + '.csv')\n",
        "\n",
        "            dataset = pd.read_csv(gesture_dir)\n",
        "\n",
        "            dataset['flex_1'] = dataset['flex_1'].rolling(3).median()\n",
        "            dataset['flex_2'] = dataset['flex_2'].rolling(3).median()\n",
        "            dataset['flex_3'] = dataset['flex_3'].rolling(3).median()\n",
        "            dataset['flex_4'] = dataset['flex_4'].rolling(3).median()\n",
        "            dataset['flex_5'] = dataset['flex_5'].rolling(3).median()\n",
        "\n",
        "            dataset.fillna(0, inplace=True)\n",
        "\n",
        "            # flex = ['flex_1', 'flex_2', 'flex_3', 'flex_4', 'flex_5']\n",
        "            # max_flex = dataset[flex].max(axis=1)\n",
        "            # max_flex.replace(0, 1, inplace=True)\n",
        "            # dataset[flex] = dataset[flex].divide(max_flex, axis=0)\n",
        "            \n",
        "            flx1 = dataset['flex_1'].to_numpy().reshape(-1, WINDOW_LEN)\n",
        "            flx2 = dataset['flex_2'].to_numpy().reshape(-1, WINDOW_LEN)\n",
        "            flx3 = dataset['flex_3'].to_numpy().reshape(-1, WINDOW_LEN)\n",
        "            flx4 = dataset['flex_4'].to_numpy().reshape(-1, WINDOW_LEN)\n",
        "            flx5 = dataset['flex_5'].to_numpy().reshape(-1, WINDOW_LEN)\n",
        "            \n",
        "            accx = dataset['ACCx'].to_numpy()\n",
        "            accy = dataset['ACCy'].to_numpy()\n",
        "            accz = dataset['ACCz'].to_numpy()\n",
        "            \n",
        "            accx = LowPassFilter.apply(accx).reshape(-1, WINDOW_LEN)\n",
        "            accy = LowPassFilter.apply(accy).reshape(-1, WINDOW_LEN)\n",
        "            accz = LowPassFilter.apply(accz).reshape(-1, WINDOW_LEN)\n",
        "            \n",
        "            gyrx = dataset['GYRx'].to_numpy()\n",
        "            gyry = dataset['GYRy'].to_numpy()\n",
        "            gyrz = dataset['GYRz'].to_numpy()\n",
        "            \n",
        "            gyrx = LowPassFilter.apply(gyrx).reshape(-1, WINDOW_LEN)\n",
        "            gyry = LowPassFilter.apply(gyry).reshape(-1, WINDOW_LEN)\n",
        "            gyrz = LowPassFilter.apply(gyrz).reshape(-1, WINDOW_LEN)\n",
        "            \n",
        "            accm = np.sqrt(accx ** 2 + accy ** 2 + accz ** 2)\n",
        "            gyrm = np.sqrt(gyrx ** 2 + gyry ** 2 + gyrz ** 2)\n",
        "            \n",
        "            g_idx = GESTURES.index(gesture)\n",
        "            labels = np.ones((accx.shape[0], 1)) * g_idx\n",
        "            \n",
        "            channels = np.stack([\n",
        "                flx1, flx2, flx3, flx4, flx5,\n",
        "                accx, accy, accz\n",
        "            ], axis=-1)\n",
        "            \n",
        "            if first_time == True:\n",
        "                X = channels\n",
        "                y = labels\n",
        "                first_time = False\n",
        "            else:\n",
        "                X = np.append(X, channels, axis=0)\n",
        "                y = np.append(y, labels, axis=0)\n",
        "            \n",
        "        \n",
        "        x_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_X.joblib')\n",
        "        y_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_y.joblib')\n",
        "        joblib.dump(X, x_path)\n",
        "        joblib.dump(y, y_path)\n",
        "        \n",
        "        print('√')\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QmReRMF-qQcl",
      "metadata": {
        "id": "QmReRMF-qQcl"
      },
      "outputs": [],
      "source": [
        "# ------------- Spatial Path Image Generation ----------- #\n",
        "\n",
        "def clean_dir(path):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(path)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "    \n",
        "    print('creating ' + path + ' directory ... ', end='')\n",
        "    os.mkdir(path)\n",
        "    print('√')\n",
        "    \n",
        "# ----------- Spatial Path Vector Calculation ----------- #\n",
        "\n",
        "def get_displacement(acc):\n",
        "    v = np.zeros(acc.shape)\n",
        "    d = np.zeros(acc.shape)\n",
        "    for i in range(acc.shape[0] - 1):\n",
        "        v[i + 1] = v[i] + acc[i] * DT\n",
        "        d[i + 1] = v[i] * DT + 0.5 * acc[i] * DT * DT\n",
        "        \n",
        "    return d\n",
        "\n",
        "def write_image(x, y, path):\n",
        "    fig, ax = plt.subplots(frameon=True, figsize=(3, 3))\n",
        "    ax.axis('off')\n",
        "    plt.scatter(x, y, s=SHAPES, c='black')\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "def generate_bw_images():\n",
        "    count = 0\n",
        "    image_dir = os.path.join(BASE_DIR, BW_IMG_DIR)\n",
        "    clean_dir(image_dir)\n",
        "    \n",
        "    for plane in PLANES:\n",
        "        print('processing spatial path images for ' + plane + ' plane ... ', end='')\n",
        "        plane_dir = os.path.join(image_dir, plane)\n",
        "        os.mkdir(plane_dir)\n",
        "        \n",
        "        # for gesture in GESTURES:\n",
        "        #     os.mkdir(os.path.join(plane_dir, gesture))\n",
        "\n",
        "        for user in USERS:\n",
        "            os.mkdir(os.path.join(plane_dir, user))\n",
        "    \n",
        "            # for user in USERS:\n",
        "            for gesture in GESTURES:\n",
        "                user_dir = os.path.join(BASE_DIR, DATA_DIR, user)\n",
        "                gesture_dir = os.path.join(user_dir, gesture + '.csv')\n",
        "                \n",
        "                accx = pd.read_csv(gesture_dir)['ACCx'].to_numpy()\n",
        "                accy = pd.read_csv(gesture_dir)['ACCy'].to_numpy()\n",
        "                accz = pd.read_csv(gesture_dir)['ACCz'].to_numpy()\n",
        "\n",
        "                x = get_displacement(accx).reshape(-1, 150)\n",
        "                y = get_displacement(accy).reshape(-1, 150)\n",
        "                z = get_displacement(accz).reshape(-1, 150)\n",
        "\n",
        "                for i in range(x.shape[0]):\n",
        "                    image_name = 'u' + user + '_g' + '{:0>2d}'.format(GESTURES.index(gesture)) + \\\n",
        "                                 '_s' + '{:0>7d}'.format(count) + '_p' + plane + '.jpg'\n",
        "                    path = os.path.join(plane_dir, user, image_name)\n",
        "                    \n",
        "                    if plane == 'XY':\n",
        "                        write_image(x[i, :], y[i, :], path)\n",
        "                    elif plane == 'YZ':\n",
        "                        write_image(y[i, :], z[i, :], path)\n",
        "                    else:\n",
        "                        write_image(z[i, :], x[i, :], path)\n",
        "\n",
        "                    count = count + 1\n",
        "            \n",
        "        print('√')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07jhA8ukqScv",
      "metadata": {
        "id": "07jhA8ukqScv",
        "outputId": "8a8ff694-2a5c-4c4c-bbd4-9845d1befb0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cleaning already existing files ... √\n",
            "creating ./Channels/ directory ... √\n",
            "Processing data for user 001 √\n",
            "Processing data for user 002 √\n",
            "Processing data for user 003 √\n",
            "Processing data for user 004 √\n",
            "Processing data for user 005 √\n",
            "Processing data for user 006 √\n",
            "Processing data for user 007 √\n",
            "Processing data for user 008 √\n",
            "Processing data for user 009 √\n",
            "Processing data for user 010 √\n",
            "Processing data for user 011 √\n",
            "Processing data for user 012 √\n",
            "Processing data for user 013 √\n",
            "Processing data for user 014 √\n",
            "Processing data for user 015 √\n",
            "Processing data for user 016 √\n",
            "Processing data for user 017 √\n",
            "Processing data for user 018 √\n",
            "Processing data for user 019 √\n",
            "Processing data for user 020 √\n",
            "Processing data for user 021 √\n",
            "Processing data for user 022 √\n",
            "Processing data for user 023 √\n",
            "Processing data for user 024 √\n",
            "Processing data for user 025 √\n"
          ]
        }
      ],
      "source": [
        "# extract_channels()\n",
        "# generate_bw_images()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stylish-banner",
      "metadata": {
        "id": "stylish-banner"
      },
      "outputs": [],
      "source": [
        "def load_data(plane, test_user):\n",
        "    X_train = np.zeros((TRAIN_LEN, IMG_LEN, IMG_LEN, 3), dtype='uint8')\n",
        "    X_test = np.zeros((TEST_LEN, IMG_LEN, IMG_LEN, 3), dtype='uint8')\n",
        "    y_train = np.zeros((TRAIN_LEN, 1), dtype='uint8')\n",
        "    y_test = np.zeros((TEST_LEN, 1), dtype='uint8')\n",
        "    \n",
        "    train_count = 0\n",
        "    test_count = 0\n",
        "        \n",
        "    # for gesture in GESTURES:\n",
        "    for user in USERS:\n",
        "        print('loading data for user ' + user + ' on the ' + plane + ' plane ... ', end='')\n",
        "        path = os.path.join(BASE_DIR, IMG_DIR, plane, user)\n",
        "        for filename in os.listdir(path):\n",
        "            img = cv2.imread(os.path.join(path, filename))\n",
        "            resized = cv2.resize(img, IMG_SIZE)\n",
        "            # resized = np.expand_dims(resized, axis=-1)\n",
        "            label = int(filename[6:8])\n",
        "            if filename[1:4] != test_user:\n",
        "                X_train[train_count, :] = resized\n",
        "                y_train[train_count, 0] = label # GESTURES.index(gesture)\n",
        "                train_count = train_count + 1\n",
        "            else:\n",
        "                X_test[test_count, :] = resized\n",
        "                y_test[test_count, 0] = label # GESTURES.index(gesture)\n",
        "                test_count = test_count + 1\n",
        "                \n",
        "        print('√')\n",
        "        \n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def load_and_save_data(plane):\n",
        "    X = np.zeros((DATASET_LEN, IMG_LEN, IMG_LEN, 1))\n",
        "    y = np.zeros((DATASET_LEN, 1))\n",
        "    \n",
        "    train_count = 0\n",
        "    test_count  = TRAIN_LEN\n",
        "        \n",
        "    for gesture in GESTURES:\n",
        "        print('loading data for ' + gesture + ' gesture on the ' + plane + ' plane ... ', end='')\n",
        "        path = os.path.join(BASE_DIR, IMG_DIR, plane, gesture)\n",
        "        for filename in os.listdir(path):\n",
        "            img = cv2.imread(os.path.join(path, filename), cv2.IMREAD_GRAYSCALE)\n",
        "            resized = cv2.resize(img, IMG_SIZE)\n",
        "            if filename[1:4] != TEST_USER:\n",
        "                X[train_count, :] = resized\n",
        "                y[train_count, 0] = GESTURES.index(gesture)\n",
        "                train_count = train_count + 1\n",
        "            else:\n",
        "                X[test_count, :] = resized\n",
        "                y[test_count, 0] = GESTURES.index(gesture)\n",
        "                test_count = test_count + 1\n",
        "                \n",
        "        print('√')\n",
        "\n",
        "    joblib.dump(X, BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    joblib.dump(y, BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "\n",
        "def load_data_from_joblib(plane):\n",
        "    print('Loading data for ' + plane + ' plane ... ', end='')\n",
        "    X = joblib.load(BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    y = joblib.load(BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    test_user = int(TEST_USER)\n",
        "    X_train = X[:TRAIN_LEN, :, :, :]\n",
        "    y_train = y[:TRAIN_LEN, :]\n",
        "    X_test = X[TRAIN_LEN:, :, :, :]\n",
        "    y_test = y[TRAIN_LEN:, :]\n",
        "\n",
        "    print('√')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "extra-disclosure",
      "metadata": {
        "id": "extra-disclosure"
      },
      "outputs": [],
      "source": [
        "# X_train_xy, X_test_xy, y_train_xy, y_test_xy = load_data('XY')\n",
        "# X_train_yz, X_test_yz, y_train_yz, y_test_yz = load_data('YZ')\n",
        "# X_train_zx, X_test_zx, y_train_zx, y_test_zx = load_data('ZX')\n",
        "\n",
        "# Save to Google  Drive\n",
        "# load_and_save_data('XY')X_train_xy, y_train_xy = shuffle(X_train_xy, y_train_xy)\n",
        "# load_and_save_data('YZ')\n",
        "# load_and_save_data('ZX')\n",
        "\n",
        "# Load from Google Drive\n",
        "# X_train_xy, X_test_xy, y_train_xy, y_test_xy = load_data_from_joblib('XY')\n",
        "# X_train_yz, X_test_yz, y_train_yz, y_test_yz = load_data_from_joblib('YZ')\n",
        "# X_train_zx, X_test_zx, y_train_zx, y_test_zx = load_data_from_joblib('ZX')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "conditional-advisory",
      "metadata": {
        "id": "conditional-advisory"
      },
      "outputs": [],
      "source": [
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "internal-arkansas",
      "metadata": {
        "id": "internal-arkansas"
      },
      "outputs": [],
      "source": [
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "strange-encoding",
      "metadata": {
        "id": "strange-encoding"
      },
      "outputs": [],
      "source": [
        "global_average_layer = GlobalAvgPool2D()\n",
        "prediction_layer = Dense(len(GESTURES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e049e9a",
      "metadata": {
        "id": "6e049e9a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.keras.layers.pooling import MaxPooling2D\n",
        "\n",
        "def get_conv_block_1D():\n",
        "    input = Input(shape=(150, 1))\n",
        "    x = BatchNormalization()(input)\n",
        "    x = Conv1D(filters=8, kernel_size=3, activation='relu', padding='valid')(x)\n",
        "    x = Conv1D(filters=16, kernel_size=3, activation='relu', padding='valid')(x)\n",
        "    x = MaxPooling1D(2)(x)\n",
        "    x = Conv1D(filters=16, kernel_size=3, activation='relu', padding='valid')(x)\n",
        "    x = Conv1D(filters=16, kernel_size=3, activation='relu', padding='valid')(x)\n",
        "    x = MaxPooling1D(2)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(50, activation='relu')(x)\n",
        "\n",
        "    return input, x\n",
        "\n",
        "def get_conv_block_2D():\n",
        "    input = tf.keras.layers.Input(shape=IMG_SHAPE)\n",
        "    # x = data_augmentation(input)\n",
        "    x = preprocess_input(input)\n",
        "    x = base_model(x, training=False)\n",
        "    x = global_average_layer(x)\n",
        "\n",
        "    # x = layers.Conv2D(16, 3, padding=\"valid\", kernel_regularizer=regularizers.l2(0.001),)(\n",
        "    #     input\n",
        "    # )\n",
        "    # x = layers.BatchNormalization()(x)\n",
        "    # x = tf.keras.activations.relu(x)\n",
        "    # x = layers.MaxPooling2D()(x)\n",
        "    # x = layers.Conv2D(32, 3, padding=\"valid\", kernel_regularizer=regularizers.l2(0.001),)(\n",
        "    #     x\n",
        "    # )\n",
        "    # x = layers.BatchNormalization()(x)\n",
        "    # x = tf.keras.activations.relu(x)\n",
        "    # x = layers.MaxPooling2D()(x)\n",
        "    # x = layers.Conv2D(\n",
        "    #     64, 3, padding=\"valid\", kernel_regularizer=regularizers.l2(0.001),\n",
        "    # )(x)\n",
        "    # x = layers.BatchNormalization()(x)\n",
        "    # x = tf.keras.activations.relu(x)\n",
        "    # x = layers.Flatten()(x)\n",
        "\n",
        "    return input, x\n",
        "\n",
        "\n",
        "def get_stacked_model():\n",
        "    inputs = []\n",
        "    CNNs = []\n",
        "\n",
        "    # for i in range(8):\n",
        "    #     input_i, CNN_i = get_conv_block_1D()\n",
        "    #     inputs.append(input_i)\n",
        "    #     CNNs.append(CNN_i)\n",
        "\n",
        "    for i in range(3):\n",
        "        input_i, CNN_i = get_conv_block_2D()\n",
        "        inputs.append(input_i)\n",
        "        CNNs.append(CNN_i)\n",
        "\n",
        "    x = concatenate(CNNs, axis=-1)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    output = Dense(16)(x)\n",
        "    model = Model(inputs, output)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    loss = SparseCategoricalCrossentropy(from_logits=True)\n",
        "    model.compile(loss=loss, optimizer=opt, metrics=[\"accuracy\"])\n",
        "    \n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WTWKoIlYyzKW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTWKoIlYyzKW",
        "outputId": "2fc6d3ed-0214-4af2-9e45-e5f86df9005d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " tf.math.truediv (TFOpLambda)   (None, 160, 160, 3)  0           ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.truediv_1 (TFOpLambda)  (None, 160, 160, 3)  0          ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.truediv_2 (TFOpLambda)  (None, 160, 160, 3)  0          ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.subtract (TFOpLambda)  (None, 160, 160, 3)  0           ['tf.math.truediv[0][0]']        \n",
            "                                                                                                  \n",
            " tf.math.subtract_1 (TFOpLambda  (None, 160, 160, 3)  0          ['tf.math.truediv_1[0][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.subtract_2 (TFOpLambda  (None, 160, 160, 3)  0          ['tf.math.truediv_2[0][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " mobilenetv2_1.00_160 (Function  (None, 5, 5, 1280)  2257984     ['tf.math.subtract[0][0]',       \n",
            " al)                                                              'tf.math.subtract_1[0][0]',     \n",
            "                                                                  'tf.math.subtract_2[0][0]']     \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 1280)        0           ['mobilenetv2_1.00_160[0][0]',   \n",
            " alAveragePooling2D)                                              'mobilenetv2_1.00_160[1][0]',   \n",
            "                                                                  'mobilenetv2_1.00_160[2][0]']   \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 3840)         0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 , 'global_average_pooling2d[1][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'global_average_pooling2d[2][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 3840)         0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 128)          491648      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 128)          0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 16)           2064        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,751,696\n",
            "Trainable params: 493,712\n",
            "Non-trainable params: 2,257,984\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = get_stacked_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "upper-tobago",
      "metadata": {
        "id": "upper-tobago"
      },
      "outputs": [],
      "source": [
        "# def get_model():\n",
        "#     inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
        "#     #     x = data_augmentation(inputs)\n",
        "#     x = preprocess_input(inputs)\n",
        "#     x = base_model(x, training=False)\n",
        "#     x = global_average_layer(x)\n",
        "#     x = tf.keras.layers.Dropout(0.2)(x)\n",
        "#     outputs = prediction_layer(x)\n",
        "#     model = tf.keras.Model(inputs, outputs)\n",
        "#     model.compile(\n",
        "#         optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE, decay=DECAY),\n",
        "#         loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#         metrics=[\"accuracy\"],\n",
        "#     )\n",
        "#     return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3a457f4",
      "metadata": {
        "id": "b3a457f4",
        "outputId": "b317938f-f577-4073-f7f2-638eb7c5542b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing results for user 001... \n",
            "loading data for user 001 on the XY plane ... √\n",
            "loading data for user 002 on the XY plane ... √\n",
            "loading data for user 003 on the XY plane ... √\n",
            "loading data for user 004 on the XY plane ... √\n",
            "loading data for user 005 on the XY plane ... √\n",
            "loading data for user 006 on the XY plane ... √\n",
            "loading data for user 007 on the XY plane ... √\n",
            "loading data for user 008 on the XY plane ... √\n",
            "loading data for user 009 on the XY plane ... √\n",
            "loading data for user 010 on the XY plane ... √\n",
            "loading data for user 011 on the XY plane ... √\n",
            "loading data for user 012 on the XY plane ... √\n",
            "loading data for user 013 on the XY plane ... √\n",
            "loading data for user 014 on the XY plane ... √\n",
            "loading data for user 015 on the XY plane ... √\n",
            "loading data for user 016 on the XY plane ... √\n",
            "loading data for user 017 on the XY plane ... √\n",
            "loading data for user 018 on the XY plane ... √\n",
            "loading data for user 019 on the XY plane ... √\n",
            "loading data for user 020 on the XY plane ... √\n",
            "loading data for user 021 on the XY plane ... √\n",
            "loading data for user 022 on the XY plane ... √\n",
            "loading data for user 023 on the XY plane ... √\n",
            "loading data for user 024 on the XY plane ... √\n",
            "loading data for user 025 on the XY plane ... √\n",
            "loading data for user 001 on the YZ plane ... √\n",
            "loading data for user 002 on the YZ plane ... √\n",
            "loading data for user 003 on the YZ plane ... √\n",
            "loading data for user 004 on the YZ plane ... √\n",
            "loading data for user 005 on the YZ plane ... √\n",
            "loading data for user 006 on the YZ plane ... √\n",
            "loading data for user 007 on the YZ plane ... √\n",
            "loading data for user 008 on the YZ plane ... √\n",
            "loading data for user 009 on the YZ plane ... √\n",
            "loading data for user 010 on the YZ plane ... √\n",
            "loading data for user 011 on the YZ plane ... √\n",
            "loading data for user 012 on the YZ plane ... √\n",
            "loading data for user 013 on the YZ plane ... √\n",
            "loading data for user 014 on the YZ plane ... √\n",
            "loading data for user 015 on the YZ plane ... √\n",
            "loading data for user 016 on the YZ plane ... √\n",
            "loading data for user 017 on the YZ plane ... √\n",
            "loading data for user 018 on the YZ plane ... √\n",
            "loading data for user 019 on the YZ plane ... √\n",
            "loading data for user 020 on the YZ plane ... √\n",
            "loading data for user 021 on the YZ plane ... √\n",
            "loading data for user 022 on the YZ plane ... √\n",
            "loading data for user 023 on the YZ plane ... √\n",
            "loading data for user 024 on the YZ plane ... √\n",
            "loading data for user 025 on the YZ plane ... √\n",
            "loading data for user 001 on the ZX plane ... √\n",
            "loading data for user 002 on the ZX plane ... √\n",
            "loading data for user 003 on the ZX plane ... √\n",
            "loading data for user 004 on the ZX plane ... √\n",
            "loading data for user 005 on the ZX plane ... √\n",
            "loading data for user 006 on the ZX plane ... √\n",
            "loading data for user 007 on the ZX plane ... √\n",
            "loading data for user 008 on the ZX plane ... √\n",
            "loading data for user 009 on the ZX plane ... √\n",
            "loading data for user 010 on the ZX plane ... √\n",
            "loading data for user 011 on the ZX plane ... √\n",
            "loading data for user 012 on the ZX plane ... √\n",
            "loading data for user 013 on the ZX plane ... √\n",
            "loading data for user 014 on the ZX plane ... √\n",
            "loading data for user 015 on the ZX plane ... √\n",
            "loading data for user 016 on the ZX plane ... √\n",
            "loading data for user 017 on the ZX plane ... √\n",
            "loading data for user 018 on the ZX plane ... √\n",
            "loading data for user 019 on the ZX plane ... √\n",
            "loading data for user 020 on the ZX plane ... √\n",
            "loading data for user 021 on the ZX plane ... √\n",
            "loading data for user 022 on the ZX plane ... √\n",
            "loading data for user 023 on the ZX plane ... √\n",
            "loading data for user 024 on the ZX plane ... √\n",
            "loading data for user 025 on the ZX plane ... √\n",
            "8\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "60/60 [==============================] - 26s 200ms/step - loss: 2.6916 - accuracy: 0.1924 - val_loss: 1.8843 - val_accuracy: 0.5375\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 9s 146ms/step - loss: 1.6605 - accuracy: 0.4805 - val_loss: 0.9846 - val_accuracy: 0.7750\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 9s 146ms/step - loss: 0.9732 - accuracy: 0.7021 - val_loss: 0.5265 - val_accuracy: 0.8625\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 9s 146ms/step - loss: 0.6378 - accuracy: 0.7995 - val_loss: 0.3900 - val_accuracy: 0.8750\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.4808 - accuracy: 0.8513 - val_loss: 0.2723 - val_accuracy: 0.9375\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 9s 146ms/step - loss: 0.3589 - accuracy: 0.8849 - val_loss: 0.2232 - val_accuracy: 0.9500\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.3143 - accuracy: 0.9010 - val_loss: 0.1765 - val_accuracy: 0.9563\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 9s 146ms/step - loss: 0.2474 - accuracy: 0.9193 - val_loss: 0.1528 - val_accuracy: 0.9625\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 9s 154ms/step - loss: 0.2237 - accuracy: 0.9273 - val_loss: 0.1152 - val_accuracy: 0.9750\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.2019 - accuracy: 0.9320 - val_loss: 0.1021 - val_accuracy: 0.9750\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 10s 162ms/step - loss: 0.1748 - accuracy: 0.9469 - val_loss: 0.0820 - val_accuracy: 0.9875\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 9s 152ms/step - loss: 0.1621 - accuracy: 0.9466 - val_loss: 0.0822 - val_accuracy: 0.9812\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.1482 - accuracy: 0.9568 - val_loss: 0.0709 - val_accuracy: 0.9812\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.1291 - accuracy: 0.9591 - val_loss: 0.0771 - val_accuracy: 0.9812\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1237 - accuracy: 0.9635 - val_loss: 0.0756 - val_accuracy: 0.9812\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1164 - accuracy: 0.9646 - val_loss: 0.0678 - val_accuracy: 0.9750\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.1103 - accuracy: 0.9672 - val_loss: 0.0661 - val_accuracy: 0.9812\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0947 - accuracy: 0.9682 - val_loss: 0.0557 - val_accuracy: 0.9812\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.0939 - accuracy: 0.9732 - val_loss: 0.0587 - val_accuracy: 0.9812\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0873 - accuracy: 0.9693 - val_loss: 0.0487 - val_accuracy: 0.9875\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0836 - accuracy: 0.9742 - val_loss: 0.0424 - val_accuracy: 0.9875\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0866 - accuracy: 0.9742 - val_loss: 0.0495 - val_accuracy: 0.9875\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0661 - accuracy: 0.9807 - val_loss: 0.0470 - val_accuracy: 0.9875\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0714 - accuracy: 0.9766 - val_loss: 0.0467 - val_accuracy: 0.9875\n",
            "Epoch 25/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.0679 - accuracy: 0.9805 - val_loss: 0.0419 - val_accuracy: 0.9875\n",
            "Epoch 26/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0643 - accuracy: 0.9807 - val_loss: 0.0474 - val_accuracy: 0.9812\n",
            "Epoch 27/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0645 - accuracy: 0.9802 - val_loss: 0.0504 - val_accuracy: 0.9875\n",
            "Epoch 28/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0504 - accuracy: 0.9849 - val_loss: 0.0421 - val_accuracy: 0.9812\n",
            "Epoch 29/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0553 - accuracy: 0.9839 - val_loss: 0.0530 - val_accuracy: 0.9812\n",
            "Epoch 30/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0477 - accuracy: 0.9872 - val_loss: 0.0439 - val_accuracy: 0.9812\n",
            "Epoch 31/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.0482 - accuracy: 0.9844 - val_loss: 0.0363 - val_accuracy: 0.9875\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 1.8843 - accuracy: 0.5375\n",
            "53.75 %\n",
            "Processing results for user 002... \n",
            "loading data for user 001 on the XY plane ... √\n",
            "loading data for user 002 on the XY plane ... √\n",
            "loading data for user 003 on the XY plane ... √\n",
            "loading data for user 004 on the XY plane ... √\n",
            "loading data for user 005 on the XY plane ... √\n",
            "loading data for user 006 on the XY plane ... √\n",
            "loading data for user 007 on the XY plane ... √\n",
            "loading data for user 008 on the XY plane ... √\n",
            "loading data for user 009 on the XY plane ... √\n",
            "loading data for user 010 on the XY plane ... √\n",
            "loading data for user 011 on the XY plane ... √\n",
            "loading data for user 012 on the XY plane ... √\n",
            "loading data for user 013 on the XY plane ... √\n",
            "loading data for user 014 on the XY plane ... √\n",
            "loading data for user 015 on the XY plane ... √\n",
            "loading data for user 016 on the XY plane ... √\n",
            "loading data for user 017 on the XY plane ... √\n",
            "loading data for user 018 on the XY plane ... √\n",
            "loading data for user 019 on the XY plane ... √\n",
            "loading data for user 020 on the XY plane ... √\n",
            "loading data for user 021 on the XY plane ... √\n",
            "loading data for user 022 on the XY plane ... √\n",
            "loading data for user 023 on the XY plane ... √\n",
            "loading data for user 024 on the XY plane ... √\n",
            "loading data for user 025 on the XY plane ... √\n",
            "loading data for user 001 on the YZ plane ... √\n",
            "loading data for user 002 on the YZ plane ... √\n",
            "loading data for user 003 on the YZ plane ... √\n",
            "loading data for user 004 on the YZ plane ... √\n",
            "loading data for user 005 on the YZ plane ... √\n",
            "loading data for user 006 on the YZ plane ... √\n",
            "loading data for user 007 on the YZ plane ... √\n",
            "loading data for user 008 on the YZ plane ... √\n",
            "loading data for user 009 on the YZ plane ... √\n",
            "loading data for user 010 on the YZ plane ... √\n",
            "loading data for user 011 on the YZ plane ... √\n",
            "loading data for user 012 on the YZ plane ... √\n",
            "loading data for user 013 on the YZ plane ... √\n",
            "loading data for user 014 on the YZ plane ... √\n",
            "loading data for user 015 on the YZ plane ... √\n",
            "loading data for user 016 on the YZ plane ... √\n",
            "loading data for user 017 on the YZ plane ... √\n",
            "loading data for user 018 on the YZ plane ... √\n",
            "loading data for user 019 on the YZ plane ... √\n",
            "loading data for user 020 on the YZ plane ... √\n",
            "loading data for user 021 on the YZ plane ... √\n",
            "loading data for user 022 on the YZ plane ... √\n",
            "loading data for user 023 on the YZ plane ... √\n",
            "loading data for user 024 on the YZ plane ... √\n",
            "loading data for user 025 on the YZ plane ... √\n",
            "loading data for user 001 on the ZX plane ... √\n",
            "loading data for user 002 on the ZX plane ... √\n",
            "loading data for user 003 on the ZX plane ... √\n",
            "loading data for user 004 on the ZX plane ... √\n",
            "loading data for user 005 on the ZX plane ... √\n",
            "loading data for user 006 on the ZX plane ... √\n",
            "loading data for user 007 on the ZX plane ... √\n",
            "loading data for user 008 on the ZX plane ... √\n",
            "loading data for user 009 on the ZX plane ... √\n",
            "loading data for user 010 on the ZX plane ... √\n",
            "loading data for user 011 on the ZX plane ... √\n",
            "loading data for user 012 on the ZX plane ... √\n",
            "loading data for user 013 on the ZX plane ... √\n",
            "loading data for user 014 on the ZX plane ... √\n",
            "loading data for user 015 on the ZX plane ... √\n",
            "loading data for user 016 on the ZX plane ... √\n",
            "loading data for user 017 on the ZX plane ... √\n",
            "loading data for user 018 on the ZX plane ... √\n",
            "loading data for user 019 on the ZX plane ... √\n",
            "loading data for user 020 on the ZX plane ... √\n",
            "loading data for user 021 on the ZX plane ... √\n",
            "loading data for user 022 on the ZX plane ... √\n",
            "loading data for user 023 on the ZX plane ... √\n",
            "loading data for user 024 on the ZX plane ... √\n",
            "loading data for user 025 on the ZX plane ... √\n",
            "8\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "60/60 [==============================] - 19s 191ms/step - loss: 2.6578 - accuracy: 0.1826 - val_loss: 1.9052 - val_accuracy: 0.5813\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 1.5867 - accuracy: 0.5151 - val_loss: 0.7976 - val_accuracy: 0.8313\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.8769 - accuracy: 0.7320 - val_loss: 0.4515 - val_accuracy: 0.8813\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.6130 - accuracy: 0.8010 - val_loss: 0.3422 - val_accuracy: 0.8500\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.4562 - accuracy: 0.8565 - val_loss: 0.2834 - val_accuracy: 0.9312\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.3464 - accuracy: 0.8930 - val_loss: 0.2477 - val_accuracy: 0.9187\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.3054 - accuracy: 0.8964 - val_loss: 0.2286 - val_accuracy: 0.9125\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.2448 - accuracy: 0.9211 - val_loss: 0.1974 - val_accuracy: 0.9250\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.2230 - accuracy: 0.9294 - val_loss: 0.1850 - val_accuracy: 0.9250\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.1845 - accuracy: 0.9456 - val_loss: 0.1805 - val_accuracy: 0.9312\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1623 - accuracy: 0.9500 - val_loss: 0.1636 - val_accuracy: 0.9438\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1492 - accuracy: 0.9549 - val_loss: 0.1787 - val_accuracy: 0.9187\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1442 - accuracy: 0.9544 - val_loss: 0.1537 - val_accuracy: 0.9500\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1274 - accuracy: 0.9612 - val_loss: 0.1614 - val_accuracy: 0.9250\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1148 - accuracy: 0.9682 - val_loss: 0.1426 - val_accuracy: 0.9563\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1113 - accuracy: 0.9630 - val_loss: 0.1609 - val_accuracy: 0.9312\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0983 - accuracy: 0.9661 - val_loss: 0.1295 - val_accuracy: 0.9500\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0854 - accuracy: 0.9779 - val_loss: 0.1248 - val_accuracy: 0.9500\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0895 - accuracy: 0.9763 - val_loss: 0.1101 - val_accuracy: 0.9625\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0808 - accuracy: 0.9750 - val_loss: 0.1303 - val_accuracy: 0.9438\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0733 - accuracy: 0.9779 - val_loss: 0.1320 - val_accuracy: 0.9375\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0790 - accuracy: 0.9766 - val_loss: 0.1213 - val_accuracy: 0.9563\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0781 - accuracy: 0.9745 - val_loss: 0.1269 - val_accuracy: 0.9563\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0561 - accuracy: 0.9823 - val_loss: 0.1248 - val_accuracy: 0.9563\n",
            "Epoch 25/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.0615 - accuracy: 0.9831 - val_loss: 0.1304 - val_accuracy: 0.9563\n",
            "Epoch 26/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.0604 - accuracy: 0.9802 - val_loss: 0.1284 - val_accuracy: 0.9563\n",
            "Epoch 27/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.0621 - accuracy: 0.9763 - val_loss: 0.1219 - val_accuracy: 0.9500\n",
            "Epoch 28/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.0495 - accuracy: 0.9846 - val_loss: 0.1229 - val_accuracy: 0.9563\n",
            "Epoch 29/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.0535 - accuracy: 0.9833 - val_loss: 0.1146 - val_accuracy: 0.9500\n",
            "Epoch 30/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0511 - accuracy: 0.9844 - val_loss: 0.1119 - val_accuracy: 0.9438\n",
            "Epoch 31/300\n",
            "60/60 [==============================] - 9s 150ms/step - loss: 0.0409 - accuracy: 0.9901 - val_loss: 0.1297 - val_accuracy: 0.9500\n",
            "3/3 [==============================] - 0s 105ms/step - loss: 1.9052 - accuracy: 0.5813\n",
            "58.13 %\n",
            "Processing results for user 003... \n",
            "loading data for user 001 on the XY plane ... √\n",
            "loading data for user 002 on the XY plane ... √\n",
            "loading data for user 003 on the XY plane ... √\n",
            "loading data for user 004 on the XY plane ... √\n",
            "loading data for user 005 on the XY plane ... √\n",
            "loading data for user 006 on the XY plane ... √\n",
            "loading data for user 007 on the XY plane ... √\n",
            "loading data for user 008 on the XY plane ... √\n",
            "loading data for user 009 on the XY plane ... √\n",
            "loading data for user 010 on the XY plane ... √\n",
            "loading data for user 011 on the XY plane ... √\n",
            "loading data for user 012 on the XY plane ... √\n",
            "loading data for user 013 on the XY plane ... √\n",
            "loading data for user 014 on the XY plane ... √\n",
            "loading data for user 015 on the XY plane ... √\n",
            "loading data for user 016 on the XY plane ... √\n",
            "loading data for user 017 on the XY plane ... √\n",
            "loading data for user 018 on the XY plane ... √\n",
            "loading data for user 019 on the XY plane ... √\n",
            "loading data for user 020 on the XY plane ... √\n",
            "loading data for user 021 on the XY plane ... √\n",
            "loading data for user 022 on the XY plane ... √\n",
            "loading data for user 023 on the XY plane ... √\n",
            "loading data for user 024 on the XY plane ... √\n",
            "loading data for user 025 on the XY plane ... √\n",
            "loading data for user 001 on the YZ plane ... √\n",
            "loading data for user 002 on the YZ plane ... √\n",
            "loading data for user 003 on the YZ plane ... √\n",
            "loading data for user 004 on the YZ plane ... √\n",
            "loading data for user 005 on the YZ plane ... √\n",
            "loading data for user 006 on the YZ plane ... √\n",
            "loading data for user 007 on the YZ plane ... √\n",
            "loading data for user 008 on the YZ plane ... √\n",
            "loading data for user 009 on the YZ plane ... √\n",
            "loading data for user 010 on the YZ plane ... √\n",
            "loading data for user 011 on the YZ plane ... √\n",
            "loading data for user 012 on the YZ plane ... √\n",
            "loading data for user 013 on the YZ plane ... √\n",
            "loading data for user 014 on the YZ plane ... √\n",
            "loading data for user 015 on the YZ plane ... √\n",
            "loading data for user 016 on the YZ plane ... √\n",
            "loading data for user 017 on the YZ plane ... √\n",
            "loading data for user 018 on the YZ plane ... √\n",
            "loading data for user 019 on the YZ plane ... √\n",
            "loading data for user 020 on the YZ plane ... √\n",
            "loading data for user 021 on the YZ plane ... √\n",
            "loading data for user 022 on the YZ plane ... √\n",
            "loading data for user 023 on the YZ plane ... √\n",
            "loading data for user 024 on the YZ plane ... √\n",
            "loading data for user 025 on the YZ plane ... √\n",
            "loading data for user 001 on the ZX plane ... √\n",
            "loading data for user 002 on the ZX plane ... √\n",
            "loading data for user 003 on the ZX plane ... √\n",
            "loading data for user 004 on the ZX plane ... √\n",
            "loading data for user 005 on the ZX plane ... √\n",
            "loading data for user 006 on the ZX plane ... √\n",
            "loading data for user 007 on the ZX plane ... √\n",
            "loading data for user 008 on the ZX plane ... √\n",
            "loading data for user 009 on the ZX plane ... √\n",
            "loading data for user 010 on the ZX plane ... √\n",
            "loading data for user 011 on the ZX plane ... √\n",
            "loading data for user 012 on the ZX plane ... √\n",
            "loading data for user 013 on the ZX plane ... √\n",
            "loading data for user 014 on the ZX plane ... √\n",
            "loading data for user 015 on the ZX plane ... √\n",
            "loading data for user 016 on the ZX plane ... √\n",
            "loading data for user 017 on the ZX plane ... √\n",
            "loading data for user 018 on the ZX plane ... √\n",
            "loading data for user 019 on the ZX plane ... √\n",
            "loading data for user 020 on the ZX plane ... √\n",
            "loading data for user 021 on the ZX plane ... √\n",
            "loading data for user 022 on the ZX plane ... √\n",
            "loading data for user 023 on the ZX plane ... √\n",
            "loading data for user 024 on the ZX plane ... √\n",
            "loading data for user 025 on the ZX plane ... √\n",
            "8\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "60/60 [==============================] - 19s 199ms/step - loss: 2.6302 - accuracy: 0.2057 - val_loss: 1.6259 - val_accuracy: 0.7125\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 1.4997 - accuracy: 0.5312 - val_loss: 0.6630 - val_accuracy: 0.9062\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 9s 146ms/step - loss: 0.8784 - accuracy: 0.7263 - val_loss: 0.3244 - val_accuracy: 0.9500\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.5736 - accuracy: 0.8292 - val_loss: 0.1915 - val_accuracy: 0.9688\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.4162 - accuracy: 0.8747 - val_loss: 0.1411 - val_accuracy: 0.9625\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.3493 - accuracy: 0.8951 - val_loss: 0.1146 - val_accuracy: 0.9812\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.2833 - accuracy: 0.9094 - val_loss: 0.0830 - val_accuracy: 0.9750\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.2351 - accuracy: 0.9253 - val_loss: 0.0750 - val_accuracy: 0.9812\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.2070 - accuracy: 0.9292 - val_loss: 0.0673 - val_accuracy: 0.9812\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1922 - accuracy: 0.9396 - val_loss: 0.0640 - val_accuracy: 0.9875\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.1629 - accuracy: 0.9474 - val_loss: 0.0468 - val_accuracy: 0.9937\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.1500 - accuracy: 0.9529 - val_loss: 0.0569 - val_accuracy: 0.9812\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1358 - accuracy: 0.9596 - val_loss: 0.0406 - val_accuracy: 0.9875\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.1221 - accuracy: 0.9591 - val_loss: 0.0354 - val_accuracy: 0.9937\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1181 - accuracy: 0.9654 - val_loss: 0.0375 - val_accuracy: 0.9937\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1153 - accuracy: 0.9609 - val_loss: 0.0344 - val_accuracy: 0.9937\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1005 - accuracy: 0.9659 - val_loss: 0.0355 - val_accuracy: 0.9937\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.0863 - accuracy: 0.9745 - val_loss: 0.0369 - val_accuracy: 0.9937\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0846 - accuracy: 0.9724 - val_loss: 0.0326 - val_accuracy: 0.9937\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0816 - accuracy: 0.9771 - val_loss: 0.0301 - val_accuracy: 0.9937\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0716 - accuracy: 0.9773 - val_loss: 0.0429 - val_accuracy: 0.9812\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0760 - accuracy: 0.9776 - val_loss: 0.0419 - val_accuracy: 0.9875\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0767 - accuracy: 0.9773 - val_loss: 0.0277 - val_accuracy: 0.9937\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0746 - accuracy: 0.9771 - val_loss: 0.0306 - val_accuracy: 0.9875\n",
            "Epoch 25/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0636 - accuracy: 0.9797 - val_loss: 0.0311 - val_accuracy: 0.9937\n",
            "Epoch 26/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.0587 - accuracy: 0.9805 - val_loss: 0.0289 - val_accuracy: 0.9937\n",
            "Epoch 27/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0595 - accuracy: 0.9812 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
            "Epoch 28/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0517 - accuracy: 0.9849 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
            "Epoch 29/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0516 - accuracy: 0.9846 - val_loss: 0.0353 - val_accuracy: 0.9875\n",
            "Epoch 30/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0480 - accuracy: 0.9870 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
            "Epoch 31/300\n",
            "60/60 [==============================] - 9s 151ms/step - loss: 0.0480 - accuracy: 0.9846 - val_loss: 0.0217 - val_accuracy: 0.9937\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 1.6259 - accuracy: 0.7125\n",
            "71.25 %\n",
            "Processing results for user 004... \n",
            "loading data for user 001 on the XY plane ... √\n",
            "loading data for user 002 on the XY plane ... √\n",
            "loading data for user 003 on the XY plane ... √\n",
            "loading data for user 004 on the XY plane ... √\n",
            "loading data for user 005 on the XY plane ... √\n",
            "loading data for user 006 on the XY plane ... √\n",
            "loading data for user 007 on the XY plane ... √\n",
            "loading data for user 008 on the XY plane ... √\n",
            "loading data for user 009 on the XY plane ... √\n",
            "loading data for user 010 on the XY plane ... √\n",
            "loading data for user 011 on the XY plane ... √\n",
            "loading data for user 012 on the XY plane ... √\n",
            "loading data for user 013 on the XY plane ... √\n",
            "loading data for user 014 on the XY plane ... √\n",
            "loading data for user 015 on the XY plane ... √\n",
            "loading data for user 016 on the XY plane ... √\n",
            "loading data for user 017 on the XY plane ... √\n",
            "loading data for user 018 on the XY plane ... √\n",
            "loading data for user 019 on the XY plane ... √\n",
            "loading data for user 020 on the XY plane ... √\n",
            "loading data for user 021 on the XY plane ... √\n",
            "loading data for user 022 on the XY plane ... √\n",
            "loading data for user 023 on the XY plane ... √\n",
            "loading data for user 024 on the XY plane ... √\n",
            "loading data for user 025 on the XY plane ... √\n",
            "loading data for user 001 on the YZ plane ... √\n",
            "loading data for user 002 on the YZ plane ... √\n",
            "loading data for user 003 on the YZ plane ... √\n",
            "loading data for user 004 on the YZ plane ... √\n",
            "loading data for user 005 on the YZ plane ... √\n",
            "loading data for user 006 on the YZ plane ... √\n",
            "loading data for user 007 on the YZ plane ... √\n",
            "loading data for user 008 on the YZ plane ... √\n",
            "loading data for user 009 on the YZ plane ... √\n",
            "loading data for user 010 on the YZ plane ... √\n",
            "loading data for user 011 on the YZ plane ... √\n",
            "loading data for user 012 on the YZ plane ... √\n",
            "loading data for user 013 on the YZ plane ... √\n",
            "loading data for user 014 on the YZ plane ... √\n",
            "loading data for user 015 on the YZ plane ... √\n",
            "loading data for user 016 on the YZ plane ... √\n",
            "loading data for user 017 on the YZ plane ... √\n",
            "loading data for user 018 on the YZ plane ... √\n",
            "loading data for user 019 on the YZ plane ... √\n",
            "loading data for user 020 on the YZ plane ... √\n",
            "loading data for user 021 on the YZ plane ... √\n",
            "loading data for user 022 on the YZ plane ... √\n",
            "loading data for user 023 on the YZ plane ... √\n",
            "loading data for user 024 on the YZ plane ... √\n",
            "loading data for user 025 on the YZ plane ... √\n",
            "loading data for user 001 on the ZX plane ... √\n",
            "loading data for user 002 on the ZX plane ... √\n",
            "loading data for user 003 on the ZX plane ... √\n",
            "loading data for user 004 on the ZX plane ... √\n",
            "loading data for user 005 on the ZX plane ... √\n",
            "loading data for user 006 on the ZX plane ... √\n",
            "loading data for user 007 on the ZX plane ... √\n",
            "loading data for user 008 on the ZX plane ... √\n",
            "loading data for user 009 on the ZX plane ... √\n",
            "loading data for user 010 on the ZX plane ... √\n",
            "loading data for user 011 on the ZX plane ... √\n",
            "loading data for user 012 on the ZX plane ... √\n",
            "loading data for user 013 on the ZX plane ... √\n",
            "loading data for user 014 on the ZX plane ... √\n",
            "loading data for user 015 on the ZX plane ... √\n",
            "loading data for user 016 on the ZX plane ... √\n",
            "loading data for user 017 on the ZX plane ... √\n",
            "loading data for user 018 on the ZX plane ... √\n",
            "loading data for user 019 on the ZX plane ... √\n",
            "loading data for user 020 on the ZX plane ... √\n",
            "loading data for user 021 on the ZX plane ... √\n",
            "loading data for user 022 on the ZX plane ... √\n",
            "loading data for user 023 on the ZX plane ... √\n",
            "loading data for user 024 on the ZX plane ... √\n",
            "loading data for user 025 on the ZX plane ... √\n",
            "8\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "60/60 [==============================] - 19s 192ms/step - loss: 2.5469 - accuracy: 0.2234 - val_loss: 2.2195 - val_accuracy: 0.3063\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 1.4783 - accuracy: 0.5404 - val_loss: 1.9083 - val_accuracy: 0.4313\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.8743 - accuracy: 0.7289 - val_loss: 1.7660 - val_accuracy: 0.4875\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 9s 146ms/step - loss: 0.5553 - accuracy: 0.8260 - val_loss: 1.6629 - val_accuracy: 0.5688\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.4232 - accuracy: 0.8635 - val_loss: 1.6248 - val_accuracy: 0.6000\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.3149 - accuracy: 0.8995 - val_loss: 1.6777 - val_accuracy: 0.6000\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.2804 - accuracy: 0.9117 - val_loss: 1.6451 - val_accuracy: 0.6187\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.2377 - accuracy: 0.9234 - val_loss: 1.5282 - val_accuracy: 0.6438\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.1934 - accuracy: 0.9385 - val_loss: 1.5868 - val_accuracy: 0.6438\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1826 - accuracy: 0.9411 - val_loss: 1.6263 - val_accuracy: 0.6125\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.1583 - accuracy: 0.9503 - val_loss: 1.6825 - val_accuracy: 0.6062\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.1448 - accuracy: 0.9542 - val_loss: 1.7959 - val_accuracy: 0.5875\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1213 - accuracy: 0.9664 - val_loss: 1.7902 - val_accuracy: 0.5750\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1153 - accuracy: 0.9643 - val_loss: 1.8514 - val_accuracy: 0.6000\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1048 - accuracy: 0.9690 - val_loss: 1.8383 - val_accuracy: 0.5688\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0964 - accuracy: 0.9716 - val_loss: 1.9051 - val_accuracy: 0.5562\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.1038 - accuracy: 0.9685 - val_loss: 1.9622 - val_accuracy: 0.5500\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0883 - accuracy: 0.9740 - val_loss: 1.9563 - val_accuracy: 0.5500\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.0836 - accuracy: 0.9742 - val_loss: 1.9578 - val_accuracy: 0.5562\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0657 - accuracy: 0.9802 - val_loss: 2.1029 - val_accuracy: 0.5625\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0738 - accuracy: 0.9745 - val_loss: 2.1272 - val_accuracy: 0.5688\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.0760 - accuracy: 0.9760 - val_loss: 2.0021 - val_accuracy: 0.5688\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0615 - accuracy: 0.9826 - val_loss: 2.0191 - val_accuracy: 0.5625\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.0753 - accuracy: 0.9766 - val_loss: 2.0165 - val_accuracy: 0.5625\n",
            "Epoch 25/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.0645 - accuracy: 0.9786 - val_loss: 2.1746 - val_accuracy: 0.5500\n",
            "Epoch 26/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0564 - accuracy: 0.9833 - val_loss: 2.1349 - val_accuracy: 0.5562\n",
            "Epoch 27/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0502 - accuracy: 0.9846 - val_loss: 2.1487 - val_accuracy: 0.5437\n",
            "Epoch 28/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0499 - accuracy: 0.9862 - val_loss: 2.2384 - val_accuracy: 0.5625\n",
            "Epoch 29/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0531 - accuracy: 0.9833 - val_loss: 2.2281 - val_accuracy: 0.5375\n",
            "Epoch 30/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0480 - accuracy: 0.9859 - val_loss: 2.1117 - val_accuracy: 0.5500\n",
            "Epoch 31/300\n",
            "60/60 [==============================] - 9s 150ms/step - loss: 0.0465 - accuracy: 0.9862 - val_loss: 2.0992 - val_accuracy: 0.5500\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 2.2195 - accuracy: 0.3063\n",
            "30.63 %\n",
            "Processing results for user 005... \n",
            "loading data for user 001 on the XY plane ... √\n",
            "loading data for user 002 on the XY plane ... √\n",
            "loading data for user 003 on the XY plane ... √\n",
            "loading data for user 004 on the XY plane ... √\n",
            "loading data for user 005 on the XY plane ... √\n",
            "loading data for user 006 on the XY plane ... √\n",
            "loading data for user 007 on the XY plane ... √\n",
            "loading data for user 008 on the XY plane ... √\n",
            "loading data for user 009 on the XY plane ... √\n",
            "loading data for user 010 on the XY plane ... √\n",
            "loading data for user 011 on the XY plane ... √\n",
            "loading data for user 012 on the XY plane ... √\n",
            "loading data for user 013 on the XY plane ... √\n",
            "loading data for user 014 on the XY plane ... √\n",
            "loading data for user 015 on the XY plane ... √\n",
            "loading data for user 016 on the XY plane ... √\n",
            "loading data for user 017 on the XY plane ... √\n",
            "loading data for user 018 on the XY plane ... √\n",
            "loading data for user 019 on the XY plane ... √\n",
            "loading data for user 020 on the XY plane ... √\n",
            "loading data for user 021 on the XY plane ... √\n",
            "loading data for user 022 on the XY plane ... √\n",
            "loading data for user 023 on the XY plane ... √\n",
            "loading data for user 024 on the XY plane ... √\n",
            "loading data for user 025 on the XY plane ... √\n",
            "loading data for user 001 on the YZ plane ... √\n",
            "loading data for user 002 on the YZ plane ... √\n",
            "loading data for user 003 on the YZ plane ... √\n",
            "loading data for user 004 on the YZ plane ... √\n",
            "loading data for user 005 on the YZ plane ... √\n",
            "loading data for user 006 on the YZ plane ... √\n",
            "loading data for user 007 on the YZ plane ... √\n",
            "loading data for user 008 on the YZ plane ... √\n",
            "loading data for user 009 on the YZ plane ... √\n",
            "loading data for user 010 on the YZ plane ... √\n",
            "loading data for user 011 on the YZ plane ... √\n",
            "loading data for user 012 on the YZ plane ... √\n",
            "loading data for user 013 on the YZ plane ... √\n",
            "loading data for user 014 on the YZ plane ... √\n",
            "loading data for user 015 on the YZ plane ... √\n",
            "loading data for user 016 on the YZ plane ... √\n",
            "loading data for user 017 on the YZ plane ... √\n",
            "loading data for user 018 on the YZ plane ... √\n",
            "loading data for user 019 on the YZ plane ... √\n",
            "loading data for user 020 on the YZ plane ... √\n",
            "loading data for user 021 on the YZ plane ... √\n",
            "loading data for user 022 on the YZ plane ... √\n",
            "loading data for user 023 on the YZ plane ... √\n",
            "loading data for user 024 on the YZ plane ... √\n",
            "loading data for user 025 on the YZ plane ... √\n",
            "loading data for user 001 on the ZX plane ... √\n",
            "loading data for user 002 on the ZX plane ... √\n",
            "loading data for user 003 on the ZX plane ... √\n",
            "loading data for user 004 on the ZX plane ... √\n",
            "loading data for user 005 on the ZX plane ... √\n",
            "loading data for user 006 on the ZX plane ... √\n",
            "loading data for user 007 on the ZX plane ... √\n",
            "loading data for user 008 on the ZX plane ... √\n",
            "loading data for user 009 on the ZX plane ... √\n",
            "loading data for user 010 on the ZX plane ... √\n",
            "loading data for user 011 on the ZX plane ... √\n",
            "loading data for user 012 on the ZX plane ... √\n",
            "loading data for user 013 on the ZX plane ... √\n",
            "loading data for user 014 on the ZX plane ... √\n",
            "loading data for user 015 on the ZX plane ... √\n",
            "loading data for user 016 on the ZX plane ... √\n",
            "loading data for user 017 on the ZX plane ... √\n",
            "loading data for user 018 on the ZX plane ... √\n",
            "loading data for user 019 on the ZX plane ... √\n",
            "loading data for user 020 on the ZX plane ... √\n",
            "loading data for user 021 on the ZX plane ... √\n",
            "loading data for user 022 on the ZX plane ... √\n",
            "loading data for user 023 on the ZX plane ... √\n",
            "loading data for user 024 on the ZX plane ... √\n",
            "loading data for user 025 on the ZX plane ... √\n",
            "8\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "60/60 [==============================] - 19s 188ms/step - loss: 2.6355 - accuracy: 0.2039 - val_loss: 1.7919 - val_accuracy: 0.5625\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 9s 146ms/step - loss: 1.5351 - accuracy: 0.5195 - val_loss: 0.9822 - val_accuracy: 0.7437\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.8771 - accuracy: 0.7203 - val_loss: 0.6028 - val_accuracy: 0.8250\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 9s 146ms/step - loss: 0.5415 - accuracy: 0.8294 - val_loss: 0.4632 - val_accuracy: 0.8438\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 9s 146ms/step - loss: 0.4199 - accuracy: 0.8674 - val_loss: 0.3723 - val_accuracy: 0.8813\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 9s 146ms/step - loss: 0.3077 - accuracy: 0.9039 - val_loss: 0.3815 - val_accuracy: 0.8687\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.2697 - accuracy: 0.9151 - val_loss: 0.3298 - val_accuracy: 0.8562\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.2326 - accuracy: 0.9242 - val_loss: 0.2891 - val_accuracy: 0.8875\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.2039 - accuracy: 0.9370 - val_loss: 0.2636 - val_accuracy: 0.8938\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.1744 - accuracy: 0.9461 - val_loss: 0.2870 - val_accuracy: 0.9062\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1615 - accuracy: 0.9513 - val_loss: 0.2529 - val_accuracy: 0.8938\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.1477 - accuracy: 0.9536 - val_loss: 0.2304 - val_accuracy: 0.9125\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1353 - accuracy: 0.9602 - val_loss: 0.2824 - val_accuracy: 0.8938\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1250 - accuracy: 0.9607 - val_loss: 0.2348 - val_accuracy: 0.9187\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.1073 - accuracy: 0.9677 - val_loss: 0.2224 - val_accuracy: 0.9000\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.1044 - accuracy: 0.9680 - val_loss: 0.2073 - val_accuracy: 0.9187\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.1086 - accuracy: 0.9648 - val_loss: 0.2349 - val_accuracy: 0.9125\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.0824 - accuracy: 0.9753 - val_loss: 0.2095 - val_accuracy: 0.9062\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0786 - accuracy: 0.9776 - val_loss: 0.2156 - val_accuracy: 0.9062\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0744 - accuracy: 0.9792 - val_loss: 0.2263 - val_accuracy: 0.9062\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0624 - accuracy: 0.9818 - val_loss: 0.2062 - val_accuracy: 0.8938\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0716 - accuracy: 0.9786 - val_loss: 0.2174 - val_accuracy: 0.9062\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0692 - accuracy: 0.9802 - val_loss: 0.1922 - val_accuracy: 0.9187\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0624 - accuracy: 0.9797 - val_loss: 0.2148 - val_accuracy: 0.9187\n",
            "Epoch 25/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.0554 - accuracy: 0.9826 - val_loss: 0.2053 - val_accuracy: 0.9000\n",
            "Epoch 26/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0548 - accuracy: 0.9828 - val_loss: 0.2048 - val_accuracy: 0.9125\n",
            "Epoch 27/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.0554 - accuracy: 0.9836 - val_loss: 0.2060 - val_accuracy: 0.9062\n",
            "Epoch 28/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0556 - accuracy: 0.9831 - val_loss: 0.2230 - val_accuracy: 0.9062\n",
            "Epoch 29/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0429 - accuracy: 0.9859 - val_loss: 0.2127 - val_accuracy: 0.9250\n",
            "Epoch 30/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0480 - accuracy: 0.9852 - val_loss: 0.1730 - val_accuracy: 0.9187\n",
            "Epoch 31/300\n",
            "60/60 [==============================] - 9s 150ms/step - loss: 0.0390 - accuracy: 0.9906 - val_loss: 0.1937 - val_accuracy: 0.9125\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 1.7919 - accuracy: 0.5625\n",
            "56.25 %\n",
            "Processing results for user 006... \n",
            "loading data for user 001 on the XY plane ... √\n",
            "loading data for user 002 on the XY plane ... √\n",
            "loading data for user 003 on the XY plane ... √\n",
            "loading data for user 004 on the XY plane ... √\n",
            "loading data for user 005 on the XY plane ... √\n",
            "loading data for user 006 on the XY plane ... √\n",
            "loading data for user 007 on the XY plane ... √\n",
            "loading data for user 008 on the XY plane ... √\n",
            "loading data for user 009 on the XY plane ... √\n",
            "loading data for user 010 on the XY plane ... √\n",
            "loading data for user 011 on the XY plane ... √\n",
            "loading data for user 012 on the XY plane ... √\n",
            "loading data for user 013 on the XY plane ... √\n",
            "loading data for user 014 on the XY plane ... √\n",
            "loading data for user 015 on the XY plane ... √\n",
            "loading data for user 016 on the XY plane ... √\n",
            "loading data for user 017 on the XY plane ... √\n",
            "loading data for user 018 on the XY plane ... √\n",
            "loading data for user 019 on the XY plane ... √\n",
            "loading data for user 020 on the XY plane ... √\n",
            "loading data for user 021 on the XY plane ... √\n",
            "loading data for user 022 on the XY plane ... √\n",
            "loading data for user 023 on the XY plane ... √\n",
            "loading data for user 024 on the XY plane ... √\n",
            "loading data for user 025 on the XY plane ... √\n",
            "loading data for user 001 on the YZ plane ... √\n",
            "loading data for user 002 on the YZ plane ... √\n",
            "loading data for user 003 on the YZ plane ... √\n",
            "loading data for user 004 on the YZ plane ... √\n",
            "loading data for user 005 on the YZ plane ... √\n",
            "loading data for user 006 on the YZ plane ... √\n",
            "loading data for user 007 on the YZ plane ... √\n",
            "loading data for user 008 on the YZ plane ... √\n",
            "loading data for user 009 on the YZ plane ... √\n",
            "loading data for user 010 on the YZ plane ... √\n",
            "loading data for user 011 on the YZ plane ... √\n",
            "loading data for user 012 on the YZ plane ... √\n",
            "loading data for user 013 on the YZ plane ... √\n",
            "loading data for user 014 on the YZ plane ... √\n",
            "loading data for user 015 on the YZ plane ... √\n",
            "loading data for user 016 on the YZ plane ... √\n",
            "loading data for user 017 on the YZ plane ... √\n",
            "loading data for user 018 on the YZ plane ... √\n",
            "loading data for user 019 on the YZ plane ... √\n",
            "loading data for user 020 on the YZ plane ... √\n",
            "loading data for user 021 on the YZ plane ... √\n",
            "loading data for user 022 on the YZ plane ... √\n",
            "loading data for user 023 on the YZ plane ... √\n",
            "loading data for user 024 on the YZ plane ... √\n",
            "loading data for user 025 on the YZ plane ... √\n",
            "loading data for user 001 on the ZX plane ... √\n",
            "loading data for user 002 on the ZX plane ... √\n",
            "loading data for user 003 on the ZX plane ... √\n",
            "loading data for user 004 on the ZX plane ... √\n",
            "loading data for user 005 on the ZX plane ... √\n",
            "loading data for user 006 on the ZX plane ... √\n",
            "loading data for user 007 on the ZX plane ... √\n",
            "loading data for user 008 on the ZX plane ... √\n",
            "loading data for user 009 on the ZX plane ... √\n",
            "loading data for user 010 on the ZX plane ... √\n",
            "loading data for user 011 on the ZX plane ... √\n",
            "loading data for user 012 on the ZX plane ... √\n",
            "loading data for user 013 on the ZX plane ... √\n",
            "loading data for user 014 on the ZX plane ... √\n",
            "loading data for user 015 on the ZX plane ... √\n",
            "loading data for user 016 on the ZX plane ... √\n",
            "loading data for user 017 on the ZX plane ... √\n",
            "loading data for user 018 on the ZX plane ... √\n",
            "loading data for user 019 on the ZX plane ... √\n",
            "loading data for user 020 on the ZX plane ... √\n",
            "loading data for user 021 on the ZX plane ... √\n",
            "loading data for user 022 on the ZX plane ... √\n",
            "loading data for user 023 on the ZX plane ... √\n",
            "loading data for user 024 on the ZX plane ... √\n",
            "loading data for user 025 on the ZX plane ... √\n",
            "8\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "60/60 [==============================] - 19s 190ms/step - loss: 2.6605 - accuracy: 0.1937 - val_loss: 1.6639 - val_accuracy: 0.6750\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 1.5896 - accuracy: 0.5065 - val_loss: 0.8929 - val_accuracy: 0.7625\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 9s 147ms/step - loss: 0.8958 - accuracy: 0.7240 - val_loss: 0.6853 - val_accuracy: 0.7625\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.5671 - accuracy: 0.8208 - val_loss: 0.6333 - val_accuracy: 0.7812\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.4131 - accuracy: 0.8711 - val_loss: 0.5807 - val_accuracy: 0.8062\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.3315 - accuracy: 0.8888 - val_loss: 0.4767 - val_accuracy: 0.8562\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.2817 - accuracy: 0.9102 - val_loss: 0.4922 - val_accuracy: 0.8687\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.2210 - accuracy: 0.9276 - val_loss: 0.4605 - val_accuracy: 0.8750\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.2071 - accuracy: 0.9328 - val_loss: 0.4278 - val_accuracy: 0.8813\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1693 - accuracy: 0.9477 - val_loss: 0.4051 - val_accuracy: 0.8813\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1594 - accuracy: 0.9513 - val_loss: 0.4046 - val_accuracy: 0.8938\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 9s 150ms/step - loss: 0.1408 - accuracy: 0.9552 - val_loss: 0.4423 - val_accuracy: 0.8875\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 9s 150ms/step - loss: 0.1299 - accuracy: 0.9604 - val_loss: 0.4219 - val_accuracy: 0.9000\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.1211 - accuracy: 0.9609 - val_loss: 0.3912 - val_accuracy: 0.8938\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1035 - accuracy: 0.9693 - val_loss: 0.3727 - val_accuracy: 0.8938\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0992 - accuracy: 0.9701 - val_loss: 0.4177 - val_accuracy: 0.9000\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.0938 - accuracy: 0.9703 - val_loss: 0.3923 - val_accuracy: 0.9062\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 11s 176ms/step - loss: 0.0865 - accuracy: 0.9734 - val_loss: 0.3989 - val_accuracy: 0.8938\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 9s 154ms/step - loss: 0.0878 - accuracy: 0.9727 - val_loss: 0.4259 - val_accuracy: 0.9125\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.0761 - accuracy: 0.9773 - val_loss: 0.4215 - val_accuracy: 0.9000\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0733 - accuracy: 0.9753 - val_loss: 0.4024 - val_accuracy: 0.9000\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0713 - accuracy: 0.9773 - val_loss: 0.4050 - val_accuracy: 0.9000\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0715 - accuracy: 0.9763 - val_loss: 0.3794 - val_accuracy: 0.9187\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.0596 - accuracy: 0.9833 - val_loss: 0.4051 - val_accuracy: 0.9000\n",
            "Epoch 25/300\n",
            "60/60 [==============================] - 9s 151ms/step - loss: 0.0508 - accuracy: 0.9870 - val_loss: 0.3819 - val_accuracy: 0.9187\n",
            "Epoch 26/300\n",
            "60/60 [==============================] - 9s 151ms/step - loss: 0.0579 - accuracy: 0.9784 - val_loss: 0.3933 - val_accuracy: 0.9062\n",
            "Epoch 27/300\n",
            "60/60 [==============================] - 9s 151ms/step - loss: 0.0496 - accuracy: 0.9852 - val_loss: 0.3941 - val_accuracy: 0.9125\n",
            "Epoch 28/300\n",
            "60/60 [==============================] - 9s 150ms/step - loss: 0.0529 - accuracy: 0.9831 - val_loss: 0.3984 - val_accuracy: 0.9062\n",
            "Epoch 29/300\n",
            "60/60 [==============================] - 9s 150ms/step - loss: 0.0545 - accuracy: 0.9836 - val_loss: 0.3782 - val_accuracy: 0.9125\n",
            "Epoch 30/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.0415 - accuracy: 0.9878 - val_loss: 0.4030 - val_accuracy: 0.9187\n",
            "Epoch 31/300\n",
            "60/60 [==============================] - 9s 152ms/step - loss: 0.0443 - accuracy: 0.9867 - val_loss: 0.4070 - val_accuracy: 0.9125\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 1.6639 - accuracy: 0.6750\n",
            "67.50 %\n",
            "Processing results for user 007... \n",
            "loading data for user 001 on the XY plane ... √\n",
            "loading data for user 002 on the XY plane ... √\n",
            "loading data for user 003 on the XY plane ... √\n",
            "loading data for user 004 on the XY plane ... √\n",
            "loading data for user 005 on the XY plane ... √\n",
            "loading data for user 006 on the XY plane ... √\n",
            "loading data for user 007 on the XY plane ... √\n",
            "loading data for user 008 on the XY plane ... √\n",
            "loading data for user 009 on the XY plane ... √\n",
            "loading data for user 010 on the XY plane ... √\n",
            "loading data for user 011 on the XY plane ... √\n",
            "loading data for user 012 on the XY plane ... √\n",
            "loading data for user 013 on the XY plane ... √\n",
            "loading data for user 014 on the XY plane ... √\n",
            "loading data for user 015 on the XY plane ... √\n",
            "loading data for user 016 on the XY plane ... √\n",
            "loading data for user 017 on the XY plane ... √\n",
            "loading data for user 018 on the XY plane ... √\n",
            "loading data for user 019 on the XY plane ... √\n",
            "loading data for user 020 on the XY plane ... √\n",
            "loading data for user 021 on the XY plane ... √\n",
            "loading data for user 022 on the XY plane ... √\n",
            "loading data for user 023 on the XY plane ... √\n",
            "loading data for user 024 on the XY plane ... √\n",
            "loading data for user 025 on the XY plane ... √\n",
            "loading data for user 001 on the YZ plane ... √\n",
            "loading data for user 002 on the YZ plane ... √\n",
            "loading data for user 003 on the YZ plane ... √\n",
            "loading data for user 004 on the YZ plane ... √\n",
            "loading data for user 005 on the YZ plane ... √\n",
            "loading data for user 006 on the YZ plane ... √\n",
            "loading data for user 007 on the YZ plane ... √\n",
            "loading data for user 008 on the YZ plane ... √\n",
            "loading data for user 009 on the YZ plane ... √\n",
            "loading data for user 010 on the YZ plane ... √\n",
            "loading data for user 011 on the YZ plane ... √\n",
            "loading data for user 012 on the YZ plane ... √\n",
            "loading data for user 013 on the YZ plane ... √\n",
            "loading data for user 014 on the YZ plane ... √\n",
            "loading data for user 015 on the YZ plane ... √\n",
            "loading data for user 016 on the YZ plane ... √\n",
            "loading data for user 017 on the YZ plane ... √\n",
            "loading data for user 018 on the YZ plane ... √\n",
            "loading data for user 019 on the YZ plane ... √\n",
            "loading data for user 020 on the YZ plane ... √\n",
            "loading data for user 021 on the YZ plane ... √\n",
            "loading data for user 022 on the YZ plane ... √\n",
            "loading data for user 023 on the YZ plane ... √\n",
            "loading data for user 024 on the YZ plane ... √\n",
            "loading data for user 025 on the YZ plane ... √\n",
            "loading data for user 001 on the ZX plane ... √\n",
            "loading data for user 002 on the ZX plane ... √\n",
            "loading data for user 003 on the ZX plane ... √\n",
            "loading data for user 004 on the ZX plane ... √\n",
            "loading data for user 005 on the ZX plane ... √\n",
            "loading data for user 006 on the ZX plane ... √\n",
            "loading data for user 007 on the ZX plane ... √\n",
            "loading data for user 008 on the ZX plane ... √\n",
            "loading data for user 009 on the ZX plane ... √\n",
            "loading data for user 010 on the ZX plane ... √\n",
            "loading data for user 011 on the ZX plane ... √\n",
            "loading data for user 012 on the ZX plane ... √\n",
            "loading data for user 013 on the ZX plane ... √\n",
            "loading data for user 014 on the ZX plane ... √\n",
            "loading data for user 015 on the ZX plane ... √\n",
            "loading data for user 016 on the ZX plane ... √\n",
            "loading data for user 017 on the ZX plane ... √\n",
            "loading data for user 018 on the ZX plane ... √\n",
            "loading data for user 019 on the ZX plane ... √\n",
            "loading data for user 020 on the ZX plane ... √\n",
            "loading data for user 021 on the ZX plane ... √\n",
            "loading data for user 022 on the ZX plane ... √\n",
            "loading data for user 023 on the ZX plane ... √\n",
            "loading data for user 024 on the ZX plane ... √\n",
            "loading data for user 025 on the ZX plane ... √\n",
            "8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "60/60 [==============================] - 19s 191ms/step - loss: 2.6056 - accuracy: 0.2036 - val_loss: 1.7260 - val_accuracy: 0.6250\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 1.6051 - accuracy: 0.5049 - val_loss: 0.8539 - val_accuracy: 0.7875\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.9496 - accuracy: 0.7076 - val_loss: 0.4338 - val_accuracy: 0.9250\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.5911 - accuracy: 0.8182 - val_loss: 0.2577 - val_accuracy: 0.9250\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.4221 - accuracy: 0.8714 - val_loss: 0.1690 - val_accuracy: 0.9563\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.3465 - accuracy: 0.8883 - val_loss: 0.1411 - val_accuracy: 0.9688\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.2817 - accuracy: 0.9125 - val_loss: 0.1142 - val_accuracy: 0.9750\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.2431 - accuracy: 0.9263 - val_loss: 0.1018 - val_accuracy: 0.9750\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.2074 - accuracy: 0.9391 - val_loss: 0.0827 - val_accuracy: 0.9875\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.1810 - accuracy: 0.9417 - val_loss: 0.0732 - val_accuracy: 0.9875\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.1748 - accuracy: 0.9466 - val_loss: 0.0618 - val_accuracy: 0.9875\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1554 - accuracy: 0.9500 - val_loss: 0.0773 - val_accuracy: 0.9875\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.1280 - accuracy: 0.9570 - val_loss: 0.0587 - val_accuracy: 0.9875\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1128 - accuracy: 0.9664 - val_loss: 0.0628 - val_accuracy: 0.9812\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.1115 - accuracy: 0.9680 - val_loss: 0.0541 - val_accuracy: 0.9937\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.1132 - accuracy: 0.9633 - val_loss: 0.0515 - val_accuracy: 0.9937\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.0953 - accuracy: 0.9703 - val_loss: 0.0578 - val_accuracy: 0.9875\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0982 - accuracy: 0.9693 - val_loss: 0.0494 - val_accuracy: 0.9875\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.0865 - accuracy: 0.9742 - val_loss: 0.0457 - val_accuracy: 0.9875\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.0848 - accuracy: 0.9734 - val_loss: 0.0474 - val_accuracy: 0.9937\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0744 - accuracy: 0.9776 - val_loss: 0.0681 - val_accuracy: 0.9750\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.0779 - accuracy: 0.9789 - val_loss: 0.0470 - val_accuracy: 0.9875\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 9s 149ms/step - loss: 0.0748 - accuracy: 0.9753 - val_loss: 0.0435 - val_accuracy: 0.9937\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 9s 150ms/step - loss: 0.0714 - accuracy: 0.9773 - val_loss: 0.0554 - val_accuracy: 0.9812\n",
            "Epoch 25/300\n",
            "43/60 [====================>.........] - ETA: 2s - loss: 0.0594 - accuracy: 0.9836"
          ]
        }
      ],
      "source": [
        "\n",
        "ACC = []\n",
        "logs = ''\n",
        "\n",
        "for test_user in USER:\n",
        "    print('Processing results for user ' + test_user, end='... \\n')\n",
        "    \n",
        "    X_train = []\n",
        "    X_test = []\n",
        "    y_train = []\n",
        "    y_test = []\n",
        "    \n",
        "    first_time_train = True\n",
        "    first_time_test = True\n",
        "\n",
        "    for user in USERS:\n",
        "        x_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_X.joblib')\n",
        "        y_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_y.joblib')\n",
        "        X = joblib.load(x_path)\n",
        "        y = joblib.load(y_path)\n",
        "\n",
        "        if user == test_user:\n",
        "            if first_time_train == True:\n",
        "                first_time_train = False\n",
        "                X_test = X\n",
        "                y_test = y\n",
        "                \n",
        "            else:\n",
        "                X_test = np.append(X_test, X, axis=0)\n",
        "                y_test = np.append(y_test, y, axis=0)\n",
        "                \n",
        "        else:\n",
        "            if first_time_test == True:\n",
        "                first_time_test = False\n",
        "                X_train = X\n",
        "                y_train = y\n",
        "                \n",
        "            else:\n",
        "                X_train = np.append(X_train, X, axis=0)\n",
        "                y_train = np.append(y_train, y, axis=0)\n",
        "\n",
        "\n",
        "    # X_train, y_train = shuffle(X_train, y_train)\n",
        "\n",
        "    X_train_xy, X_test_xy, y_train_xy, y_test_xy = load_data('XY', test_user)\n",
        "    X_train_yz, X_test_yz, y_train_yz, y_test_yz = load_data('YZ', test_user)\n",
        "    X_train_zx, X_test_zx, y_train_zx, y_test_zx = load_data('ZX', test_user)\n",
        "\n",
        "    X_train_xy, X_train_yz, X_train_zx, X_train, y_train = shuffle(\n",
        "        X_train_xy, X_train_yz, X_train_zx, X_train, y_train\n",
        "    )\n",
        "\n",
        "    X_train_combined = [X_train_xy, X_train_yz, X_train_zx]\n",
        "    X_test_combined = [X_test_xy, X_test_yz, X_test_zx]\n",
        "\n",
        "    del X_train_xy, X_test_xy, y_train_xy, y_test_xy\n",
        "    del X_train_yz, X_test_yz, y_train_yz, y_test_yz\n",
        "    del X_train_zx, X_test_zx, y_train_zx, y_test_zx\n",
        "    del X_train, X_test\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    print(len(X_train_combined))\n",
        "\n",
        "    model = get_stacked_model()\n",
        "    model.fit(X_train_combined, y_train, epochs=20, batch_size=64)\n",
        "    _, accuracy = model.evaluate(X_test_combined, y_test, batch_size=64)\n",
        "\n",
        "    accuracy = accuracy * 100\n",
        "    print(f'%.2f %%' %(accuracy))\n",
        "    logs = logs + 'Accuracy for user ' + str(test_user) + '... ' + str(accuracy) + '\\n'\n",
        "    ACC.append(accuracy)\n",
        "    \n",
        "AVG_ACC = np.mean(ACC)\n",
        "STD = np.std(ACC)\n",
        "print('------------------------------------')\n",
        "print(f'Average accuracy %.2f +/- %.2f' %(AVG_ACC, STD))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92fd4333",
      "metadata": {
        "id": "92fd4333"
      },
      "outputs": [],
      "source": [
        "# model = get_stacked_model()\n",
        "# X_train_xy, X_train_yz, X_train_zx, y_train_xy = shuffle(\n",
        "#     X_train_xy, X_train_yz, X_train_zx, y_train_xy\n",
        "# )\n",
        "\n",
        "# history = model.fit(\n",
        "#     [X_train_xy, X_train_yz, X_train_zx],\n",
        "#     y_train_xy,\n",
        "#     validation_data=([X_test_xy, X_test_yz, X_test_zx], y_test_xy),\n",
        "#     batch_size=32,\n",
        "#     epochs=10,\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "distinct-appendix",
      "metadata": {
        "id": "distinct-appendix",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# model_xy = get_model()\n",
        "# X_train_xy, y_train_xy = shuffle(X_train_xy, y_train_xy)\n",
        "# history_xy = model_xy.fit(X_train_xy, y_train_xy, validation_data=(X_test_xy, y_test_xy), epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "constitutional-genre",
      "metadata": {
        "id": "constitutional-genre"
      },
      "outputs": [],
      "source": [
        "# # prob_xy = tf.keras.Sequential([model_xy, tf.keras.layers.Softmax()])\n",
        "# # y_pred_xy = prob_xy.predict(X_test_xy)\n",
        "# y_pred_xy = model_xy.predict(X_test_xy)\n",
        "# y_pred = np.argmax(y_pred_xy, axis=1)\n",
        "# print(classification_report(y_test_xy.ravel(), y_pred, zero_division=0))\n",
        "# prc_xy = precision_score(y_test_xy.ravel(), y_pred, zero_division=0, average=None)\n",
        "# tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "emotional-chrome",
      "metadata": {
        "id": "emotional-chrome"
      },
      "outputs": [],
      "source": [
        "# model_yz = get_model()\n",
        "# X_train_yz, y_train_yz = shuffle(X_train_yz, y_train_yz)\n",
        "# history_yz = model_yz.fit(X_train_yz, y_train_yz, validation_data=(X_test_yz, y_test_yz), epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "boring-insurance",
      "metadata": {
        "id": "boring-insurance"
      },
      "outputs": [],
      "source": [
        "# # prob_yz = tf.keras.Sequential([model_yz, tf.keras.layers.Softmax()])\n",
        "# # y_pred_yz = prob_yz.predict(X_test_yz)\n",
        "# y_pred_yz = model_yz.predict(X_test_yz)\n",
        "# y_pred = np.argmax(y_pred_yz, axis=1)\n",
        "# print(classification_report(y_test_yz.ravel(), y_pred, zero_division=0))\n",
        "# prc_yz = precision_score(y_test_yz.ravel(), y_pred, zero_division=0, average=None)\n",
        "# tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "joint-evaluation",
      "metadata": {
        "id": "joint-evaluation"
      },
      "outputs": [],
      "source": [
        "# model_zx = get_model()\n",
        "# X_train_zx, y_train_zx = shuffle(X_train_zx, y_train_zx)\n",
        "# history_zx = model_zx.fit(X_train_zx, y_train_zx, validation_data=(X_test_zx, y_test_zx), epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "designed-still",
      "metadata": {
        "id": "designed-still"
      },
      "outputs": [],
      "source": [
        "# # prob_zx = tf.keras.Sequential([model_zx, tf.keras.layers.Softmax()])\n",
        "# # y_pred_zx = prob_zx.predict(X_test_zx)\n",
        "# y_pred_zx = model_zx.predict(X_test_zx)\n",
        "# y_pred = np.argmax(y_pred_zx, axis=1)\n",
        "# print(classification_report(y_test_zx.ravel(), y_pred, zero_division=0))\n",
        "# prc_zx = precision_score(y_test_zx.ravel(), y_pred, zero_division=0, average=None)\n",
        "# tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "selective-geography",
      "metadata": {
        "id": "selective-geography"
      },
      "outputs": [],
      "source": [
        "# y_total = y_pred_xy + y_pred_yz + y_pred_zx\n",
        "# y_pred = np.argmax(y_total, axis=1)\n",
        "# report = classification_report(y_test_xy.ravel(), y_pred, zero_division=0)\n",
        "# print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collected-palmer",
      "metadata": {
        "id": "collected-palmer"
      },
      "outputs": [],
      "source": [
        "# config = '\\n\\nTEST_USER ' + TEST_USER + ' T: ' + str(int(time.time())) + '\\n'\n",
        "# underline = '=====================================\\n'\n",
        "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
        "# if not os.path.exists(log_dir):\n",
        "#     os.mkdir(log_dir)\n",
        "# f = open(os.path.join(log_dir, 'logs_sptl_bw' + CONFIG + '.txt'), 'a')\n",
        "# f.write(config)\n",
        "# f.write(underline)\n",
        "# f.write(report)\n",
        "# f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "intellectual-lunch",
      "metadata": {
        "id": "intellectual-lunch"
      },
      "outputs": [],
      "source": [
        "# config = TEST_USER + ' :'\n",
        "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
        "# if not os.path.exists(log_dir):\n",
        "#     os.mkdir(log_dir)\n",
        "# f = open(os.path.join(log_dir, 'prc_sptl_bw_xy' + CONFIG + '.txt'), 'a')\n",
        "# f.write(config)\n",
        "# f.write(np.array2string(prc_xy, precision=2, max_line_width=100) + '\\n')\n",
        "# f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "trying-thread",
      "metadata": {
        "id": "trying-thread"
      },
      "outputs": [],
      "source": [
        "# config = TEST_USER + ' :'\n",
        "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
        "# if not os.path.exists(log_dir):\n",
        "#     os.mkdir(log_dir)\n",
        "# f = open(os.path.join(log_dir, 'prc_sptl_bw_yz' + CONFIG + '.txt'), 'a')\n",
        "# f.write(config)\n",
        "# f.write(np.array2string(prc_yz, precision=2, max_line_width=100) + '\\n')\n",
        "# f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "general-plant",
      "metadata": {
        "id": "general-plant"
      },
      "outputs": [],
      "source": [
        "# config = TEST_USER + ' :'\n",
        "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
        "# if not os.path.exists(log_dir):\n",
        "#     os.mkdir(log_dir)\n",
        "# f = open(os.path.join(log_dir, 'prc_sptl_bw_zx' + CONFIG + '.txt'), 'a')\n",
        "# f.write(config)\n",
        "# f.write(np.array2string(prc_zx, precision=2, max_line_width=100) + '\\n')\n",
        "# f.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Spatial_Path_Transfer_Learning_BW.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}