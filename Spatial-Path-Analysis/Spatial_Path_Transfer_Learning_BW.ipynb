{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tamil-chrome",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "tamil-chrome",
    "outputId": "cdcbac02-d4f9-47b5-bc44-0dfdcffa8a50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, GlobalAvgPool2D, Dropout, concatenate\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "MfafORnwZkyT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MfafORnwZkyT",
    "outputId": "4ec0451e-a896-42a7-b0ab-e00a09bcc158"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "casual-stack",
   "metadata": {
    "id": "casual-stack"
   },
   "outputs": [],
   "source": [
    "# -------- TEST USER ----------- #\n",
    "\n",
    "TEST_USER      = '004'\n",
    "\n",
    "BASE_DIR       = '../Dataset/'\n",
    "\n",
    "# Google Drive\n",
    "# BASE_DIR       = '/content/drive/MyDrive/Research/Hand Gesture/GitHub/'\n",
    "\n",
    "IMG_DIR        = 'BW-Spatial-Path-Images/'\n",
    "LOG_DIR        = 'Logs/'\n",
    "\n",
    "USERS          = ['001', '002', '003', '004', '005', '006', '007', '008', '009',\n",
    "                  '010', '011', '012', '013', '014', '015', '016', '017', '018',\n",
    "                  '019', '020', '021', '022', '023', '024', '025']\n",
    "\n",
    "# ------------------------------- Only Dynalic Gestures ------------------------------ #\n",
    "GESTURES       = ['j', 'z', 'bad', 'deaf', 'fine', 'good', 'goodbye', 'hello', 'hungry',\n",
    "                  'me', 'no', 'please', 'sorry', 'thankyou', 'yes', 'you']\n",
    "\n",
    "PLANES         = ['XY', 'YZ', 'ZX']\n",
    "\n",
    "BATCH_SIZE     = 32\n",
    "IMG_LEN        = 160\n",
    "IMG_SIZE       = (IMG_LEN, IMG_LEN)\n",
    "\n",
    "# ------------- FOR THE GREATER GOOD :) ------------- #\n",
    "DATASET_LEN    = 4000\n",
    "TRAIN_LEN      = 3840\n",
    "TEST_LEN       = 160\n",
    "\n",
    "EPOCHS         = 50\n",
    "LEARNING_RATE  = 0.001\n",
    "DECAY          = 0.0\n",
    "\n",
    "CONFIG         = '_L_7_S_160x160_E_7'\n",
    "\n",
    "XY_WEIGHTS     = np.array([0.91, 0.75, 0.61, 0.63, 0.51, 0.66, 0.81, 0.65, 0.65, 0.31,\n",
    "                           0.66, 0.29, 0.34, 0.64, 0.64, 0.31])\n",
    "YZ_WEIGHTS     = np.array([0.73, 0.71, 0.70, 0.79, 0.76, 0.38, 0.80, 0.61, 0.58, 0.73,\n",
    "                           0.49, 0.26, 0.26, 0.52, 0.59, 0.54])\n",
    "ZX_WEIGHTS     = np.array([0.33, 0.66, 0.51, 0.54, 0.37, 0.51, 0.71, 0.30, 0.75, 0.41,\n",
    "                           0.40, 0.27, 0.24, 0.61, 0.36, 0.49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stylish-banner",
   "metadata": {
    "id": "stylish-banner"
   },
   "outputs": [],
   "source": [
    "def load_data(plane):\n",
    "    X_train = np.zeros((TRAIN_LEN, IMG_LEN, IMG_LEN, 3), dtype='uint8')\n",
    "    X_test = np.zeros((TEST_LEN, IMG_LEN, IMG_LEN, 3), dtype='uint8')\n",
    "    y_train = np.zeros((TRAIN_LEN, 1), dtype='uint8')\n",
    "    y_test = np.zeros((TEST_LEN, 1), dtype='uint8')\n",
    "    \n",
    "    train_count = 0\n",
    "    test_count = 0\n",
    "        \n",
    "    for gesture in GESTURES:\n",
    "        print('loading data for ' + gesture + ' gesture on the ' + plane + ' plane ... ', end='')\n",
    "        path = os.path.join(BASE_DIR, IMG_DIR, plane, gesture)\n",
    "        for filename in os.listdir(path):\n",
    "            img = cv2.imread(os.path.join(path, filename))\n",
    "            resized = cv2.resize(img, IMG_SIZE)\n",
    "            if filename[1:4] != TEST_USER:\n",
    "                X_train[train_count, :] = resized\n",
    "                y_train[train_count, 0] = GESTURES.index(gesture)\n",
    "                train_count = train_count + 1\n",
    "            else:\n",
    "                X_test[test_count, :] = resized\n",
    "                y_test[test_count, 0] = GESTURES.index(gesture)\n",
    "                test_count = test_count + 1\n",
    "                \n",
    "        print('√')\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def load_and_save_data(plane):\n",
    "    X = np.zeros((DATASET_LEN, IMG_LEN, IMG_LEN, 3))\n",
    "    y = np.zeros((DATASET_LEN, 1))\n",
    "    \n",
    "    train_count = 0\n",
    "    test_count  = TRAIN_LEN\n",
    "        \n",
    "    for gesture in GESTURES:\n",
    "        print('loading data for ' + gesture + ' gesture on the ' + plane + ' plane ... ', end='')\n",
    "        path = os.path.join(BASE_DIR, IMG_DIR, plane, gesture)\n",
    "        for filename in os.listdir(path):\n",
    "            img = cv2.imread(os.path.join(path, filename))\n",
    "            resized = cv2.resize(img, IMG_SIZE)\n",
    "            if filename[1:4] != TEST_USER:\n",
    "                X[train_count, :] = resized\n",
    "                y[train_count, 0] = GESTURES.index(gesture)\n",
    "                train_count = train_count + 1\n",
    "            else:\n",
    "                X[test_count, :] = resized\n",
    "                y[test_count, 0] = GESTURES.index(gesture)\n",
    "                test_count = test_count + 1\n",
    "                \n",
    "        print('√')\n",
    "\n",
    "    joblib.dump(X, BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
    "    joblib.dump(y, BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
    "\n",
    "def load_data_from_joblib(plane):\n",
    "    print('Loading data for ' + plane + ' plane ... ', end='')\n",
    "    X = joblib.load(BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
    "    y = joblib.load(BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
    "    test_user = int(TEST_USER)\n",
    "    X_train = X[:TRAIN_LEN, :, :, :]\n",
    "    y_train = y[:TRAIN_LEN, :]\n",
    "    X_test = X[TRAIN_LEN:, :, :, :]\n",
    "    y_test = y[TRAIN_LEN:, :]\n",
    "\n",
    "    print('√')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extra-disclosure",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "extra-disclosure",
    "outputId": "5d7048b4-28fc-4e61-ca21-71b05be417db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data for j gesture on the XY plane ... √\n",
      "loading data for z gesture on the XY plane ... √\n",
      "loading data for bad gesture on the XY plane ... √\n",
      "loading data for deaf gesture on the XY plane ... √\n",
      "loading data for fine gesture on the XY plane ... √\n",
      "loading data for good gesture on the XY plane ... √\n",
      "loading data for goodbye gesture on the XY plane ... √\n",
      "loading data for hello gesture on the XY plane ... √\n",
      "loading data for hungry gesture on the XY plane ... √\n",
      "loading data for me gesture on the XY plane ... √\n",
      "loading data for no gesture on the XY plane ... √\n",
      "loading data for please gesture on the XY plane ... √\n",
      "loading data for sorry gesture on the XY plane ... √\n",
      "loading data for thankyou gesture on the XY plane ... √\n",
      "loading data for yes gesture on the XY plane ... √\n",
      "loading data for you gesture on the XY plane ... √\n",
      "loading data for j gesture on the YZ plane ... √\n",
      "loading data for z gesture on the YZ plane ... √\n",
      "loading data for bad gesture on the YZ plane ... √\n",
      "loading data for deaf gesture on the YZ plane ... √\n",
      "loading data for fine gesture on the YZ plane ... √\n",
      "loading data for good gesture on the YZ plane ... √\n",
      "loading data for goodbye gesture on the YZ plane ... √\n",
      "loading data for hello gesture on the YZ plane ... √\n",
      "loading data for hungry gesture on the YZ plane ... √\n",
      "loading data for me gesture on the YZ plane ... √\n",
      "loading data for no gesture on the YZ plane ... √\n",
      "loading data for please gesture on the YZ plane ... √\n",
      "loading data for sorry gesture on the YZ plane ... √\n",
      "loading data for thankyou gesture on the YZ plane ... √\n",
      "loading data for yes gesture on the YZ plane ... √\n",
      "loading data for you gesture on the YZ plane ... √\n",
      "loading data for j gesture on the ZX plane ... √\n",
      "loading data for z gesture on the ZX plane ... √\n",
      "loading data for bad gesture on the ZX plane ... √\n",
      "loading data for deaf gesture on the ZX plane ... √\n",
      "loading data for fine gesture on the ZX plane ... √\n",
      "loading data for good gesture on the ZX plane ... √\n",
      "loading data for goodbye gesture on the ZX plane ... √\n",
      "loading data for hello gesture on the ZX plane ... √\n",
      "loading data for hungry gesture on the ZX plane ... √\n",
      "loading data for me gesture on the ZX plane ... √\n",
      "loading data for no gesture on the ZX plane ... √\n",
      "loading data for please gesture on the ZX plane ... √\n",
      "loading data for sorry gesture on the ZX plane ... √\n",
      "loading data for thankyou gesture on the ZX plane ... √\n",
      "loading data for yes gesture on the ZX plane ... √\n",
      "loading data for you gesture on the ZX plane ... √\n"
     ]
    }
   ],
   "source": [
    "X_train_xy, X_test_xy, y_train_xy, y_test_xy = load_data('XY')\n",
    "X_train_yz, X_test_yz, y_train_yz, y_test_yz = load_data('YZ')\n",
    "X_train_zx, X_test_zx, y_train_zx, y_test_zx = load_data('ZX')\n",
    "\n",
    "# Save to Google  Drive\n",
    "# load_and_save_data('XY')X_train_xy, y_train_xy = shuffle(X_train_xy, y_train_xy)\n",
    "# load_and_save_data('YZ')\n",
    "# load_and_save_data('ZX')\n",
    "\n",
    "# Load from Google Drive\n",
    "# X_train_xy, X_test_xy, y_train_xy, y_test_xy = load_data_from_joblib('XY')\n",
    "# X_train_yz, X_test_yz, y_train_yz, y_test_yz = load_data_from_joblib('YZ')\n",
    "# X_train_zx, X_test_zx, y_train_zx, y_test_zx = load_data_from_joblib('ZX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "conditional-advisory",
   "metadata": {
    "id": "conditional-advisory"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 14:50:47.139070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 14:50:47.144854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 14:50:47.145273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 14:50:47.146087: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-07 14:50:47.146742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 14:50:47.147138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 14:50:47.147471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 14:50:47.534811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 14:50:47.535077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 14:50:47.535283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 14:50:47.535487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1613 MB memory:  -> device: 0, name: GeForce MX330, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "internal-arkansas",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "internal-arkansas",
    "outputId": "5c5ae4bd-72a6-426d-c60f-cba486c62a1b"
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "strange-encoding",
   "metadata": {
    "id": "strange-encoding"
   },
   "outputs": [],
   "source": [
    "global_average_layer = GlobalAvgPool2D()\n",
    "prediction_layer = Dense(len(GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e049e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_block():\n",
    "    input = tf.keras.layers.Input(shape=IMG_SHAPE)\n",
    "    # x = data_augmentation(input)\n",
    "    x = preprocess_input(input)\n",
    "    x = base_model(x, training=False)\n",
    "    x = global_average_layer(x)\n",
    "\n",
    "    return input, x\n",
    "\n",
    "\n",
    "def get_stacked_model(n):\n",
    "    inputs = []\n",
    "    CNNs = []\n",
    "\n",
    "    for i in range(n):\n",
    "        input_i, CNN_i = get_cnn_block()\n",
    "        inputs.append(input_i)\n",
    "        CNNs.append(CNN_i)\n",
    "\n",
    "    x = concatenate(CNNs, axis=-1)\n",
    "    x = Dropout(0.4)(x)\n",
    "    # x = Dense(100, activation=\"relu\")(x)\n",
    "    # x = Dropout(0.4)(x)\n",
    "    # x = Dense(20, activation='selu')(x)\n",
    "    # x = Dropout(0.5)(x)\n",
    "    output = prediction_layer(x)\n",
    "    model = Model(inputs, output)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    loss = SparseCategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(loss=loss, optimizer=opt, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "upper-tobago",
   "metadata": {
    "id": "upper-tobago"
   },
   "outputs": [],
   "source": [
    "# def get_model():\n",
    "#     inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
    "#     #     x = data_augmentation(inputs)\n",
    "#     x = preprocess_input(inputs)\n",
    "#     x = base_model(x, training=False)\n",
    "#     x = global_average_layer(x)\n",
    "#     x = tf.keras.layers.Dropout(0.2)(x)\n",
    "#     outputs = prediction_layer(x)\n",
    "#     model = tf.keras.Model(inputs, outputs)\n",
    "#     model.compile(\n",
    "#         optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE, decay=DECAY),\n",
    "#         loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#         metrics=[\"accuracy\"],\n",
    "#     )\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92fd4333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 14:50:54.359703: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/480 [..............................] - ETA: 38s - loss: 3.5587 - accuracy: 0.0625      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 14:50:56.000329: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.73MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-07 14:50:56.067301: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 923.19MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-07 14:50:56.090945: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 923.19MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-07 14:50:56.102112: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 923.19MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 48s 87ms/step - loss: 1.7767 - accuracy: 0.4604 - val_loss: 1.9535 - val_accuracy: 0.3750\n",
      "Epoch 2/50\n",
      "480/480 [==============================] - 40s 84ms/step - loss: 0.6392 - accuracy: 0.8219 - val_loss: 1.9261 - val_accuracy: 0.4375\n",
      "Epoch 3/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.4025 - accuracy: 0.8826 - val_loss: 1.9329 - val_accuracy: 0.4563\n",
      "Epoch 4/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.2994 - accuracy: 0.9055 - val_loss: 2.0380 - val_accuracy: 0.4563\n",
      "Epoch 5/50\n",
      "480/480 [==============================] - 50s 103ms/step - loss: 0.2378 - accuracy: 0.9255 - val_loss: 2.0688 - val_accuracy: 0.4500\n",
      "Epoch 6/50\n",
      "480/480 [==============================] - 41s 84ms/step - loss: 0.2029 - accuracy: 0.9344 - val_loss: 2.1946 - val_accuracy: 0.4437\n",
      "Epoch 7/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.1822 - accuracy: 0.9378 - val_loss: 2.1820 - val_accuracy: 0.4500\n",
      "Epoch 8/50\n",
      "480/480 [==============================] - 40s 84ms/step - loss: 0.1617 - accuracy: 0.9456 - val_loss: 2.2171 - val_accuracy: 0.4875\n",
      "Epoch 9/50\n",
      "480/480 [==============================] - 40s 84ms/step - loss: 0.1364 - accuracy: 0.9578 - val_loss: 2.2458 - val_accuracy: 0.4875\n",
      "Epoch 10/50\n",
      "480/480 [==============================] - 41s 84ms/step - loss: 0.1331 - accuracy: 0.9565 - val_loss: 2.2794 - val_accuracy: 0.4875\n",
      "Epoch 11/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.1174 - accuracy: 0.9573 - val_loss: 2.3018 - val_accuracy: 0.4625\n",
      "Epoch 12/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.1083 - accuracy: 0.9643 - val_loss: 2.4339 - val_accuracy: 0.4625\n",
      "Epoch 13/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.0992 - accuracy: 0.9638 - val_loss: 2.2883 - val_accuracy: 0.4750\n",
      "Epoch 14/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.0985 - accuracy: 0.9641 - val_loss: 2.4784 - val_accuracy: 0.4750\n",
      "Epoch 15/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.0893 - accuracy: 0.9693 - val_loss: 2.4651 - val_accuracy: 0.4750\n",
      "Epoch 16/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.0855 - accuracy: 0.9688 - val_loss: 2.6181 - val_accuracy: 0.4563\n",
      "Epoch 17/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.0797 - accuracy: 0.9695 - val_loss: 2.6078 - val_accuracy: 0.4875\n",
      "Epoch 18/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.0728 - accuracy: 0.9719 - val_loss: 2.5376 - val_accuracy: 0.4875\n",
      "Epoch 19/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.0732 - accuracy: 0.9708 - val_loss: 2.6435 - val_accuracy: 0.4938\n",
      "Epoch 20/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.0705 - accuracy: 0.9737 - val_loss: 2.6754 - val_accuracy: 0.4938\n",
      "Epoch 21/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.0640 - accuracy: 0.9776 - val_loss: 2.7748 - val_accuracy: 0.4563\n",
      "Epoch 22/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.0626 - accuracy: 0.9779 - val_loss: 2.7475 - val_accuracy: 0.4812\n",
      "Epoch 23/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.0561 - accuracy: 0.9797 - val_loss: 2.7927 - val_accuracy: 0.4812\n",
      "Epoch 24/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.0558 - accuracy: 0.9805 - val_loss: 2.8414 - val_accuracy: 0.4750\n",
      "Epoch 25/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.0535 - accuracy: 0.9807 - val_loss: 2.8095 - val_accuracy: 0.4750\n",
      "Epoch 26/50\n",
      "480/480 [==============================] - 41s 85ms/step - loss: 0.0556 - accuracy: 0.9784 - val_loss: 2.9152 - val_accuracy: 0.4688\n",
      "Epoch 27/50\n",
      "143/480 [=======>......................] - ETA: 27s - loss: 0.0425 - accuracy: 0.9869"
     ]
    }
   ],
   "source": [
    "model = get_stacked_model(3)\n",
    "X_train_xy, X_train_yz, X_train_zx, y_train_xy = shuffle(\n",
    "    X_train_xy, X_train_yz, X_train_zx, y_train_xy\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train_xy, X_train_yz, X_train_zx],\n",
    "    y_train_xy,\n",
    "    validation_data=([X_test_xy, X_test_yz, X_test_zx], y_test_xy),\n",
    "    batch_size=8,\n",
    "    epochs=EPOCHS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-appendix",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 973
    },
    "id": "distinct-appendix",
    "outputId": "7ead500b-3cac-4519-900d-c46b55f8362d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_xy = get_model()\n",
    "# X_train_xy, y_train_xy = shuffle(X_train_xy, y_train_xy)\n",
    "# history_xy = model_xy.fit(X_train_xy, y_train_xy, validation_data=(X_test_xy, y_test_xy), epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-genre",
   "metadata": {
    "id": "constitutional-genre"
   },
   "outputs": [],
   "source": [
    "# # prob_xy = tf.keras.Sequential([model_xy, tf.keras.layers.Softmax()])\n",
    "# # y_pred_xy = prob_xy.predict(X_test_xy)\n",
    "# y_pred_xy = model_xy.predict(X_test_xy)\n",
    "# y_pred = np.argmax(y_pred_xy, axis=1)\n",
    "# print(classification_report(y_test_xy.ravel(), y_pred, zero_division=0))\n",
    "# prc_xy = precision_score(y_test_xy.ravel(), y_pred, zero_division=0, average=None)\n",
    "# tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-chrome",
   "metadata": {
    "id": "emotional-chrome"
   },
   "outputs": [],
   "source": [
    "# model_yz = get_model()\n",
    "# X_train_yz, y_train_yz = shuffle(X_train_yz, y_train_yz)\n",
    "# history_yz = model_yz.fit(X_train_yz, y_train_yz, validation_data=(X_test_yz, y_test_yz), epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-insurance",
   "metadata": {
    "id": "boring-insurance"
   },
   "outputs": [],
   "source": [
    "# # prob_yz = tf.keras.Sequential([model_yz, tf.keras.layers.Softmax()])\n",
    "# # y_pred_yz = prob_yz.predict(X_test_yz)\n",
    "# y_pred_yz = model_yz.predict(X_test_yz)\n",
    "# y_pred = np.argmax(y_pred_yz, axis=1)\n",
    "# print(classification_report(y_test_yz.ravel(), y_pred, zero_division=0))\n",
    "# prc_yz = precision_score(y_test_yz.ravel(), y_pred, zero_division=0, average=None)\n",
    "# tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-evaluation",
   "metadata": {
    "id": "joint-evaluation"
   },
   "outputs": [],
   "source": [
    "# model_zx = get_model()\n",
    "# X_train_zx, y_train_zx = shuffle(X_train_zx, y_train_zx)\n",
    "# history_zx = model_zx.fit(X_train_zx, y_train_zx, validation_data=(X_test_zx, y_test_zx), epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-still",
   "metadata": {
    "id": "designed-still"
   },
   "outputs": [],
   "source": [
    "# # prob_zx = tf.keras.Sequential([model_zx, tf.keras.layers.Softmax()])\n",
    "# # y_pred_zx = prob_zx.predict(X_test_zx)\n",
    "# y_pred_zx = model_zx.predict(X_test_zx)\n",
    "# y_pred = np.argmax(y_pred_zx, axis=1)\n",
    "# print(classification_report(y_test_zx.ravel(), y_pred, zero_division=0))\n",
    "# prc_zx = precision_score(y_test_zx.ravel(), y_pred, zero_division=0, average=None)\n",
    "# tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-geography",
   "metadata": {
    "id": "selective-geography"
   },
   "outputs": [],
   "source": [
    "# y_total = y_pred_xy + y_pred_yz + y_pred_zx\n",
    "# y_pred = np.argmax(y_total, axis=1)\n",
    "# report = classification_report(y_test_xy.ravel(), y_pred, zero_division=0)\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-palmer",
   "metadata": {
    "id": "collected-palmer"
   },
   "outputs": [],
   "source": [
    "# config = '\\n\\nTEST_USER ' + TEST_USER + ' T: ' + str(int(time.time())) + '\\n'\n",
    "# underline = '=====================================\\n'\n",
    "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.mkdir(log_dir)\n",
    "# f = open(os.path.join(log_dir, 'logs_sptl_bw' + CONFIG + '.txt'), 'a')\n",
    "# f.write(config)\n",
    "# f.write(underline)\n",
    "# f.write(report)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-lunch",
   "metadata": {
    "id": "intellectual-lunch"
   },
   "outputs": [],
   "source": [
    "# config = TEST_USER + ' :'\n",
    "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.mkdir(log_dir)\n",
    "# f = open(os.path.join(log_dir, 'prc_sptl_bw_xy' + CONFIG + '.txt'), 'a')\n",
    "# f.write(config)\n",
    "# f.write(np.array2string(prc_xy, precision=2, max_line_width=100) + '\\n')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-thread",
   "metadata": {
    "id": "trying-thread"
   },
   "outputs": [],
   "source": [
    "# config = TEST_USER + ' :'\n",
    "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.mkdir(log_dir)\n",
    "# f = open(os.path.join(log_dir, 'prc_sptl_bw_yz' + CONFIG + '.txt'), 'a')\n",
    "# f.write(config)\n",
    "# f.write(np.array2string(prc_yz, precision=2, max_line_width=100) + '\\n')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-plant",
   "metadata": {
    "id": "general-plant"
   },
   "outputs": [],
   "source": [
    "# config = TEST_USER + ' :'\n",
    "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.mkdir(log_dir)\n",
    "# f = open(os.path.join(log_dir, 'prc_sptl_bw_zx' + CONFIG + '.txt'), 'a')\n",
    "# f.write(config)\n",
    "# f.write(np.array2string(prc_zx, precision=2, max_line_width=100) + '\\n')\n",
    "# f.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Spatial_Path_Transfer_Learning_BW.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
