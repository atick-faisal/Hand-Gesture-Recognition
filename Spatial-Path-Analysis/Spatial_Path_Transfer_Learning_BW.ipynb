{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tamil-chrome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "casual-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- TEST USER ----------- #\n",
    "\n",
    "TEST_USER      = '002'\n",
    "\n",
    "BASE_DIR       = '../'\n",
    "IMG_DIR        = 'BW-Spatial-Path-Images/'\n",
    "LOG_DIR        = 'Logs/'\n",
    "\n",
    "USERS          = ['001', '002', '003', '004', '005', '006', '007']\n",
    "\n",
    "# ------------------------------- Only Dynalic Gestures ------------------------------ #\n",
    "GESTURES       = ['j', 'z', 'bad', 'deaf', 'fine', 'good', 'goodbye', 'hello', 'hungry',\n",
    "                  'me', 'no', 'please', 'sorry', 'thankyou', 'yes', 'you']\n",
    "\n",
    "PLANES         = ['XY', 'YZ', 'ZX']\n",
    "\n",
    "BATCH_SIZE     = 32\n",
    "IMG_LEN        = 160\n",
    "IMG_SIZE       = (IMG_LEN, IMG_LEN)\n",
    "\n",
    "# ------------- FOR THE GREATER GOOD :) ------------- #\n",
    "TRAIN_LEN      = 960\n",
    "TEST_LEN       = 160\n",
    "\n",
    "EPOCHS         = 7\n",
    "LEARNING_RATE  = 0.001\n",
    "DECAY          = 0.0\n",
    "\n",
    "CONFIG         = '_L_7_S_160x160_E_7'\n",
    "\n",
    "XY_WEIGHTS     = np.array([0.91, 0.75, 0.61, 0.63, 0.51, 0.66, 0.81, 0.65, 0.65, 0.31,\n",
    "                           0.66, 0.29, 0.34, 0.64, 0.64, 0.31])\n",
    "YZ_WEIGHTS     = np.array([0.73, 0.71, 0.70, 0.79, 0.76, 0.38, 0.80, 0.61, 0.58, 0.73,\n",
    "                           0.49, 0.26, 0.26, 0.52, 0.59, 0.54])\n",
    "ZX_WEIGHTS     = np.array([0.33, 0.66, 0.51, 0.54, 0.37, 0.51, 0.71, 0.30, 0.75, 0.41,\n",
    "                           0.40, 0.27, 0.24, 0.61, 0.36, 0.49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stylish-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(plane):\n",
    "    X_train = np.zeros((TRAIN_LEN, IMG_LEN, IMG_LEN, 3))\n",
    "    X_test = np.zeros((TEST_LEN, IMG_LEN, IMG_LEN, 3))\n",
    "    y_train = np.zeros((TRAIN_LEN, 1))\n",
    "    y_test = np.zeros((TEST_LEN, 1))\n",
    "    \n",
    "    train_count = 0\n",
    "    test_count = 0\n",
    "        \n",
    "    for gesture in GESTURES:\n",
    "        print('loading data for ' + gesture + ' gesture on the ' + plane + ' plane ... ', end='')\n",
    "        path = os.path.join(BASE_DIR, IMG_DIR, plane, gesture)\n",
    "        for filename in os.listdir(path):\n",
    "            img = cv2.imread(os.path.join(path, filename))\n",
    "            resized = cv2.resize(img, IMG_SIZE)\n",
    "            if filename[1:4] != TEST_USER:\n",
    "                X_train[train_count, :] = resized\n",
    "                y_train[train_count, 0] = GESTURES.index(gesture)\n",
    "                train_count = train_count + 1\n",
    "            else:\n",
    "                X_test[test_count, :] = resized\n",
    "                y_test[test_count, 0] = GESTURES.index(gesture)\n",
    "                test_count = test_count + 1\n",
    "                \n",
    "        print('√')\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extra-disclosure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data for j gesture on the XY plane ... √\n",
      "loading data for z gesture on the XY plane ... √\n",
      "loading data for bad gesture on the XY plane ... √\n",
      "loading data for deaf gesture on the XY plane ... √\n",
      "loading data for fine gesture on the XY plane ... √\n",
      "loading data for good gesture on the XY plane ... √\n",
      "loading data for goodbye gesture on the XY plane ... √\n",
      "loading data for hello gesture on the XY plane ... √\n",
      "loading data for hungry gesture on the XY plane ... √\n",
      "loading data for me gesture on the XY plane ... √\n",
      "loading data for no gesture on the XY plane ... √\n",
      "loading data for please gesture on the XY plane ... √\n",
      "loading data for sorry gesture on the XY plane ... √\n",
      "loading data for thankyou gesture on the XY plane ... √\n",
      "loading data for yes gesture on the XY plane ... √\n",
      "loading data for you gesture on the XY plane ... √\n",
      "loading data for j gesture on the YZ plane ... √\n",
      "loading data for z gesture on the YZ plane ... √\n",
      "loading data for bad gesture on the YZ plane ... √\n",
      "loading data for deaf gesture on the YZ plane ... √\n",
      "loading data for fine gesture on the YZ plane ... √\n",
      "loading data for good gesture on the YZ plane ... √\n",
      "loading data for goodbye gesture on the YZ plane ... √\n",
      "loading data for hello gesture on the YZ plane ... √\n",
      "loading data for hungry gesture on the YZ plane ... √\n",
      "loading data for me gesture on the YZ plane ... √\n",
      "loading data for no gesture on the YZ plane ... √\n",
      "loading data for please gesture on the YZ plane ... √\n",
      "loading data for sorry gesture on the YZ plane ... √\n",
      "loading data for thankyou gesture on the YZ plane ... √\n",
      "loading data for yes gesture on the YZ plane ... √\n",
      "loading data for you gesture on the YZ plane ... √\n",
      "loading data for j gesture on the ZX plane ... √\n",
      "loading data for z gesture on the ZX plane ... √\n",
      "loading data for bad gesture on the ZX plane ... √\n",
      "loading data for deaf gesture on the ZX plane ... √\n",
      "loading data for fine gesture on the ZX plane ... √\n",
      "loading data for good gesture on the ZX plane ... √\n",
      "loading data for goodbye gesture on the ZX plane ... √\n",
      "loading data for hello gesture on the ZX plane ... √\n",
      "loading data for hungry gesture on the ZX plane ... √\n",
      "loading data for me gesture on the ZX plane ... √\n",
      "loading data for no gesture on the ZX plane ... √\n",
      "loading data for please gesture on the ZX plane ... √\n",
      "loading data for sorry gesture on the ZX plane ... √\n",
      "loading data for thankyou gesture on the ZX plane ... √\n",
      "loading data for yes gesture on the ZX plane ... √\n",
      "loading data for you gesture on the ZX plane ... √\n"
     ]
    }
   ],
   "source": [
    "X_train_xy, X_test_xy, y_train_xy, y_test_xy = load_data('XY')\n",
    "X_train_yz, X_test_yz, y_train_yz, y_test_yz = load_data('YZ')\n",
    "X_train_zx, X_test_zx, y_train_zx, y_test_zx = load_data('ZX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "conditional-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "internal-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "strange-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(len(GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "upper-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
    "    x = preprocess_input(inputs)\n",
    "    x = base_model(x, training=False)\n",
    "    x = global_average_layer(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = prediction_layer(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE, decay=DECAY),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "distinct-appendix",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "30/30 [==============================] - 18s 486ms/step - loss: 2.8148 - accuracy: 0.1479 - val_loss: 1.8696 - val_accuracy: 0.4875\n",
      "Epoch 2/7\n",
      "30/30 [==============================] - 13s 438ms/step - loss: 1.6636 - accuracy: 0.5047 - val_loss: 1.5398 - val_accuracy: 0.5312\n",
      "Epoch 3/7\n",
      "30/30 [==============================] - 13s 432ms/step - loss: 1.2321 - accuracy: 0.6330 - val_loss: 1.4295 - val_accuracy: 0.5750\n",
      "Epoch 4/7\n",
      "30/30 [==============================] - 13s 435ms/step - loss: 0.9927 - accuracy: 0.6895 - val_loss: 1.3126 - val_accuracy: 0.5688\n",
      "Epoch 5/7\n",
      "30/30 [==============================] - 13s 433ms/step - loss: 0.8375 - accuracy: 0.7484 - val_loss: 1.2132 - val_accuracy: 0.6438\n",
      "Epoch 6/7\n",
      "30/30 [==============================] - 13s 438ms/step - loss: 0.7414 - accuracy: 0.7813 - val_loss: 1.1426 - val_accuracy: 0.6438\n",
      "Epoch 7/7\n",
      "30/30 [==============================] - 13s 420ms/step - loss: 0.6315 - accuracy: 0.8290 - val_loss: 1.1660 - val_accuracy: 0.6687\n"
     ]
    }
   ],
   "source": [
    "model_xy = get_model()\n",
    "history_xy = model_xy.fit(X_train_xy, y_train_xy, validation_data=(X_test_xy, y_test_xy), epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "constitutional-genre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95        10\n",
      "         1.0       0.88      0.70      0.78        10\n",
      "         2.0       0.89      0.80      0.84        10\n",
      "         3.0       0.62      1.00      0.77        10\n",
      "         4.0       1.00      0.90      0.95        10\n",
      "         5.0       0.91      1.00      0.95        10\n",
      "         6.0       1.00      0.20      0.33        10\n",
      "         7.0       1.00      0.70      0.82        10\n",
      "         8.0       0.77      1.00      0.87        10\n",
      "         9.0       0.83      0.50      0.62        10\n",
      "        10.0       0.86      0.60      0.71        10\n",
      "        11.0       0.17      0.10      0.12        10\n",
      "        12.0       0.35      0.70      0.47        10\n",
      "        13.0       0.44      0.70      0.54        10\n",
      "        14.0       0.33      0.20      0.25        10\n",
      "        15.0       0.46      0.60      0.52        10\n",
      "\n",
      "    accuracy                           0.67       160\n",
      "   macro avg       0.71      0.67      0.66       160\n",
      "weighted avg       0.71      0.67      0.66       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prob_xy = tf.keras.Sequential([model_xy, tf.keras.layers.Softmax()])\n",
    "# y_pred_xy = prob_xy.predict(X_test_xy)\n",
    "y_pred_xy = model_xy.predict(X_test_xy)\n",
    "y_pred = np.argmax(y_pred_xy, axis=1)\n",
    "print(classification_report(y_test_xy.ravel(), y_pred, zero_division=0))\n",
    "prc_xy = precision_score(y_test_xy.ravel(), y_pred, zero_division=0, average=None)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "emotional-chrome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "30/30 [==============================] - 15s 427ms/step - loss: 3.4494 - accuracy: 0.1546 - val_loss: 2.3939 - val_accuracy: 0.2937\n",
      "Epoch 2/7\n",
      "30/30 [==============================] - 12s 407ms/step - loss: 1.9281 - accuracy: 0.4067 - val_loss: 1.6357 - val_accuracy: 0.4563\n",
      "Epoch 3/7\n",
      "30/30 [==============================] - 13s 422ms/step - loss: 1.3018 - accuracy: 0.5872 - val_loss: 1.2887 - val_accuracy: 0.5938\n",
      "Epoch 4/7\n",
      "30/30 [==============================] - 13s 427ms/step - loss: 0.9571 - accuracy: 0.6678 - val_loss: 1.1449 - val_accuracy: 0.6250\n",
      "Epoch 5/7\n",
      "30/30 [==============================] - 12s 395ms/step - loss: 0.8095 - accuracy: 0.7652 - val_loss: 1.0476 - val_accuracy: 0.6625\n",
      "Epoch 6/7\n",
      "30/30 [==============================] - 14s 465ms/step - loss: 0.6654 - accuracy: 0.8025 - val_loss: 0.9730 - val_accuracy: 0.6875\n",
      "Epoch 7/7\n",
      "30/30 [==============================] - 15s 505ms/step - loss: 0.6119 - accuracy: 0.8085 - val_loss: 0.9529 - val_accuracy: 0.6812\n"
     ]
    }
   ],
   "source": [
    "model_yz = get_model()\n",
    "history_yz = model_yz.fit(X_train_yz, y_train_yz, validation_data=(X_test_yz, y_test_yz), epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "boring-insurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.90      0.86        10\n",
      "         1.0       1.00      0.90      0.95        10\n",
      "         2.0       1.00      0.70      0.82        10\n",
      "         3.0       1.00      0.80      0.89        10\n",
      "         4.0       0.80      0.80      0.80        10\n",
      "         5.0       0.62      1.00      0.77        10\n",
      "         6.0       1.00      0.80      0.89        10\n",
      "         7.0       1.00      0.50      0.67        10\n",
      "         8.0       0.67      0.40      0.50        10\n",
      "         9.0       0.53      1.00      0.69        10\n",
      "        10.0       0.50      0.40      0.44        10\n",
      "        11.0       0.38      0.30      0.33        10\n",
      "        12.0       0.33      0.80      0.47        10\n",
      "        13.0       1.00      1.00      1.00        10\n",
      "        14.0       0.33      0.10      0.15        10\n",
      "        15.0       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.68       160\n",
      "   macro avg       0.73      0.68      0.67       160\n",
      "weighted avg       0.73      0.68      0.67       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prob_yz = tf.keras.Sequential([model_yz, tf.keras.layers.Softmax()])\n",
    "# y_pred_yz = prob_yz.predict(X_test_yz)\n",
    "y_pred_yz = model_yz.predict(X_test_yz)\n",
    "y_pred = np.argmax(y_pred_yz, axis=1)\n",
    "print(classification_report(y_test_yz.ravel(), y_pred, zero_division=0))\n",
    "prc_yz = precision_score(y_test_yz.ravel(), y_pred, zero_division=0, average=None)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "joint-evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "30/30 [==============================] - 17s 466ms/step - loss: 3.4401 - accuracy: 0.1980 - val_loss: 2.9293 - val_accuracy: 0.2438\n",
      "Epoch 2/7\n",
      "30/30 [==============================] - 14s 485ms/step - loss: 2.2665 - accuracy: 0.3358 - val_loss: 2.2706 - val_accuracy: 0.3375\n",
      "Epoch 3/7\n",
      "30/30 [==============================] - 14s 477ms/step - loss: 1.6759 - accuracy: 0.4790 - val_loss: 2.0179 - val_accuracy: 0.4563\n",
      "Epoch 4/7\n",
      "30/30 [==============================] - 15s 504ms/step - loss: 1.2976 - accuracy: 0.5732 - val_loss: 1.8477 - val_accuracy: 0.4563\n",
      "Epoch 5/7\n",
      "30/30 [==============================] - 12s 412ms/step - loss: 1.0752 - accuracy: 0.6667 - val_loss: 1.7841 - val_accuracy: 0.4750\n",
      "Epoch 6/7\n",
      "30/30 [==============================] - 14s 465ms/step - loss: 0.9180 - accuracy: 0.7193 - val_loss: 1.7819 - val_accuracy: 0.5000\n",
      "Epoch 7/7\n",
      "30/30 [==============================] - 15s 494ms/step - loss: 0.8254 - accuracy: 0.7494 - val_loss: 1.7412 - val_accuracy: 0.5125\n"
     ]
    }
   ],
   "source": [
    "model_zx = get_model()\n",
    "history_zx = model_zx.fit(X_train_zx, y_train_zx, validation_data=(X_test_zx, y_test_zx), epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "designed-still",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        10\n",
      "         1.0       0.33      0.10      0.15        10\n",
      "         2.0       0.60      0.30      0.40        10\n",
      "         3.0       0.77      1.00      0.87        10\n",
      "         4.0       0.27      0.30      0.29        10\n",
      "         5.0       0.42      1.00      0.59        10\n",
      "         6.0       1.00      0.90      0.95        10\n",
      "         7.0       0.43      0.60      0.50        10\n",
      "         8.0       0.83      1.00      0.91        10\n",
      "         9.0       0.50      0.60      0.55        10\n",
      "        10.0       0.09      0.10      0.10        10\n",
      "        11.0       0.00      0.00      0.00        10\n",
      "        12.0       0.40      0.20      0.27        10\n",
      "        13.0       0.91      1.00      0.95        10\n",
      "        14.0       0.06      0.10      0.07        10\n",
      "        15.0       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.51       160\n",
      "   macro avg       0.48      0.51      0.47       160\n",
      "weighted avg       0.48      0.51      0.47       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prob_zx = tf.keras.Sequential([model_zx, tf.keras.layers.Softmax()])\n",
    "# y_pred_zx = prob_zx.predict(X_test_zx)\n",
    "y_pred_zx = model_zx.predict(X_test_zx)\n",
    "y_pred = np.argmax(y_pred_zx, axis=1)\n",
    "print(classification_report(y_test_zx.ravel(), y_pred, zero_division=0))\n",
    "prc_zx = precision_score(y_test_zx.ravel(), y_pred, zero_division=0, average=None)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "selective-geography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.95        10\n",
      "         1.0       1.00      1.00      1.00        10\n",
      "         2.0       1.00      1.00      1.00        10\n",
      "         3.0       0.91      1.00      0.95        10\n",
      "         4.0       0.91      1.00      0.95        10\n",
      "         5.0       0.77      1.00      0.87        10\n",
      "         6.0       1.00      1.00      1.00        10\n",
      "         7.0       1.00      1.00      1.00        10\n",
      "         8.0       1.00      1.00      1.00        10\n",
      "         9.0       1.00      1.00      1.00        10\n",
      "        10.0       1.00      0.60      0.75        10\n",
      "        11.0       0.33      0.10      0.15        10\n",
      "        12.0       0.36      0.90      0.51        10\n",
      "        13.0       1.00      1.00      1.00        10\n",
      "        14.0       1.00      0.10      0.18        10\n",
      "        15.0       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.85       160\n",
      "   macro avg       0.89      0.85      0.83       160\n",
      "weighted avg       0.89      0.85      0.83       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_total = y_pred_xy + y_pred_yz + y_pred_zx\n",
    "y_pred = np.argmax(y_total, axis=1)\n",
    "report = classification_report(y_test_xy.ravel(), y_pred, zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "collected-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = '\\n\\nTEST_USER ' + TEST_USER + ' T: ' + str(int(time.time())) + '\\n'\n",
    "underline = '=====================================\\n'\n",
    "log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "f = open(os.path.join(log_dir, 'logs_sptl_bw' + CONFIG + '.txt'), 'a')\n",
    "f.write(config)\n",
    "f.write(underline)\n",
    "f.write(report)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intellectual-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = TEST_USER + ' :'\n",
    "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.mkdir(log_dir)\n",
    "# f = open(os.path.join(log_dir, 'prc_sptl_bw_xy' + CONFIG + '.txt'), 'a')\n",
    "# f.write(config)\n",
    "# f.write(np.array2string(prc_xy, precision=2, max_line_width=100) + '\\n')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "trying-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = TEST_USER + ' :'\n",
    "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.mkdir(log_dir)\n",
    "# f = open(os.path.join(log_dir, 'prc_sptl_bw_yz' + CONFIG + '.txt'), 'a')\n",
    "# f.write(config)\n",
    "# f.write(np.array2string(prc_yz, precision=2, max_line_width=100) + '\\n')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "general-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = TEST_USER + ' :'\n",
    "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.mkdir(log_dir)\n",
    "# f = open(os.path.join(log_dir, 'prc_sptl_bw_zx' + CONFIG + '.txt'), 'a')\n",
    "# f.write(config)\n",
    "# f.write(np.array2string(prc_zx, precision=2, max_line_width=100) + '\\n')\n",
    "# f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
