{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/Hand-Gesture-Recognition/blob/dev/Spatial-Path-Analysis/Spatial_Path_Transfer_Learning_BW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "tamil-chrome",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tamil-chrome",
        "outputId": "cf6c0f8c-c8af-49a5-e5bd-766b24ee53c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import gc\n",
        "import cv2\n",
        "import time\n",
        "import joblib\n",
        "import shutil\n",
        "import tarfile\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, confusion_matrix\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, GlobalAvgPool2D, Dropout, Flatten, concatenate\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from scipy.signal import butter, lfilter\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "MfafORnwZkyT",
      "metadata": {
        "id": "MfafORnwZkyT"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "casual-stack",
      "metadata": {
        "id": "casual-stack"
      },
      "outputs": [],
      "source": [
        "# -------- TEST USER ----------- #\n",
        "\n",
        "TEST_USER      = '010'\n",
        "DATASET_ID     = '1p0CSRb9gax0sKqdyzOYVt-BXvZ4GtrBv'\n",
        "\n",
        "# BASE_DIR       = '../Dataset/'\n",
        "\n",
        "# Google Drive\n",
        "BASE_DIR       = '.'\n",
        "DATA_DIR       = 'Sensor-Data/'\n",
        "BW_IMG_DIR     = 'BW-Spatial-Path-Images/'\n",
        "RGB_IMG_DIR    = 'RGB-Spatial-Path-Images/'\n",
        "CHANNELS_DIR   = 'Channels/'\n",
        "IMG_SIZE       = (3, 3) # INCHES\n",
        "\n",
        "IMG_DIR        = 'BW-Spatial-Path-Images/'\n",
        "LOG_DIR        = 'Logs/'\n",
        "\n",
        "USERS          = ['001', '002', '003', '004', '005', '006', '007', '008', '009',\n",
        "                  '010', '011', '012', '013', '014', '015', '016', '017', '018',\n",
        "                  '019', '020', '021', '022', '023', '024', '025']\n",
        "\n",
        "# ------------------------------- Only Dynalic Gestures ------------------------------ #\n",
        "GESTURES       = ['j', 'z', 'bad', 'deaf', 'fine', 'good', 'goodbye', 'hello', 'hungry',\n",
        "                  'me', 'no', 'please', 'sorry', 'thankyou', 'yes', 'you']\n",
        "\n",
        "PLANES         = ['XY', 'YZ', 'ZX']\n",
        "\n",
        "BATCH_SIZE     = 32\n",
        "IMG_LEN        = 224\n",
        "IMG_SIZE       = (IMG_LEN, IMG_LEN)\n",
        "\n",
        "# ------------- FOR THE GREATER GOOD :) ------------- #\n",
        "DATASET_LEN    = 4000\n",
        "TRAIN_LEN      = 3840\n",
        "TEST_LEN       = 160\n",
        "\n",
        "EPOCHS         = 50\n",
        "LEARNING_RATE  = 0.001\n",
        "DECAY          = 0.0\n",
        "\n",
        "DT             = 0.01\n",
        "SHAPES         = 100\n",
        "CUT_OFF        = 3.0\n",
        "ORDER          = 4\n",
        "FS             = 100\n",
        "\n",
        "WINDOW_LEN     = 150\n",
        "\n",
        "CONFIG         = '_L_7_S_160x160_E_7'\n",
        "CHANNELS_GROUP = 'DYNAMIC_ACC_ONLY_'\n",
        "\n",
        "XY_WEIGHTS     = np.array([0.91, 0.75, 0.61, 0.63, 0.51, 0.66, 0.81, 0.65, 0.65, 0.31,\n",
        "                           0.66, 0.29, 0.34, 0.64, 0.64, 0.31])\n",
        "YZ_WEIGHTS     = np.array([0.73, 0.71, 0.70, 0.79, 0.76, 0.38, 0.80, 0.61, 0.58, 0.73,\n",
        "                           0.49, 0.26, 0.26, 0.52, 0.59, 0.54])\n",
        "ZX_WEIGHTS     = np.array([0.33, 0.66, 0.51, 0.54, 0.37, 0.51, 0.71, 0.30, 0.75, 0.41,\n",
        "                           0.40, 0.27, 0.24, 0.61, 0.36, 0.49])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e65322ba",
      "metadata": {
        "id": "e65322ba"
      },
      "outputs": [],
      "source": [
        "class LowPassFilter(object): \n",
        "    def butter_lowpass(cutoff, fs, order):\n",
        "        nyq = 0.5 * fs\n",
        "        normal_cutoff = cutoff / nyq\n",
        "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "        return b, a\n",
        "\n",
        "    def apply(data, cutoff=CUT_OFF, fs=FS, order=ORDER):\n",
        "        b, a = LowPassFilter.butter_lowpass(cutoff, fs, order=order)\n",
        "        y = lfilter(b, a, data)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ksdY7MgcqHNr",
      "metadata": {
        "id": "ksdY7MgcqHNr"
      },
      "outputs": [],
      "source": [
        "#--------------------- Download util for Google Drive ------------------- #\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "        \n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "        \n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "\n",
        "def download_data(fid, destination):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(destination)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('creating data directory ... ', end='')\n",
        "    os.mkdir(destination)\n",
        "    print('√')\n",
        "    \n",
        "    print('downloading dataset from the repository ... ', end='')\n",
        "    filename = os.path.join(destination, 'dataset.tar.xz')\n",
        "    try:\n",
        "        download_file_from_google_drive(fid, filename)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('extracting the dataset ... ', end='')\n",
        "    try:\n",
        "        tar = tarfile.open(filename)\n",
        "        tar.extractall(destination)\n",
        "        tar.close()\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "MtE4QJm-qOZY",
      "metadata": {
        "id": "MtE4QJm-qOZY"
      },
      "outputs": [],
      "source": [
        "# # ------- Comment This if already downloaded -------- #\n",
        "\n",
        "# destination = os.path.join(BASE_DIR, DATA_DIR)\n",
        "# download_data(DATASET_ID, destination)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f9d84aa1",
      "metadata": {
        "id": "f9d84aa1"
      },
      "outputs": [],
      "source": [
        "def clean_dir(path):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(path)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "    \n",
        "    print('creating ' + path + ' directory ... ', end='')\n",
        "    os.mkdir(path)\n",
        "    print('√')\n",
        "\n",
        "def extract_channels():\n",
        "    channels_dir = os.path.join(BASE_DIR, CHANNELS_DIR)\n",
        "    clean_dir(channels_dir)\n",
        "        \n",
        "    for user in USERS:\n",
        "    # for gesture in GESTURES:\n",
        "        print('Processing data for user ' + user, end=' ')\n",
        "        # print(f\"processing data for gesture {gesture} \", end=\"...\" )\n",
        "        \n",
        "        X = []\n",
        "        y = []\n",
        "        first_time = True\n",
        "        \n",
        "        for gesture in GESTURES:\n",
        "        # for user in USERS:\n",
        "              \n",
        "            user_dir = os.path.join(BASE_DIR, DATA_DIR, user)\n",
        "            gesture_dir = os.path.join(user_dir, gesture + '.csv')\n",
        "\n",
        "            dataset = pd.read_csv(gesture_dir)\n",
        "\n",
        "            dataset['flex_1'] = dataset['flex_1'].rolling(3).median()\n",
        "            dataset['flex_2'] = dataset['flex_2'].rolling(3).median()\n",
        "            dataset['flex_3'] = dataset['flex_3'].rolling(3).median()\n",
        "            dataset['flex_4'] = dataset['flex_4'].rolling(3).median()\n",
        "            dataset['flex_5'] = dataset['flex_5'].rolling(3).median()\n",
        "\n",
        "            dataset.fillna(0, inplace=True)\n",
        "\n",
        "            # flex = ['flex_1', 'flex_2', 'flex_3', 'flex_4', 'flex_5']\n",
        "            # max_flex = dataset[flex].max(axis=1)\n",
        "            # max_flex.replace(0, 1, inplace=True)\n",
        "            # dataset[flex] = dataset[flex].divide(max_flex, axis=0)\n",
        "            \n",
        "            flx1 = dataset['flex_1'].to_numpy().reshape(-1, WINDOW_LEN)\n",
        "            flx2 = dataset['flex_2'].to_numpy().reshape(-1, WINDOW_LEN)\n",
        "            flx3 = dataset['flex_3'].to_numpy().reshape(-1, WINDOW_LEN)\n",
        "            flx4 = dataset['flex_4'].to_numpy().reshape(-1, WINDOW_LEN)\n",
        "            flx5 = dataset['flex_5'].to_numpy().reshape(-1, WINDOW_LEN)\n",
        "            \n",
        "            accx = dataset['ACCx'].to_numpy()\n",
        "            accy = dataset['ACCy'].to_numpy()\n",
        "            accz = dataset['ACCz'].to_numpy()\n",
        "            \n",
        "            accx = LowPassFilter.apply(accx).reshape(-1, WINDOW_LEN)\n",
        "            accy = LowPassFilter.apply(accy).reshape(-1, WINDOW_LEN)\n",
        "            accz = LowPassFilter.apply(accz).reshape(-1, WINDOW_LEN)\n",
        "            \n",
        "            gyrx = dataset['GYRx'].to_numpy()\n",
        "            gyry = dataset['GYRy'].to_numpy()\n",
        "            gyrz = dataset['GYRz'].to_numpy()\n",
        "            \n",
        "            gyrx = LowPassFilter.apply(gyrx).reshape(-1, WINDOW_LEN)\n",
        "            gyry = LowPassFilter.apply(gyry).reshape(-1, WINDOW_LEN)\n",
        "            gyrz = LowPassFilter.apply(gyrz).reshape(-1, WINDOW_LEN)\n",
        "            \n",
        "            accm = np.sqrt(accx ** 2 + accy ** 2 + accz ** 2)\n",
        "            gyrm = np.sqrt(gyrx ** 2 + gyry ** 2 + gyrz ** 2)\n",
        "            \n",
        "            g_idx = GESTURES.index(gesture)\n",
        "            labels = np.ones((accx.shape[0], 1)) * g_idx\n",
        "            \n",
        "            channels = np.stack([\n",
        "                flx1, flx2, flx3, flx4, flx5,\n",
        "                accx, accy, accz\n",
        "            ], axis=-1)\n",
        "            \n",
        "            if first_time == True:\n",
        "                X = channels\n",
        "                y = labels\n",
        "                first_time = False\n",
        "            else:\n",
        "                X = np.append(X, channels, axis=0)\n",
        "                y = np.append(y, labels, axis=0)\n",
        "            \n",
        "        \n",
        "        x_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_X.joblib')\n",
        "        y_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_y.joblib')\n",
        "        joblib.dump(X, x_path)\n",
        "        joblib.dump(y, y_path)\n",
        "        \n",
        "        print('√')\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "QmReRMF-qQcl",
      "metadata": {
        "id": "QmReRMF-qQcl"
      },
      "outputs": [],
      "source": [
        "# ------------- Spatial Path Image Generation ----------- #\n",
        "\n",
        "def clean_dir(path):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(path)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "    \n",
        "    print('creating ' + path + ' directory ... ', end='')\n",
        "    os.mkdir(path)\n",
        "    print('√')\n",
        "    \n",
        "# ----------- Spatial Path Vector Calculation ----------- #\n",
        "\n",
        "def get_displacement(acc):\n",
        "    v = np.zeros(acc.shape)\n",
        "    d = np.zeros(acc.shape)\n",
        "    for i in range(acc.shape[0] - 1):\n",
        "        v[i + 1] = v[i] + acc[i] * DT\n",
        "        d[i + 1] = v[i] * DT + 0.5 * acc[i] * DT * DT\n",
        "        \n",
        "    return d\n",
        "\n",
        "def write_image(x, y, path):\n",
        "    fig, ax = plt.subplots(frameon=True, figsize=(3, 3))\n",
        "    ax.axis('off')\n",
        "    plt.scatter(x, y, s=SHAPES, c='black')\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "def generate_bw_images():\n",
        "    image_dir = os.path.join(BASE_DIR, BW_IMG_DIR)\n",
        "    clean_dir(image_dir)\n",
        "    \n",
        "    for plane in PLANES:\n",
        "        print('processing spatial path images for ' + plane + ' plane ... ', end='')\n",
        "        plane_dir = os.path.join(image_dir, plane)\n",
        "        os.mkdir(plane_dir)\n",
        "        \n",
        "        # for gesture in GESTURES:\n",
        "        #     os.mkdir(os.path.join(plane_dir, gesture))\n",
        "\n",
        "        for user in USERS:\n",
        "            os.mkdir(os.path.join(plane_dir, user))\n",
        "    \n",
        "            # for user in USERS:\n",
        "            for gesture in GESTURES:\n",
        "                os.mkdir(os.path.join(plane_dir, user, gesture))\n",
        "                user_dir = os.path.join(BASE_DIR, DATA_DIR, user)\n",
        "                gesture_dir = os.path.join(user_dir, gesture + '.csv')\n",
        "                \n",
        "                accx = pd.read_csv(gesture_dir)['ACCx'].to_numpy()\n",
        "                accy = pd.read_csv(gesture_dir)['ACCy'].to_numpy()\n",
        "                accz = pd.read_csv(gesture_dir)['ACCz'].to_numpy()\n",
        "\n",
        "                x = get_displacement(accx).reshape(-1, 150)\n",
        "                y = get_displacement(accy).reshape(-1, 150)\n",
        "                z = get_displacement(accz).reshape(-1, 150)\n",
        "\n",
        "                count = 0\n",
        "                for i in range(x.shape[0]):\n",
        "                    # image_name = 'u' + user + '_g' + '{:0>2d}'.format(GESTURES.index(gesture)) + \\\n",
        "                    #              '_s' + '{:0>7d}'.format(count) + '_p' + plane + '.jpg'\n",
        "                    image_name = \"{:0>7d}\".format(count) + \".jpg\"\n",
        "                    path = os.path.join(plane_dir, user, gesture, image_name)\n",
        "                    \n",
        "                    if plane == 'XY':\n",
        "                        write_image(x[i, :], y[i, :], path)\n",
        "                    elif plane == 'YZ':\n",
        "                        write_image(y[i, :], z[i, :], path)\n",
        "                    else:\n",
        "                        write_image(z[i, :], x[i, :], path)\n",
        "\n",
        "                    count = count + 1\n",
        "            \n",
        "        print('√')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "07jhA8ukqScv",
      "metadata": {
        "id": "07jhA8ukqScv"
      },
      "outputs": [],
      "source": [
        "# extract_channels()\n",
        "# generate_bw_images()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "stylish-banner",
      "metadata": {
        "id": "stylish-banner"
      },
      "outputs": [],
      "source": [
        "def load_data(plane, test_user):\n",
        "    X_train = np.zeros((TRAIN_LEN, IMG_LEN, IMG_LEN, 3), dtype='uint8')\n",
        "    X_test = np.zeros((TEST_LEN, IMG_LEN, IMG_LEN, 3), dtype='uint8')\n",
        "    y_train = np.zeros((TRAIN_LEN, 1), dtype='uint8')\n",
        "    y_test = np.zeros((TEST_LEN, 1), dtype='uint8')\n",
        "    \n",
        "    train_count = 0\n",
        "    test_count = 0\n",
        "        \n",
        "    # for gesture in GESTURES:\n",
        "    for user in USERS:\n",
        "        print('loading data for user ' + user + ' on the ' + plane + ' plane ... ', end='')\n",
        "        user_dir = os.path.join(BASE_DIR, IMG_DIR, plane, user)\n",
        "\n",
        "        for gesture in GESTURES:\n",
        "            gesture_dir = os.path.join(user_dir, gesture)\n",
        "\n",
        "            # for filename in os.listdir(path):\n",
        "\n",
        "            for count in range(10):\n",
        "                image_name = \"{:0>7d}\".format(count) + \".jpg\"\n",
        "                img = cv2.imread(os.path.join(gesture_dir, image_name))\n",
        "                resized = cv2.resize(img, IMG_SIZE)\n",
        "                # resized = np.expand_dims(resized, axis=-1)\n",
        "                # label = int(filename[6:8])\n",
        "                if user != test_user:\n",
        "                    X_train[train_count, :] = resized\n",
        "                    y_train[train_count, 0] = GESTURES.index(gesture)\n",
        "                    train_count = train_count + 1\n",
        "                else:\n",
        "                    X_test[test_count, :] = resized\n",
        "                    y_test[test_count, 0] = GESTURES.index(gesture)\n",
        "                    test_count = test_count + 1\n",
        "                \n",
        "        print('√')\n",
        "        \n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def load_and_save_data(plane):\n",
        "    X = np.zeros((DATASET_LEN, IMG_LEN, IMG_LEN, 1))\n",
        "    y = np.zeros((DATASET_LEN, 1))\n",
        "    \n",
        "    train_count = 0\n",
        "    test_count  = TRAIN_LEN\n",
        "        \n",
        "    for gesture in GESTURES:\n",
        "        print('loading data for ' + gesture + ' gesture on the ' + plane + ' plane ... ', end='')\n",
        "        path = os.path.join(BASE_DIR, IMG_DIR, plane, gesture)\n",
        "        for filename in os.listdir(path):\n",
        "            img = cv2.imread(os.path.join(path, filename), cv2.IMREAD_GRAYSCALE)\n",
        "            resized = cv2.resize(img, IMG_SIZE)\n",
        "            if filename[1:4] != TEST_USER:\n",
        "                X[train_count, :] = resized\n",
        "                y[train_count, 0] = GESTURES.index(gesture)\n",
        "                train_count = train_count + 1\n",
        "            else:\n",
        "                X[test_count, :] = resized\n",
        "                y[test_count, 0] = GESTURES.index(gesture)\n",
        "                test_count = test_count + 1\n",
        "                \n",
        "        print('√')\n",
        "\n",
        "    joblib.dump(X, BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    joblib.dump(y, BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "\n",
        "def load_data_from_joblib(plane):\n",
        "    print('Loading data for ' + plane + ' plane ... ', end='')\n",
        "    X = joblib.load(BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    y = joblib.load(BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    test_user = int(TEST_USER)\n",
        "    X_train = X[:TRAIN_LEN, :, :, :]\n",
        "    y_train = y[:TRAIN_LEN, :]\n",
        "    X_test = X[TRAIN_LEN:, :, :, :]\n",
        "    y_test = y[TRAIN_LEN:, :]\n",
        "\n",
        "    print('√')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "extra-disclosure",
      "metadata": {
        "id": "extra-disclosure"
      },
      "outputs": [],
      "source": [
        "# X_train_xy, X_test_xy, y_train_xy, y_test_xy = load_data('XY')\n",
        "# X_train_yz, X_test_yz, y_train_yz, y_test_yz = load_data('YZ')\n",
        "# X_train_zx, X_test_zx, y_train_zx, y_test_zx = load_data('ZX')\n",
        "\n",
        "# Save to Google  Drive\n",
        "# load_and_save_data('XY')X_train_xy, y_train_xy = shuffle(X_train_xy, y_train_xy)\n",
        "# load_and_save_data('YZ')\n",
        "# load_and_save_data('ZX')\n",
        "\n",
        "# Load from Google Drive\n",
        "# X_train_xy, X_test_xy, y_train_xy, y_test_xy = load_data_from_joblib('XY')\n",
        "# X_train_yz, X_test_yz, y_train_yz, y_test_yz = load_data_from_joblib('YZ')\n",
        "# X_train_zx, X_test_zx, y_train_zx, y_test_zx = load_data_from_joblib('ZX')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "conditional-advisory",
      "metadata": {
        "id": "conditional-advisory"
      },
      "outputs": [],
      "source": [
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "internal-arkansas",
      "metadata": {
        "id": "internal-arkansas",
        "outputId": "02cf3aea-3282-42b1-deb1-586ec5a8065d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "\n",
        "# ... Change Model\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "strange-encoding",
      "metadata": {
        "id": "strange-encoding"
      },
      "outputs": [],
      "source": [
        "global_average_layer = GlobalAvgPool2D()\n",
        "prediction_layer = Dense(len(GESTURES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6e049e9a",
      "metadata": {
        "id": "6e049e9a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.keras.layers.pooling import MaxPooling2D\n",
        "\n",
        "def get_conv_block_1D():\n",
        "    input = Input(shape=(150, 1))\n",
        "    x = BatchNormalization()(input)\n",
        "    x = Conv1D(filters=8, kernel_size=3, activation='relu', padding='valid')(x)\n",
        "    x = Conv1D(filters=16, kernel_size=3, activation='relu', padding='valid')(x)\n",
        "    x = MaxPooling1D(2)(x)\n",
        "    x = Conv1D(filters=16, kernel_size=3, activation='relu', padding='valid')(x)\n",
        "    x = Conv1D(filters=16, kernel_size=3, activation='relu', padding='valid')(x)\n",
        "    x = MaxPooling1D(2)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(50, activation='relu')(x)\n",
        "\n",
        "    return input, x\n",
        "\n",
        "def get_conv_block_2D():\n",
        "    input = tf.keras.layers.Input(shape=IMG_SHAPE)\n",
        "    # x = data_augmentation(input)\n",
        "    x = preprocess_input(input)\n",
        "    x = base_model(x, training=False)\n",
        "    x = global_average_layer(x)\n",
        "\n",
        "    # x = layers.Conv2D(16, 3, padding=\"valid\", kernel_regularizer=regularizers.l2(0.001),)(\n",
        "    #     input\n",
        "    # )\n",
        "    # x = layers.BatchNormalization()(x)\n",
        "    # x = tf.keras.activations.relu(x)\n",
        "    # x = layers.MaxPooling2D()(x)\n",
        "    # x = layers.Conv2D(32, 3, padding=\"valid\", kernel_regularizer=regularizers.l2(0.001),)(\n",
        "    #     x\n",
        "    # )\n",
        "    # x = layers.BatchNormalization()(x)\n",
        "    # x = tf.keras.activations.relu(x)\n",
        "    # x = layers.MaxPooling2D()(x)\n",
        "    # x = layers.Conv2D(\n",
        "    #     64, 3, padding=\"valid\", kernel_regularizer=regularizers.l2(0.001),\n",
        "    # )(x)\n",
        "    # x = layers.BatchNormalization()(x)\n",
        "    # x = tf.keras.activations.relu(x)\n",
        "    # x = layers.Flatten()(x)\n",
        "\n",
        "    return input, x\n",
        "\n",
        "\n",
        "def get_stacked_model():\n",
        "    inputs = []\n",
        "    CNNs = []\n",
        "\n",
        "    for i in range(5):\n",
        "        input_i, CNN_i = get_conv_block_1D()\n",
        "        inputs.append(input_i)\n",
        "        CNNs.append(CNN_i)\n",
        "\n",
        "    for i in range(3):\n",
        "        input_i, CNN_i = get_conv_block_2D()\n",
        "        inputs.append(input_i)\n",
        "        CNNs.append(CNN_i)\n",
        "\n",
        "    x = concatenate(CNNs, axis=-1)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    output = Dense(16, activation=\"softmax\")(x)\n",
        "    model = Model(inputs, output)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    loss = SparseCategoricalCrossentropy(from_logits=False)\n",
        "    model.compile(loss=loss, optimizer=opt, metrics=[\"accuracy\"])\n",
        "    \n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "WTWKoIlYyzKW",
      "metadata": {
        "id": "WTWKoIlYyzKW",
        "outputId": "a4f8ef44-e9d9-4a4e-cb50-9e0721d5c794",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 150, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 150, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 150, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 150, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, 150, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 150, 1)      4           ['input_2[0][0]']                \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 150, 1)      4           ['input_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 150, 1)      4           ['input_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 150, 1)      4           ['input_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 150, 1)      4           ['input_6[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 148, 8)       32          ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 148, 8)       32          ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 148, 8)       32          ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 148, 8)       32          ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)             (None, 148, 8)       32          ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 146, 16)      400         ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 146, 16)      400         ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 146, 16)      400         ['conv1d_8[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 146, 16)      400         ['conv1d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)             (None, 146, 16)      400         ['conv1d_16[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 73, 16)       0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling1d_2 (MaxPooling1D)  (None, 73, 16)      0           ['conv1d_5[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling1d_4 (MaxPooling1D)  (None, 73, 16)      0           ['conv1d_9[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling1d_6 (MaxPooling1D)  (None, 73, 16)      0           ['conv1d_13[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling1d_8 (MaxPooling1D)  (None, 73, 16)      0           ['conv1d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 71, 16)       784         ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 71, 16)       784         ['max_pooling1d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 71, 16)       784         ['max_pooling1d_4[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 71, 16)       784         ['max_pooling1d_6[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)             (None, 71, 16)       784         ['max_pooling1d_8[0][0]']        \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " input_9 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 69, 16)       784         ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 69, 16)       784         ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 69, 16)       784         ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)             (None, 69, 16)       784         ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_19 (Conv1D)             (None, 69, 16)       784         ['conv1d_18[0][0]']              \n",
            "                                                                                                  \n",
            " tf.math.truediv (TFOpLambda)   (None, 224, 224, 3)  0           ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.truediv_1 (TFOpLambda)  (None, 224, 224, 3)  0          ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.truediv_2 (TFOpLambda)  (None, 224, 224, 3)  0          ['input_9[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 34, 16)      0           ['conv1d_3[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling1d_3 (MaxPooling1D)  (None, 34, 16)      0           ['conv1d_7[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling1d_5 (MaxPooling1D)  (None, 34, 16)      0           ['conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling1d_7 (MaxPooling1D)  (None, 34, 16)      0           ['conv1d_15[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling1d_9 (MaxPooling1D)  (None, 34, 16)      0           ['conv1d_19[0][0]']              \n",
            "                                                                                                  \n",
            " tf.math.subtract (TFOpLambda)  (None, 224, 224, 3)  0           ['tf.math.truediv[0][0]']        \n",
            "                                                                                                  \n",
            " tf.math.subtract_1 (TFOpLambda  (None, 224, 224, 3)  0          ['tf.math.truediv_1[0][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.subtract_2 (TFOpLambda  (None, 224, 224, 3)  0          ['tf.math.truediv_2[0][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 544)          0           ['max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 544)          0           ['max_pooling1d_3[0][0]']        \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 544)          0           ['max_pooling1d_5[0][0]']        \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 544)          0           ['max_pooling1d_7[0][0]']        \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)            (None, 544)          0           ['max_pooling1d_9[0][0]']        \n",
            "                                                                                                  \n",
            " mobilenetv2_1.00_224 (Function  (None, 7, 7, 1280)  2257984     ['tf.math.subtract[0][0]',       \n",
            " al)                                                              'tf.math.subtract_1[0][0]',     \n",
            "                                                                  'tf.math.subtract_2[0][0]']     \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 50)           27250       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 50)           27250       ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 50)           27250       ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 50)           27250       ['flatten_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 50)           27250       ['flatten_4[0][0]']              \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 1280)        0           ['mobilenetv2_1.00_224[0][0]',   \n",
            " alAveragePooling2D)                                              'mobilenetv2_1.00_224[1][0]',   \n",
            "                                                                  'mobilenetv2_1.00_224[2][0]']   \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 4090)         0           ['dense_1[0][0]',                \n",
            "                                                                  'dense_2[0][0]',                \n",
            "                                                                  'dense_3[0][0]',                \n",
            "                                                                  'dense_4[0][0]',                \n",
            "                                                                  'dense_5[0][0]',                \n",
            "                                                                  'global_average_pooling2d[0][0]'\n",
            "                                                                 , 'global_average_pooling2d[1][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'global_average_pooling2d[2][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 4090)         0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 128)          523648      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 128)          0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 16)           2064        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,929,966\n",
            "Trainable params: 671,972\n",
            "Non-trainable params: 2,257,994\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = get_stacked_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "upper-tobago",
      "metadata": {
        "id": "upper-tobago"
      },
      "outputs": [],
      "source": [
        "# def get_model():\n",
        "#     inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
        "#     #     x = data_augmentation(inputs)\n",
        "#     x = preprocess_input(inputs)\n",
        "#     x = base_model(x, training=False)\n",
        "#     x = global_average_layer(x)\n",
        "#     x = tf.keras.layers.Dropout(0.2)(x)\n",
        "#     outputs = prediction_layer(x)\n",
        "#     model = tf.keras.Model(inputs, outputs)\n",
        "#     model.compile(\n",
        "#         optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE, decay=DECAY),\n",
        "#         loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#         metrics=[\"accuracy\"],\n",
        "#     )\n",
        "#     return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b3a457f4",
      "metadata": {
        "id": "b3a457f4",
        "outputId": "37b6c21b-a043-456d-c83c-3ffa651870bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing results for user 017... \n",
            "loading data for user 001 on the XY plane ... √\n",
            "loading data for user 002 on the XY plane ... √\n",
            "loading data for user 003 on the XY plane ... √\n",
            "loading data for user 004 on the XY plane ... √\n",
            "loading data for user 005 on the XY plane ... √\n",
            "loading data for user 006 on the XY plane ... √\n",
            "loading data for user 007 on the XY plane ... √\n",
            "loading data for user 008 on the XY plane ... √\n",
            "loading data for user 009 on the XY plane ... √\n",
            "loading data for user 010 on the XY plane ... √\n",
            "loading data for user 011 on the XY plane ... √\n",
            "loading data for user 012 on the XY plane ... √\n",
            "loading data for user 013 on the XY plane ... √\n",
            "loading data for user 014 on the XY plane ... √\n",
            "loading data for user 015 on the XY plane ... √\n",
            "loading data for user 016 on the XY plane ... √\n",
            "loading data for user 017 on the XY plane ... √\n",
            "loading data for user 018 on the XY plane ... √\n",
            "loading data for user 019 on the XY plane ... √\n",
            "loading data for user 020 on the XY plane ... √\n",
            "loading data for user 021 on the XY plane ... √\n",
            "loading data for user 022 on the XY plane ... √\n",
            "loading data for user 023 on the XY plane ... √\n",
            "loading data for user 024 on the XY plane ... √\n",
            "loading data for user 025 on the XY plane ... √\n",
            "loading data for user 001 on the YZ plane ... √\n",
            "loading data for user 002 on the YZ plane ... √\n",
            "loading data for user 003 on the YZ plane ... √\n",
            "loading data for user 004 on the YZ plane ... √\n",
            "loading data for user 005 on the YZ plane ... √\n",
            "loading data for user 006 on the YZ plane ... √\n",
            "loading data for user 007 on the YZ plane ... √\n",
            "loading data for user 008 on the YZ plane ... √\n",
            "loading data for user 009 on the YZ plane ... √\n",
            "loading data for user 010 on the YZ plane ... √\n",
            "loading data for user 011 on the YZ plane ... √\n",
            "loading data for user 012 on the YZ plane ... √\n",
            "loading data for user 013 on the YZ plane ... √\n",
            "loading data for user 014 on the YZ plane ... √\n",
            "loading data for user 015 on the YZ plane ... √\n",
            "loading data for user 016 on the YZ plane ... √\n",
            "loading data for user 017 on the YZ plane ... √\n",
            "loading data for user 018 on the YZ plane ... √\n",
            "loading data for user 019 on the YZ plane ... √\n",
            "loading data for user 020 on the YZ plane ... √\n",
            "loading data for user 021 on the YZ plane ... √\n",
            "loading data for user 022 on the YZ plane ... √\n",
            "loading data for user 023 on the YZ plane ... √\n",
            "loading data for user 024 on the YZ plane ... √\n",
            "loading data for user 025 on the YZ plane ... √\n",
            "loading data for user 001 on the ZX plane ... √\n",
            "loading data for user 002 on the ZX plane ... √\n",
            "loading data for user 003 on the ZX plane ... √\n",
            "loading data for user 004 on the ZX plane ... √\n",
            "loading data for user 005 on the ZX plane ... √\n",
            "loading data for user 006 on the ZX plane ... √\n",
            "loading data for user 007 on the ZX plane ... √\n",
            "loading data for user 008 on the ZX plane ... √\n",
            "loading data for user 009 on the ZX plane ... √\n",
            "loading data for user 010 on the ZX plane ... √\n",
            "loading data for user 011 on the ZX plane ... √\n",
            "loading data for user 012 on the ZX plane ... √\n",
            "loading data for user 013 on the ZX plane ... √\n",
            "loading data for user 014 on the ZX plane ... √\n",
            "loading data for user 015 on the ZX plane ... √\n",
            "loading data for user 016 on the ZX plane ... √\n",
            "loading data for user 017 on the ZX plane ... √\n",
            "loading data for user 018 on the ZX plane ... √\n",
            "loading data for user 019 on the ZX plane ... √\n",
            "loading data for user 020 on the ZX plane ... √\n",
            "loading data for user 021 on the ZX plane ... √\n",
            "loading data for user 022 on the ZX plane ... √\n",
            "loading data for user 023 on the ZX plane ... √\n",
            "loading data for user 024 on the ZX plane ... √\n",
            "loading data for user 025 on the ZX plane ... √\n",
            "8\n",
            "Epoch 1/300\n",
            "60/60 [==============================] - 34s 262ms/step - loss: 2.5831 - accuracy: 0.1974 - val_loss: 1.5254 - val_accuracy: 0.6938\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 13s 213ms/step - loss: 1.5881 - accuracy: 0.4904 - val_loss: 0.6032 - val_accuracy: 0.9688\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 13s 213ms/step - loss: 0.9818 - accuracy: 0.6906 - val_loss: 0.2322 - val_accuracy: 0.9750\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 13s 213ms/step - loss: 0.6381 - accuracy: 0.8008 - val_loss: 0.1233 - val_accuracy: 0.9875\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.5019 - accuracy: 0.8391 - val_loss: 0.1003 - val_accuracy: 0.9750\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.3881 - accuracy: 0.8771 - val_loss: 0.0767 - val_accuracy: 0.9875\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.3352 - accuracy: 0.8927 - val_loss: 0.0448 - val_accuracy: 0.9937\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.2767 - accuracy: 0.9143 - val_loss: 0.0360 - val_accuracy: 0.9937\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.2518 - accuracy: 0.9219 - val_loss: 0.0350 - val_accuracy: 0.9937\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.2055 - accuracy: 0.9349 - val_loss: 0.0354 - val_accuracy: 0.9937\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.1765 - accuracy: 0.9432 - val_loss: 0.0396 - val_accuracy: 0.9875\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.1651 - accuracy: 0.9479 - val_loss: 0.0316 - val_accuracy: 0.9937\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.1537 - accuracy: 0.9565 - val_loss: 0.0299 - val_accuracy: 0.9937\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.1388 - accuracy: 0.9573 - val_loss: 0.0259 - val_accuracy: 0.9937\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.1318 - accuracy: 0.9607 - val_loss: 0.0360 - val_accuracy: 0.9875\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.1250 - accuracy: 0.9594 - val_loss: 0.0280 - val_accuracy: 0.9937\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.1092 - accuracy: 0.9674 - val_loss: 0.0254 - val_accuracy: 0.9875\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.1149 - accuracy: 0.9630 - val_loss: 0.0266 - val_accuracy: 0.9875\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.1025 - accuracy: 0.9661 - val_loss: 0.0216 - val_accuracy: 0.9937\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0906 - accuracy: 0.9724 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.0959 - accuracy: 0.9706 - val_loss: 0.0311 - val_accuracy: 0.9875\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.0857 - accuracy: 0.9740 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0830 - accuracy: 0.9745 - val_loss: 0.0239 - val_accuracy: 0.9875\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.0742 - accuracy: 0.9763 - val_loss: 0.0349 - val_accuracy: 0.9875\n",
            "Epoch 25/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0729 - accuracy: 0.9789 - val_loss: 0.0220 - val_accuracy: 0.9937\n",
            "Epoch 26/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0753 - accuracy: 0.9747 - val_loss: 0.0201 - val_accuracy: 0.9937\n",
            "Epoch 27/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0724 - accuracy: 0.9766 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
            "Epoch 28/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0592 - accuracy: 0.9846 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 29/300\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.0607 - accuracy: 0.9836 - val_loss: 0.0188 - val_accuracy: 0.9937\n",
            "Epoch 30/300\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.0594 - accuracy: 0.9831 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 31/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0588 - accuracy: 0.9839 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 32/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0571 - accuracy: 0.9841 - val_loss: 0.0150 - val_accuracy: 0.9937\n",
            "Epoch 33/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0520 - accuracy: 0.9836 - val_loss: 0.0240 - val_accuracy: 0.9937\n",
            "Epoch 34/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0453 - accuracy: 0.9865 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 35/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0518 - accuracy: 0.9831 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 36/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0485 - accuracy: 0.9849 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 37/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0471 - accuracy: 0.9859 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 38/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0442 - accuracy: 0.9862 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 39/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0439 - accuracy: 0.9878 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
            "Epoch 40/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0411 - accuracy: 0.9888 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 41/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0384 - accuracy: 0.9875 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 42/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0390 - accuracy: 0.9888 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 43/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0372 - accuracy: 0.9901 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 44/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0342 - accuracy: 0.9888 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "Epoch 45/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0345 - accuracy: 0.9898 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 46/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0318 - accuracy: 0.9909 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 47/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0304 - accuracy: 0.9917 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 48/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0287 - accuracy: 0.9927 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 49/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0285 - accuracy: 0.9919 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 50/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0295 - accuracy: 0.9924 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "3/3 [==============================] - 1s 156ms/step - loss: 0.0100 - accuracy: 1.0000\n",
            "100.00 %\n",
            "Processing results for user 018... \n",
            "loading data for user 001 on the XY plane ... √\n",
            "loading data for user 002 on the XY plane ... √\n",
            "loading data for user 003 on the XY plane ... √\n",
            "loading data for user 004 on the XY plane ... √\n",
            "loading data for user 005 on the XY plane ... √\n",
            "loading data for user 006 on the XY plane ... √\n",
            "loading data for user 007 on the XY plane ... √\n",
            "loading data for user 008 on the XY plane ... √\n",
            "loading data for user 009 on the XY plane ... √\n",
            "loading data for user 010 on the XY plane ... √\n",
            "loading data for user 011 on the XY plane ... √\n",
            "loading data for user 012 on the XY plane ... √\n",
            "loading data for user 013 on the XY plane ... √\n",
            "loading data for user 014 on the XY plane ... √\n",
            "loading data for user 015 on the XY plane ... √\n",
            "loading data for user 016 on the XY plane ... √\n",
            "loading data for user 017 on the XY plane ... √\n",
            "loading data for user 018 on the XY plane ... √\n",
            "loading data for user 019 on the XY plane ... √\n",
            "loading data for user 020 on the XY plane ... √\n",
            "loading data for user 021 on the XY plane ... √\n",
            "loading data for user 022 on the XY plane ... √\n",
            "loading data for user 023 on the XY plane ... √\n",
            "loading data for user 024 on the XY plane ... √\n",
            "loading data for user 025 on the XY plane ... √\n",
            "loading data for user 001 on the YZ plane ... √\n",
            "loading data for user 002 on the YZ plane ... √\n",
            "loading data for user 003 on the YZ plane ... √\n",
            "loading data for user 004 on the YZ plane ... √\n",
            "loading data for user 005 on the YZ plane ... √\n",
            "loading data for user 006 on the YZ plane ... √\n",
            "loading data for user 007 on the YZ plane ... √\n",
            "loading data for user 008 on the YZ plane ... √\n",
            "loading data for user 009 on the YZ plane ... √\n",
            "loading data for user 010 on the YZ plane ... √\n",
            "loading data for user 011 on the YZ plane ... √\n",
            "loading data for user 012 on the YZ plane ... √\n",
            "loading data for user 013 on the YZ plane ... √\n",
            "loading data for user 014 on the YZ plane ... √\n",
            "loading data for user 015 on the YZ plane ... √\n",
            "loading data for user 016 on the YZ plane ... √\n",
            "loading data for user 017 on the YZ plane ... √\n",
            "loading data for user 018 on the YZ plane ... √\n",
            "loading data for user 019 on the YZ plane ... √\n",
            "loading data for user 020 on the YZ plane ... √\n",
            "loading data for user 021 on the YZ plane ... √\n",
            "loading data for user 022 on the YZ plane ... √\n",
            "loading data for user 023 on the YZ plane ... √\n",
            "loading data for user 024 on the YZ plane ... √\n",
            "loading data for user 025 on the YZ plane ... √\n",
            "loading data for user 001 on the ZX plane ... √\n",
            "loading data for user 002 on the ZX plane ... √\n",
            "loading data for user 003 on the ZX plane ... √\n",
            "loading data for user 004 on the ZX plane ... √\n",
            "loading data for user 005 on the ZX plane ... √\n",
            "loading data for user 006 on the ZX plane ... √\n",
            "loading data for user 007 on the ZX plane ... √\n",
            "loading data for user 008 on the ZX plane ... √\n",
            "loading data for user 009 on the ZX plane ... √\n",
            "loading data for user 010 on the ZX plane ... √\n",
            "loading data for user 011 on the ZX plane ... √\n",
            "loading data for user 012 on the ZX plane ... √\n",
            "loading data for user 013 on the ZX plane ... √\n",
            "loading data for user 014 on the ZX plane ... √\n",
            "loading data for user 015 on the ZX plane ... √\n",
            "loading data for user 016 on the ZX plane ... √\n",
            "loading data for user 017 on the ZX plane ... √\n",
            "loading data for user 018 on the ZX plane ... √\n",
            "loading data for user 019 on the ZX plane ... √\n",
            "loading data for user 020 on the ZX plane ... √\n",
            "loading data for user 021 on the ZX plane ... √\n",
            "loading data for user 022 on the ZX plane ... √\n",
            "loading data for user 023 on the ZX plane ... √\n",
            "loading data for user 024 on the ZX plane ... √\n",
            "loading data for user 025 on the ZX plane ... √\n",
            "8\n",
            "Epoch 1/300\n",
            "60/60 [==============================] - 23s 254ms/step - loss: 2.5935 - accuracy: 0.2008 - val_loss: 1.5401 - val_accuracy: 0.7437\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 1.6360 - accuracy: 0.4875 - val_loss: 0.6299 - val_accuracy: 0.9375\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.9787 - accuracy: 0.6961 - val_loss: 0.2612 - val_accuracy: 0.9250\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.5932 - accuracy: 0.8133 - val_loss: 0.1104 - val_accuracy: 0.9875\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.4538 - accuracy: 0.8589 - val_loss: 0.0598 - val_accuracy: 1.0000\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.3824 - accuracy: 0.8805 - val_loss: 0.0629 - val_accuracy: 0.9937\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.3146 - accuracy: 0.9010 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.2763 - accuracy: 0.9078 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.2572 - accuracy: 0.9229 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1964 - accuracy: 0.9393 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1892 - accuracy: 0.9409 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.1670 - accuracy: 0.9474 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1487 - accuracy: 0.9526 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.1428 - accuracy: 0.9560 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1220 - accuracy: 0.9628 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.1212 - accuracy: 0.9630 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1129 - accuracy: 0.9656 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1039 - accuracy: 0.9721 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1009 - accuracy: 0.9685 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0838 - accuracy: 0.9776 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0909 - accuracy: 0.9716 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0855 - accuracy: 0.9742 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0804 - accuracy: 0.9742 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0695 - accuracy: 0.9810 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 25/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0772 - accuracy: 0.9763 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 26/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0627 - accuracy: 0.9799 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 27/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0630 - accuracy: 0.9807 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 28/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0679 - accuracy: 0.9779 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 29/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0590 - accuracy: 0.9831 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 30/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0536 - accuracy: 0.9841 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 31/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0546 - accuracy: 0.9812 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 32/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0524 - accuracy: 0.9857 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 33/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0549 - accuracy: 0.9826 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 34/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0493 - accuracy: 0.9844 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 35/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0443 - accuracy: 0.9859 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.0598 - accuracy: 1.0000\n",
            "100.00 %\n",
            "Processing results for user 019... \n",
            "loading data for user 001 on the XY plane ... √\n",
            "loading data for user 002 on the XY plane ... √\n",
            "loading data for user 003 on the XY plane ... √\n",
            "loading data for user 004 on the XY plane ... √\n",
            "loading data for user 005 on the XY plane ... √\n",
            "loading data for user 006 on the XY plane ... √\n",
            "loading data for user 007 on the XY plane ... √\n",
            "loading data for user 008 on the XY plane ... √\n",
            "loading data for user 009 on the XY plane ... √\n",
            "loading data for user 010 on the XY plane ... √\n",
            "loading data for user 011 on the XY plane ... √\n",
            "loading data for user 012 on the XY plane ... √\n",
            "loading data for user 013 on the XY plane ... √\n",
            "loading data for user 014 on the XY plane ... √\n",
            "loading data for user 015 on the XY plane ... √\n",
            "loading data for user 016 on the XY plane ... √\n",
            "loading data for user 017 on the XY plane ... √\n",
            "loading data for user 018 on the XY plane ... √\n",
            "loading data for user 019 on the XY plane ... √\n",
            "loading data for user 020 on the XY plane ... √\n",
            "loading data for user 021 on the XY plane ... √\n",
            "loading data for user 022 on the XY plane ... √\n",
            "loading data for user 023 on the XY plane ... √\n",
            "loading data for user 024 on the XY plane ... √\n",
            "loading data for user 025 on the XY plane ... √\n",
            "loading data for user 001 on the YZ plane ... √\n",
            "loading data for user 002 on the YZ plane ... √\n",
            "loading data for user 003 on the YZ plane ... √\n",
            "loading data for user 004 on the YZ plane ... √\n",
            "loading data for user 005 on the YZ plane ... √\n",
            "loading data for user 006 on the YZ plane ... √\n",
            "loading data for user 007 on the YZ plane ... √\n",
            "loading data for user 008 on the YZ plane ... √\n",
            "loading data for user 009 on the YZ plane ... √\n",
            "loading data for user 010 on the YZ plane ... √\n",
            "loading data for user 011 on the YZ plane ... √\n",
            "loading data for user 012 on the YZ plane ... √\n",
            "loading data for user 013 on the YZ plane ... √\n",
            "loading data for user 014 on the YZ plane ... √\n",
            "loading data for user 015 on the YZ plane ... √\n",
            "loading data for user 016 on the YZ plane ... √\n",
            "loading data for user 017 on the YZ plane ... √\n",
            "loading data for user 018 on the YZ plane ... √\n",
            "loading data for user 019 on the YZ plane ... √\n",
            "loading data for user 020 on the YZ plane ... √\n",
            "loading data for user 021 on the YZ plane ... √\n",
            "loading data for user 022 on the YZ plane ... √\n",
            "loading data for user 023 on the YZ plane ... √\n",
            "loading data for user 024 on the YZ plane ... √\n",
            "loading data for user 025 on the YZ plane ... √\n",
            "loading data for user 001 on the ZX plane ... √\n",
            "loading data for user 002 on the ZX plane ... √\n",
            "loading data for user 003 on the ZX plane ... √\n",
            "loading data for user 004 on the ZX plane ... √\n",
            "loading data for user 005 on the ZX plane ... √\n",
            "loading data for user 006 on the ZX plane ... √\n",
            "loading data for user 007 on the ZX plane ... √\n",
            "loading data for user 008 on the ZX plane ... √\n",
            "loading data for user 009 on the ZX plane ... √\n",
            "loading data for user 010 on the ZX plane ... √\n",
            "loading data for user 011 on the ZX plane ... √\n",
            "loading data for user 012 on the ZX plane ... √\n",
            "loading data for user 013 on the ZX plane ... √\n",
            "loading data for user 014 on the ZX plane ... √\n",
            "loading data for user 015 on the ZX plane ... √\n",
            "loading data for user 016 on the ZX plane ... √\n",
            "loading data for user 017 on the ZX plane ... √\n",
            "loading data for user 018 on the ZX plane ... √\n",
            "loading data for user 019 on the ZX plane ... √\n",
            "loading data for user 020 on the ZX plane ... √\n",
            "loading data for user 021 on the ZX plane ... √\n",
            "loading data for user 022 on the ZX plane ... √\n",
            "loading data for user 023 on the ZX plane ... √\n",
            "loading data for user 024 on the ZX plane ... √\n",
            "loading data for user 025 on the ZX plane ... √\n",
            "8\n",
            "Epoch 1/300\n",
            "60/60 [==============================] - 22s 253ms/step - loss: 2.6579 - accuracy: 0.1732 - val_loss: 1.7816 - val_accuracy: 0.6500\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 1.7226 - accuracy: 0.4523 - val_loss: 0.6781 - val_accuracy: 0.9438\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.9754 - accuracy: 0.6940 - val_loss: 0.2767 - val_accuracy: 0.9563\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.6520 - accuracy: 0.7904 - val_loss: 0.1751 - val_accuracy: 0.9750\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.4540 - accuracy: 0.8518 - val_loss: 0.1551 - val_accuracy: 0.9438\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.3885 - accuracy: 0.8771 - val_loss: 0.1152 - val_accuracy: 0.9688\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.3021 - accuracy: 0.9052 - val_loss: 0.1072 - val_accuracy: 0.9688\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.2603 - accuracy: 0.9174 - val_loss: 0.1000 - val_accuracy: 0.9688\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.2255 - accuracy: 0.9305 - val_loss: 0.0790 - val_accuracy: 0.9937\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.2021 - accuracy: 0.9367 - val_loss: 0.0693 - val_accuracy: 0.9812\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.1899 - accuracy: 0.9370 - val_loss: 0.0780 - val_accuracy: 0.9812\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.1629 - accuracy: 0.9516 - val_loss: 0.0685 - val_accuracy: 0.9875\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1491 - accuracy: 0.9516 - val_loss: 0.0585 - val_accuracy: 0.9937\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.1363 - accuracy: 0.9576 - val_loss: 0.0733 - val_accuracy: 0.9750\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.1276 - accuracy: 0.9628 - val_loss: 0.0718 - val_accuracy: 0.9688\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.1195 - accuracy: 0.9641 - val_loss: 0.0905 - val_accuracy: 0.9625\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.1081 - accuracy: 0.9674 - val_loss: 0.0536 - val_accuracy: 0.9937\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0999 - accuracy: 0.9695 - val_loss: 0.0429 - val_accuracy: 0.9937\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0919 - accuracy: 0.9714 - val_loss: 0.0659 - val_accuracy: 0.9750\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0969 - accuracy: 0.9719 - val_loss: 0.0573 - val_accuracy: 0.9875\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0871 - accuracy: 0.9737 - val_loss: 0.0607 - val_accuracy: 0.9812\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0793 - accuracy: 0.9737 - val_loss: 0.0447 - val_accuracy: 0.9875\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0803 - accuracy: 0.9758 - val_loss: 0.0680 - val_accuracy: 0.9688\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0785 - accuracy: 0.9781 - val_loss: 0.0515 - val_accuracy: 0.9812\n",
            "Epoch 25/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0708 - accuracy: 0.9771 - val_loss: 0.0580 - val_accuracy: 0.9875\n",
            "Epoch 26/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0670 - accuracy: 0.9776 - val_loss: 0.0513 - val_accuracy: 0.9812\n",
            "Epoch 27/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0649 - accuracy: 0.9826 - val_loss: 0.0404 - val_accuracy: 0.9875\n",
            "Epoch 28/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0572 - accuracy: 0.9831 - val_loss: 0.0510 - val_accuracy: 0.9875\n",
            "Epoch 29/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0589 - accuracy: 0.9807 - val_loss: 0.0390 - val_accuracy: 0.9875\n",
            "Epoch 30/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0533 - accuracy: 0.9846 - val_loss: 0.0383 - val_accuracy: 0.9812\n",
            "Epoch 31/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0562 - accuracy: 0.9820 - val_loss: 0.0336 - val_accuracy: 0.9937\n",
            "Epoch 32/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0510 - accuracy: 0.9839 - val_loss: 0.0596 - val_accuracy: 0.9750\n",
            "Epoch 33/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0449 - accuracy: 0.9883 - val_loss: 0.0361 - val_accuracy: 0.9875\n",
            "Epoch 34/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0490 - accuracy: 0.9854 - val_loss: 0.0392 - val_accuracy: 0.9875\n",
            "Epoch 35/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0413 - accuracy: 0.9891 - val_loss: 0.0541 - val_accuracy: 0.9750\n",
            "Epoch 36/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0482 - accuracy: 0.9839 - val_loss: 0.0562 - val_accuracy: 0.9688\n",
            "Epoch 37/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0329 - accuracy: 0.9896 - val_loss: 0.0390 - val_accuracy: 0.9812\n",
            "Epoch 38/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0394 - accuracy: 0.9880 - val_loss: 0.0319 - val_accuracy: 0.9937\n",
            "Epoch 39/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0379 - accuracy: 0.9906 - val_loss: 0.0329 - val_accuracy: 0.9875\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.0790 - accuracy: 0.9937\n",
            "99.37 %\n",
            "Processing results for user 020... \n",
            "loading data for user 001 on the XY plane ... √\n",
            "loading data for user 002 on the XY plane ... √\n",
            "loading data for user 003 on the XY plane ... √\n",
            "loading data for user 004 on the XY plane ... √\n",
            "loading data for user 005 on the XY plane ... √\n",
            "loading data for user 006 on the XY plane ... √\n",
            "loading data for user 007 on the XY plane ... √\n",
            "loading data for user 008 on the XY plane ... √\n",
            "loading data for user 009 on the XY plane ... √\n",
            "loading data for user 010 on the XY plane ... √\n",
            "loading data for user 011 on the XY plane ... √\n",
            "loading data for user 012 on the XY plane ... √\n",
            "loading data for user 013 on the XY plane ... √\n",
            "loading data for user 014 on the XY plane ... √\n",
            "loading data for user 015 on the XY plane ... √\n",
            "loading data for user 016 on the XY plane ... √\n",
            "loading data for user 017 on the XY plane ... √\n",
            "loading data for user 018 on the XY plane ... √\n",
            "loading data for user 019 on the XY plane ... √\n",
            "loading data for user 020 on the XY plane ... √\n",
            "loading data for user 021 on the XY plane ... √\n",
            "loading data for user 022 on the XY plane ... √\n",
            "loading data for user 023 on the XY plane ... √\n",
            "loading data for user 024 on the XY plane ... √\n",
            "loading data for user 025 on the XY plane ... √\n",
            "loading data for user 001 on the YZ plane ... √\n",
            "loading data for user 002 on the YZ plane ... √\n",
            "loading data for user 003 on the YZ plane ... √\n",
            "loading data for user 004 on the YZ plane ... √\n",
            "loading data for user 005 on the YZ plane ... √\n",
            "loading data for user 006 on the YZ plane ... √\n",
            "loading data for user 007 on the YZ plane ... √\n",
            "loading data for user 008 on the YZ plane ... √\n",
            "loading data for user 009 on the YZ plane ... √\n",
            "loading data for user 010 on the YZ plane ... √\n",
            "loading data for user 011 on the YZ plane ... √\n",
            "loading data for user 012 on the YZ plane ... √\n",
            "loading data for user 013 on the YZ plane ... √\n",
            "loading data for user 014 on the YZ plane ... √\n",
            "loading data for user 015 on the YZ plane ... √\n",
            "loading data for user 016 on the YZ plane ... √\n",
            "loading data for user 017 on the YZ plane ... √\n",
            "loading data for user 018 on the YZ plane ... √\n",
            "loading data for user 019 on the YZ plane ... √\n",
            "loading data for user 020 on the YZ plane ... √\n",
            "loading data for user 021 on the YZ plane ... √\n",
            "loading data for user 022 on the YZ plane ... √\n",
            "loading data for user 023 on the YZ plane ... √\n",
            "loading data for user 024 on the YZ plane ... √\n",
            "loading data for user 025 on the YZ plane ... √\n",
            "loading data for user 001 on the ZX plane ... √\n",
            "loading data for user 002 on the ZX plane ... √\n",
            "loading data for user 003 on the ZX plane ... √\n",
            "loading data for user 004 on the ZX plane ... √\n",
            "loading data for user 005 on the ZX plane ... √\n",
            "loading data for user 006 on the ZX plane ... √\n",
            "loading data for user 007 on the ZX plane ... √\n",
            "loading data for user 008 on the ZX plane ... √\n",
            "loading data for user 009 on the ZX plane ... √\n",
            "loading data for user 010 on the ZX plane ... √\n",
            "loading data for user 011 on the ZX plane ... √\n",
            "loading data for user 012 on the ZX plane ... √\n",
            "loading data for user 013 on the ZX plane ... √\n",
            "loading data for user 014 on the ZX plane ... √\n",
            "loading data for user 015 on the ZX plane ... √\n",
            "loading data for user 016 on the ZX plane ... √\n",
            "loading data for user 017 on the ZX plane ... √\n",
            "loading data for user 018 on the ZX plane ... √\n",
            "loading data for user 019 on the ZX plane ... √\n",
            "loading data for user 020 on the ZX plane ... √\n",
            "loading data for user 021 on the ZX plane ... √\n",
            "loading data for user 022 on the ZX plane ... √\n",
            "loading data for user 023 on the ZX plane ... √\n",
            "loading data for user 024 on the ZX plane ... √\n",
            "loading data for user 025 on the ZX plane ... √\n",
            "8\n",
            "Epoch 1/300\n",
            "60/60 [==============================] - 22s 255ms/step - loss: 2.6338 - accuracy: 0.1841 - val_loss: 1.8370 - val_accuracy: 0.6000\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 1.6107 - accuracy: 0.4836 - val_loss: 0.7073 - val_accuracy: 0.9000\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.9310 - accuracy: 0.7104 - val_loss: 0.3577 - val_accuracy: 0.9438\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.6199 - accuracy: 0.8008 - val_loss: 0.2395 - val_accuracy: 0.9500\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.4656 - accuracy: 0.8534 - val_loss: 0.1941 - val_accuracy: 0.9625\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.3657 - accuracy: 0.8880 - val_loss: 0.1815 - val_accuracy: 0.9625\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.2890 - accuracy: 0.9154 - val_loss: 0.1418 - val_accuracy: 0.9625\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.2634 - accuracy: 0.9099 - val_loss: 0.1089 - val_accuracy: 0.9750\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.2375 - accuracy: 0.9258 - val_loss: 0.1032 - val_accuracy: 0.9750\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.1997 - accuracy: 0.9349 - val_loss: 0.0941 - val_accuracy: 0.9688\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1752 - accuracy: 0.9427 - val_loss: 0.0751 - val_accuracy: 0.9875\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.1564 - accuracy: 0.9497 - val_loss: 0.0708 - val_accuracy: 0.9875\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.1373 - accuracy: 0.9552 - val_loss: 0.0542 - val_accuracy: 0.9875\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.1429 - accuracy: 0.9549 - val_loss: 0.0627 - val_accuracy: 0.9875\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1251 - accuracy: 0.9609 - val_loss: 0.0542 - val_accuracy: 0.9937\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1243 - accuracy: 0.9594 - val_loss: 0.0459 - val_accuracy: 0.9937\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1098 - accuracy: 0.9672 - val_loss: 0.0484 - val_accuracy: 0.9875\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0987 - accuracy: 0.9701 - val_loss: 0.0679 - val_accuracy: 0.9812\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0944 - accuracy: 0.9716 - val_loss: 0.0450 - val_accuracy: 0.9875\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0854 - accuracy: 0.9719 - val_loss: 0.0405 - val_accuracy: 0.9937\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0882 - accuracy: 0.9745 - val_loss: 0.0472 - val_accuracy: 0.9937\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0813 - accuracy: 0.9758 - val_loss: 0.0512 - val_accuracy: 0.9875\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0764 - accuracy: 0.9771 - val_loss: 0.0559 - val_accuracy: 0.9875\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0800 - accuracy: 0.9737 - val_loss: 0.0463 - val_accuracy: 0.9875\n",
            "Epoch 25/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0685 - accuracy: 0.9799 - val_loss: 0.0313 - val_accuracy: 0.9937\n",
            "Epoch 26/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0611 - accuracy: 0.9812 - val_loss: 0.0390 - val_accuracy: 0.9937\n",
            "Epoch 27/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0601 - accuracy: 0.9812 - val_loss: 0.0323 - val_accuracy: 0.9875\n",
            "Epoch 28/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0566 - accuracy: 0.9841 - val_loss: 0.0373 - val_accuracy: 0.9875\n",
            "Epoch 29/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0563 - accuracy: 0.9859 - val_loss: 0.0323 - val_accuracy: 0.9875\n",
            "Epoch 30/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0523 - accuracy: 0.9844 - val_loss: 0.0331 - val_accuracy: 0.9937\n",
            "Epoch 31/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0559 - accuracy: 0.9836 - val_loss: 0.0456 - val_accuracy: 0.9875\n",
            "Epoch 32/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0530 - accuracy: 0.9852 - val_loss: 0.0345 - val_accuracy: 0.9937\n",
            "Epoch 33/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0519 - accuracy: 0.9833 - val_loss: 0.0346 - val_accuracy: 0.9875\n",
            "Epoch 34/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0482 - accuracy: 0.9857 - val_loss: 0.0292 - val_accuracy: 0.9937\n",
            "Epoch 35/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0489 - accuracy: 0.9846 - val_loss: 0.0325 - val_accuracy: 0.9875\n",
            "Epoch 36/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0449 - accuracy: 0.9878 - val_loss: 0.0377 - val_accuracy: 0.9937\n",
            "Epoch 37/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0415 - accuracy: 0.9872 - val_loss: 0.0240 - val_accuracy: 0.9937\n",
            "Epoch 38/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0417 - accuracy: 0.9885 - val_loss: 0.0239 - val_accuracy: 0.9937\n",
            "Epoch 39/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0399 - accuracy: 0.9883 - val_loss: 0.0320 - val_accuracy: 0.9875\n",
            "Epoch 40/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0393 - accuracy: 0.9875 - val_loss: 0.0313 - val_accuracy: 0.9875\n",
            "Epoch 41/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0446 - accuracy: 0.9867 - val_loss: 0.0310 - val_accuracy: 0.9937\n",
            "Epoch 42/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0377 - accuracy: 0.9888 - val_loss: 0.0258 - val_accuracy: 0.9937\n",
            "Epoch 43/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0329 - accuracy: 0.9917 - val_loss: 0.0303 - val_accuracy: 0.9937\n",
            "Epoch 44/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0323 - accuracy: 0.9901 - val_loss: 0.0208 - val_accuracy: 0.9937\n",
            "Epoch 45/300\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.0347 - accuracy: 0.9898 - val_loss: 0.0285 - val_accuracy: 0.9875\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.0542 - accuracy: 0.9937\n",
            "99.37 %\n",
            "Processing results for user 021... \n",
            "loading data for user 001 on the XY plane ... √\n",
            "loading data for user 002 on the XY plane ... √\n",
            "loading data for user 003 on the XY plane ... √\n",
            "loading data for user 004 on the XY plane ... √\n",
            "loading data for user 005 on the XY plane ... √\n",
            "loading data for user 006 on the XY plane ... √\n",
            "loading data for user 007 on the XY plane ... √\n",
            "loading data for user 008 on the XY plane ... √\n",
            "loading data for user 009 on the XY plane ... √\n",
            "loading data for user 010 on the XY plane ... √\n",
            "loading data for user 011 on the XY plane ... √\n",
            "loading data for user 012 on the XY plane ... √\n",
            "loading data for user 013 on the XY plane ... √\n",
            "loading data for user 014 on the XY plane ... √\n",
            "loading data for user 015 on the XY plane ... √\n",
            "loading data for user 016 on the XY plane ... √\n",
            "loading data for user 017 on the XY plane ... √\n",
            "loading data for user 018 on the XY plane ... √\n",
            "loading data for user 019 on the XY plane ... √\n",
            "loading data for user 020 on the XY plane ... √\n",
            "loading data for user 021 on the XY plane ... √\n",
            "loading data for user 022 on the XY plane ... √\n",
            "loading data for user 023 on the XY plane ... √\n",
            "loading data for user 024 on the XY plane ... √\n",
            "loading data for user 025 on the XY plane ... √\n",
            "loading data for user 001 on the YZ plane ... √\n",
            "loading data for user 002 on the YZ plane ... √\n",
            "loading data for user 003 on the YZ plane ... √\n",
            "loading data for user 004 on the YZ plane ... √\n",
            "loading data for user 005 on the YZ plane ... √\n",
            "loading data for user 006 on the YZ plane ... √\n",
            "loading data for user 007 on the YZ plane ... √\n",
            "loading data for user 008 on the YZ plane ... √\n",
            "loading data for user 009 on the YZ plane ... √\n",
            "loading data for user 010 on the YZ plane ... √\n",
            "loading data for user 011 on the YZ plane ... √\n",
            "loading data for user 012 on the YZ plane ... √\n",
            "loading data for user 013 on the YZ plane ... √\n",
            "loading data for user 014 on the YZ plane ... √\n",
            "loading data for user 015 on the YZ plane ... √\n",
            "loading data for user 016 on the YZ plane ... √\n",
            "loading data for user 017 on the YZ plane ... √\n",
            "loading data for user 018 on the YZ plane ... √\n",
            "loading data for user 019 on the YZ plane ... √\n",
            "loading data for user 020 on the YZ plane ... √\n",
            "loading data for user 021 on the YZ plane ... √\n",
            "loading data for user 022 on the YZ plane ... √\n",
            "loading data for user 023 on the YZ plane ... √\n",
            "loading data for user 024 on the YZ plane ... √\n",
            "loading data for user 025 on the YZ plane ... √\n",
            "loading data for user 001 on the ZX plane ... √\n",
            "loading data for user 002 on the ZX plane ... √\n",
            "loading data for user 003 on the ZX plane ... √\n",
            "loading data for user 004 on the ZX plane ... √\n",
            "loading data for user 005 on the ZX plane ... √\n",
            "loading data for user 006 on the ZX plane ... √\n",
            "loading data for user 007 on the ZX plane ... √\n",
            "loading data for user 008 on the ZX plane ... √\n",
            "loading data for user 009 on the ZX plane ... √\n",
            "loading data for user 010 on the ZX plane ... √\n",
            "loading data for user 011 on the ZX plane ... √\n",
            "loading data for user 012 on the ZX plane ... √\n",
            "loading data for user 013 on the ZX plane ... √\n",
            "loading data for user 014 on the ZX plane ... √\n",
            "loading data for user 015 on the ZX plane ... √\n",
            "loading data for user 016 on the ZX plane ... √\n",
            "loading data for user 017 on the ZX plane ... √\n",
            "loading data for user 018 on the ZX plane ... √\n",
            "loading data for user 019 on the ZX plane ... √\n",
            "loading data for user 020 on the ZX plane ... √\n",
            "loading data for user 021 on the ZX plane ... √\n",
            "loading data for user 022 on the ZX plane ... √\n",
            "loading data for user 023 on the ZX plane ... √\n",
            "loading data for user 024 on the ZX plane ... √\n",
            "loading data for user 025 on the ZX plane ... √\n",
            "8\n",
            "Epoch 1/300\n",
            "60/60 [==============================] - 23s 256ms/step - loss: 2.6396 - accuracy: 0.1854 - val_loss: 1.8297 - val_accuracy: 0.6562\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 1.5860 - accuracy: 0.4971 - val_loss: 0.8243 - val_accuracy: 0.7437\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.9201 - accuracy: 0.7102 - val_loss: 0.4257 - val_accuracy: 0.8813\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.5958 - accuracy: 0.8141 - val_loss: 0.3343 - val_accuracy: 0.9000\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.4729 - accuracy: 0.8513 - val_loss: 0.2722 - val_accuracy: 0.9062\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.3739 - accuracy: 0.8823 - val_loss: 0.2186 - val_accuracy: 0.9312\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.3184 - accuracy: 0.8956 - val_loss: 0.2037 - val_accuracy: 0.9625\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.2773 - accuracy: 0.9141 - val_loss: 0.1504 - val_accuracy: 0.9563\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.2157 - accuracy: 0.9292 - val_loss: 0.1616 - val_accuracy: 0.9375\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1961 - accuracy: 0.9406 - val_loss: 0.1342 - val_accuracy: 0.9625\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1871 - accuracy: 0.9378 - val_loss: 0.1467 - val_accuracy: 0.9563\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1670 - accuracy: 0.9492 - val_loss: 0.1374 - val_accuracy: 0.9500\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1483 - accuracy: 0.9518 - val_loss: 0.1115 - val_accuracy: 0.9625\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1359 - accuracy: 0.9555 - val_loss: 0.0972 - val_accuracy: 0.9688\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1386 - accuracy: 0.9594 - val_loss: 0.0900 - val_accuracy: 0.9875\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1237 - accuracy: 0.9628 - val_loss: 0.0829 - val_accuracy: 0.9812\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1115 - accuracy: 0.9615 - val_loss: 0.1010 - val_accuracy: 0.9688\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1088 - accuracy: 0.9651 - val_loss: 0.0950 - val_accuracy: 0.9625\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1042 - accuracy: 0.9664 - val_loss: 0.0983 - val_accuracy: 0.9500\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0982 - accuracy: 0.9677 - val_loss: 0.0717 - val_accuracy: 0.9875\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0831 - accuracy: 0.9732 - val_loss: 0.0758 - val_accuracy: 0.9812\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0817 - accuracy: 0.9745 - val_loss: 0.0744 - val_accuracy: 0.9812\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0765 - accuracy: 0.9763 - val_loss: 0.0716 - val_accuracy: 0.9688\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0749 - accuracy: 0.9763 - val_loss: 0.0755 - val_accuracy: 0.9812\n",
            "Epoch 25/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0805 - accuracy: 0.9729 - val_loss: 0.0787 - val_accuracy: 0.9688\n",
            "Epoch 26/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0646 - accuracy: 0.9810 - val_loss: 0.0654 - val_accuracy: 0.9812\n",
            "Epoch 27/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0655 - accuracy: 0.9797 - val_loss: 0.0738 - val_accuracy: 0.9750\n",
            "Epoch 28/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0662 - accuracy: 0.9784 - val_loss: 0.0749 - val_accuracy: 0.9563\n",
            "Epoch 29/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0571 - accuracy: 0.9807 - val_loss: 0.0734 - val_accuracy: 0.9625\n",
            "Epoch 30/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0550 - accuracy: 0.9828 - val_loss: 0.0642 - val_accuracy: 0.9750\n",
            "Epoch 31/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0550 - accuracy: 0.9836 - val_loss: 0.0515 - val_accuracy: 0.9875\n",
            "Epoch 32/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0514 - accuracy: 0.9852 - val_loss: 0.0500 - val_accuracy: 0.9937\n",
            "Epoch 33/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0529 - accuracy: 0.9854 - val_loss: 0.0519 - val_accuracy: 0.9750\n",
            "Epoch 34/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0449 - accuracy: 0.9872 - val_loss: 0.0599 - val_accuracy: 0.9750\n",
            "Epoch 35/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0523 - accuracy: 0.9839 - val_loss: 0.0442 - val_accuracy: 0.9937\n",
            "Epoch 36/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0393 - accuracy: 0.9901 - val_loss: 0.0622 - val_accuracy: 0.9812\n",
            "Epoch 37/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0430 - accuracy: 0.9875 - val_loss: 0.0441 - val_accuracy: 0.9875\n",
            "Epoch 38/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0384 - accuracy: 0.9867 - val_loss: 0.0417 - val_accuracy: 0.9875\n",
            "Epoch 39/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0409 - accuracy: 0.9880 - val_loss: 0.0498 - val_accuracy: 0.9937\n",
            "Epoch 40/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0430 - accuracy: 0.9849 - val_loss: 0.0399 - val_accuracy: 0.9937\n",
            "Epoch 41/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0418 - accuracy: 0.9857 - val_loss: 0.0571 - val_accuracy: 0.9750\n",
            "Epoch 42/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0391 - accuracy: 0.9888 - val_loss: 0.0436 - val_accuracy: 0.9937\n",
            "Epoch 43/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0362 - accuracy: 0.9904 - val_loss: 0.0524 - val_accuracy: 0.9812\n",
            "Epoch 44/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0321 - accuracy: 0.9901 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
            "Epoch 45/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0320 - accuracy: 0.9909 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
            "Epoch 46/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0258 - accuracy: 0.9940 - val_loss: 0.0423 - val_accuracy: 0.9875\n",
            "Epoch 47/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0338 - accuracy: 0.9893 - val_loss: 0.0473 - val_accuracy: 0.9875\n",
            "Epoch 48/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0351 - accuracy: 0.9888 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
            "Epoch 49/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0272 - accuracy: 0.9930 - val_loss: 0.0425 - val_accuracy: 0.9937\n",
            "Epoch 50/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0281 - accuracy: 0.9914 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
            "Epoch 51/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0301 - accuracy: 0.9906 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
            "Epoch 52/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 0.0451 - val_accuracy: 0.9812\n",
            "Epoch 53/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0227 - accuracy: 0.9948 - val_loss: 0.0538 - val_accuracy: 0.9750\n",
            "Epoch 54/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0233 - accuracy: 0.9932 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
            "Epoch 55/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0245 - accuracy: 0.9930 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
            "Epoch 56/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0204 - accuracy: 0.9956 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
            "Epoch 57/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 0.0312 - val_accuracy: 0.9875\n",
            "Epoch 58/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.0331 - val_accuracy: 0.9937\n",
            "Epoch 59/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0242 - accuracy: 0.9932 - val_loss: 0.0450 - val_accuracy: 0.9875\n",
            "Epoch 60/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0206 - accuracy: 0.9951 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
            "Epoch 61/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.0348 - val_accuracy: 0.9937\n",
            "Epoch 62/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0230 - accuracy: 0.9943 - val_loss: 0.0302 - val_accuracy: 0.9937\n",
            "Epoch 63/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0271 - accuracy: 0.9914 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
            "Epoch 64/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0196 - accuracy: 0.9956 - val_loss: 0.0295 - val_accuracy: 0.9937\n",
            "Epoch 65/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0204 - accuracy: 0.9966 - val_loss: 0.0523 - val_accuracy: 0.9688\n",
            "Epoch 66/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0148 - accuracy: 0.9977 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
            "Epoch 67/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0134 - accuracy: 0.9979 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
            "Epoch 68/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0451 - val_accuracy: 0.9875\n",
            "Epoch 69/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.0411 - val_accuracy: 0.9812\n",
            "Epoch 70/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0176 - accuracy: 0.9958 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
            "Epoch 71/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0206 - accuracy: 0.9943 - val_loss: 0.0423 - val_accuracy: 0.9875\n",
            "Epoch 72/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0144 - accuracy: 0.9974 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
            "Epoch 73/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 0.0386 - val_accuracy: 0.9937\n",
            "Epoch 74/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.0335 - val_accuracy: 0.9875\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.0357 - accuracy: 1.0000\n",
            "100.00 %\n",
            "Processing results for user 022... \n",
            "loading data for user 001 on the XY plane ... √\n",
            "loading data for user 002 on the XY plane ... √\n",
            "loading data for user 003 on the XY plane ... √\n",
            "loading data for user 004 on the XY plane ... √\n",
            "loading data for user 005 on the XY plane ... √\n",
            "loading data for user 006 on the XY plane ... √\n",
            "loading data for user 007 on the XY plane ... √\n",
            "loading data for user 008 on the XY plane ... √\n",
            "loading data for user 009 on the XY plane ... √\n",
            "loading data for user 010 on the XY plane ... √\n",
            "loading data for user 011 on the XY plane ... √\n",
            "loading data for user 012 on the XY plane ... √\n",
            "loading data for user 013 on the XY plane ... √\n",
            "loading data for user 014 on the XY plane ... √\n",
            "loading data for user 015 on the XY plane ... √\n",
            "loading data for user 016 on the XY plane ... √\n",
            "loading data for user 017 on the XY plane ... √\n",
            "loading data for user 018 on the XY plane ... √\n",
            "loading data for user 019 on the XY plane ... √\n",
            "loading data for user 020 on the XY plane ... √\n",
            "loading data for user 021 on the XY plane ... √\n",
            "loading data for user 022 on the XY plane ... √\n",
            "loading data for user 023 on the XY plane ... √\n",
            "loading data for user 024 on the XY plane ... √\n",
            "loading data for user 025 on the XY plane ... √\n",
            "loading data for user 001 on the YZ plane ... √\n",
            "loading data for user 002 on the YZ plane ... √\n",
            "loading data for user 003 on the YZ plane ... √\n",
            "loading data for user 004 on the YZ plane ... √\n",
            "loading data for user 005 on the YZ plane ... √\n",
            "loading data for user 006 on the YZ plane ... √\n",
            "loading data for user 007 on the YZ plane ... √\n",
            "loading data for user 008 on the YZ plane ... √\n",
            "loading data for user 009 on the YZ plane ... √\n",
            "loading data for user 010 on the YZ plane ... √\n",
            "loading data for user 011 on the YZ plane ... √\n",
            "loading data for user 012 on the YZ plane ... √\n",
            "loading data for user 013 on the YZ plane ... √\n",
            "loading data for user 014 on the YZ plane ... √\n",
            "loading data for user 015 on the YZ plane ... √\n",
            "loading data for user 016 on the YZ plane ... √\n",
            "loading data for user 017 on the YZ plane ... √\n",
            "loading data for user 018 on the YZ plane ... √\n",
            "loading data for user 019 on the YZ plane ... √\n",
            "loading data for user 020 on the YZ plane ... √\n",
            "loading data for user 021 on the YZ plane ... √\n",
            "loading data for user 022 on the YZ plane ... √\n",
            "loading data for user 023 on the YZ plane ... √\n",
            "loading data for user 024 on the YZ plane ... √\n",
            "loading data for user 025 on the YZ plane ... √\n",
            "loading data for user 001 on the ZX plane ... √\n",
            "loading data for user 002 on the ZX plane ... √\n",
            "loading data for user 003 on the ZX plane ... √\n",
            "loading data for user 004 on the ZX plane ... √\n",
            "loading data for user 005 on the ZX plane ... √\n",
            "loading data for user 006 on the ZX plane ... √\n",
            "loading data for user 007 on the ZX plane ... √\n",
            "loading data for user 008 on the ZX plane ... √\n",
            "loading data for user 009 on the ZX plane ... √\n",
            "loading data for user 010 on the ZX plane ... √\n",
            "loading data for user 011 on the ZX plane ... √\n",
            "loading data for user 012 on the ZX plane ... √\n",
            "loading data for user 013 on the ZX plane ... √\n",
            "loading data for user 014 on the ZX plane ... √\n",
            "loading data for user 015 on the ZX plane ... √\n",
            "loading data for user 016 on the ZX plane ... √\n",
            "loading data for user 017 on the ZX plane ... √\n",
            "loading data for user 018 on the ZX plane ... √\n",
            "loading data for user 019 on the ZX plane ... √\n",
            "loading data for user 020 on the ZX plane ... √\n",
            "loading data for user 021 on the ZX plane ... √\n",
            "loading data for user 022 on the ZX plane ... √\n",
            "loading data for user 023 on the ZX plane ... √\n",
            "loading data for user 024 on the ZX plane ... √\n",
            "loading data for user 025 on the ZX plane ... √\n",
            "8\n",
            "Epoch 1/300\n",
            "60/60 [==============================] - 22s 257ms/step - loss: 2.7442 - accuracy: 0.1714 - val_loss: 1.8498 - val_accuracy: 0.6125\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 1.7965 - accuracy: 0.4437 - val_loss: 0.8864 - val_accuracy: 0.7750\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 1.0461 - accuracy: 0.6721 - val_loss: 0.5633 - val_accuracy: 0.8313\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.6588 - accuracy: 0.7932 - val_loss: 0.3611 - val_accuracy: 0.8750\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.4882 - accuracy: 0.8456 - val_loss: 0.3480 - val_accuracy: 0.9000\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.3739 - accuracy: 0.8797 - val_loss: 0.3032 - val_accuracy: 0.9000\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.3188 - accuracy: 0.8992 - val_loss: 0.2762 - val_accuracy: 0.9000\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.2723 - accuracy: 0.9130 - val_loss: 0.2618 - val_accuracy: 0.9062\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.2296 - accuracy: 0.9281 - val_loss: 0.2573 - val_accuracy: 0.8938\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.2148 - accuracy: 0.9302 - val_loss: 0.2659 - val_accuracy: 0.8875\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1723 - accuracy: 0.9495 - val_loss: 0.2231 - val_accuracy: 0.9312\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1644 - accuracy: 0.9518 - val_loss: 0.2000 - val_accuracy: 0.9250\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1594 - accuracy: 0.9474 - val_loss: 0.2271 - val_accuracy: 0.9312\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1405 - accuracy: 0.9560 - val_loss: 0.1538 - val_accuracy: 0.9500\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1281 - accuracy: 0.9586 - val_loss: 0.1793 - val_accuracy: 0.9500\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1178 - accuracy: 0.9641 - val_loss: 0.2068 - val_accuracy: 0.9312\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1157 - accuracy: 0.9630 - val_loss: 0.1758 - val_accuracy: 0.9500\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1092 - accuracy: 0.9656 - val_loss: 0.1302 - val_accuracy: 0.9500\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0972 - accuracy: 0.9716 - val_loss: 0.1556 - val_accuracy: 0.9500\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0885 - accuracy: 0.9732 - val_loss: 0.1533 - val_accuracy: 0.9375\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0808 - accuracy: 0.9771 - val_loss: 0.1514 - val_accuracy: 0.9438\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0859 - accuracy: 0.9721 - val_loss: 0.1599 - val_accuracy: 0.9500\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0866 - accuracy: 0.9734 - val_loss: 0.1470 - val_accuracy: 0.9500\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0772 - accuracy: 0.9734 - val_loss: 0.1738 - val_accuracy: 0.9438\n",
            "Epoch 25/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0743 - accuracy: 0.9789 - val_loss: 0.1555 - val_accuracy: 0.9500\n",
            "Epoch 26/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0748 - accuracy: 0.9766 - val_loss: 0.1351 - val_accuracy: 0.9500\n",
            "Epoch 27/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0647 - accuracy: 0.9789 - val_loss: 0.1601 - val_accuracy: 0.9375\n",
            "Epoch 28/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0675 - accuracy: 0.9797 - val_loss: 0.1549 - val_accuracy: 0.9438\n",
            "Epoch 29/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0539 - accuracy: 0.9836 - val_loss: 0.1460 - val_accuracy: 0.9500\n",
            "Epoch 30/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0549 - accuracy: 0.9820 - val_loss: 0.1530 - val_accuracy: 0.9500\n",
            "Epoch 31/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0556 - accuracy: 0.9826 - val_loss: 0.1225 - val_accuracy: 0.9563\n",
            "Epoch 32/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0474 - accuracy: 0.9872 - val_loss: 0.1286 - val_accuracy: 0.9500\n",
            "Epoch 33/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0430 - accuracy: 0.9888 - val_loss: 0.1385 - val_accuracy: 0.9563\n",
            "Epoch 34/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0488 - accuracy: 0.9849 - val_loss: 0.0895 - val_accuracy: 0.9750\n",
            "Epoch 35/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0449 - accuracy: 0.9859 - val_loss: 0.1508 - val_accuracy: 0.9438\n",
            "Epoch 36/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0437 - accuracy: 0.9878 - val_loss: 0.1177 - val_accuracy: 0.9625\n",
            "Epoch 37/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0446 - accuracy: 0.9885 - val_loss: 0.0736 - val_accuracy: 0.9812\n",
            "Epoch 38/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0393 - accuracy: 0.9883 - val_loss: 0.1096 - val_accuracy: 0.9625\n",
            "Epoch 39/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0340 - accuracy: 0.9909 - val_loss: 0.1280 - val_accuracy: 0.9563\n",
            "Epoch 40/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0347 - accuracy: 0.9885 - val_loss: 0.1052 - val_accuracy: 0.9563\n",
            "Epoch 41/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0365 - accuracy: 0.9893 - val_loss: 0.1062 - val_accuracy: 0.9563\n",
            "Epoch 42/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0384 - accuracy: 0.9872 - val_loss: 0.1315 - val_accuracy: 0.9563\n",
            "Epoch 43/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0361 - accuracy: 0.9909 - val_loss: 0.1376 - val_accuracy: 0.9500\n",
            "Epoch 44/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0329 - accuracy: 0.9911 - val_loss: 0.0885 - val_accuracy: 0.9688\n",
            "Epoch 45/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0363 - accuracy: 0.9901 - val_loss: 0.1927 - val_accuracy: 0.9250\n",
            "Epoch 46/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0276 - accuracy: 0.9919 - val_loss: 0.1426 - val_accuracy: 0.9438\n",
            "Epoch 47/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0384 - accuracy: 0.9888 - val_loss: 0.1079 - val_accuracy: 0.9625\n",
            "Epoch 48/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0296 - accuracy: 0.9914 - val_loss: 0.0952 - val_accuracy: 0.9750\n",
            "Epoch 49/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0281 - accuracy: 0.9930 - val_loss: 0.1255 - val_accuracy: 0.9563\n",
            "Epoch 50/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0311 - accuracy: 0.9911 - val_loss: 0.1315 - val_accuracy: 0.9563\n",
            "Epoch 51/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0263 - accuracy: 0.9935 - val_loss: 0.0994 - val_accuracy: 0.9750\n",
            "Epoch 52/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0252 - accuracy: 0.9932 - val_loss: 0.1187 - val_accuracy: 0.9563\n",
            "Epoch 53/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0242 - accuracy: 0.9935 - val_loss: 0.0608 - val_accuracy: 0.9812\n",
            "Epoch 54/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0271 - accuracy: 0.9919 - val_loss: 0.0961 - val_accuracy: 0.9750\n",
            "Epoch 55/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0295 - accuracy: 0.9901 - val_loss: 0.1004 - val_accuracy: 0.9688\n",
            "Epoch 56/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0220 - accuracy: 0.9953 - val_loss: 0.1088 - val_accuracy: 0.9625\n",
            "Epoch 57/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0233 - accuracy: 0.9927 - val_loss: 0.1061 - val_accuracy: 0.9688\n",
            "Epoch 58/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0241 - accuracy: 0.9932 - val_loss: 0.1491 - val_accuracy: 0.9563\n",
            "Epoch 59/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0248 - accuracy: 0.9935 - val_loss: 0.1526 - val_accuracy: 0.9500\n",
            "Epoch 60/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0276 - accuracy: 0.9927 - val_loss: 0.1214 - val_accuracy: 0.9563\n",
            "Epoch 61/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0201 - accuracy: 0.9948 - val_loss: 0.1009 - val_accuracy: 0.9625\n",
            "Epoch 62/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.1104 - val_accuracy: 0.9625\n",
            "Epoch 63/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0250 - accuracy: 0.9927 - val_loss: 0.0828 - val_accuracy: 0.9688\n",
            "Epoch 64/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0205 - accuracy: 0.9951 - val_loss: 0.0861 - val_accuracy: 0.9688\n",
            "Epoch 65/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0217 - accuracy: 0.9943 - val_loss: 0.0734 - val_accuracy: 0.9750\n",
            "Epoch 66/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0158 - accuracy: 0.9966 - val_loss: 0.0937 - val_accuracy: 0.9688\n",
            "Epoch 67/300\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.0165 - accuracy: 0.9964 - val_loss: 0.0767 - val_accuracy: 0.9812\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.0736 - accuracy: 0.9812\n",
            "98.12 %\n",
            "Processing results for user 023... \n",
            "loading data for user 001 on the XY plane ... √\n",
            "loading data for user 002 on the XY plane ... √\n",
            "loading data for user 003 on the XY plane ... √\n",
            "loading data for user 004 on the XY plane ... √\n",
            "loading data for user 005 on the XY plane ... √\n",
            "loading data for user 006 on the XY plane ... √\n",
            "loading data for user 007 on the XY plane ... √\n",
            "loading data for user 008 on the XY plane ... √\n",
            "loading data for user 009 on the XY plane ... √\n",
            "loading data for user 010 on the XY plane ... √\n",
            "loading data for user 011 on the XY plane ... √\n",
            "loading data for user 012 on the XY plane ... √\n",
            "loading data for user 013 on the XY plane ... √\n",
            "loading data for user 014 on the XY plane ... √\n",
            "loading data for user 015 on the XY plane ... √\n",
            "loading data for user 016 on the XY plane ... √\n",
            "loading data for user 017 on the XY plane ... √\n",
            "loading data for user 018 on the XY plane ... √\n",
            "loading data for user 019 on the XY plane ... √\n",
            "loading data for user 020 on the XY plane ... √\n",
            "loading data for user 021 on the XY plane ... √\n",
            "loading data for user 022 on the XY plane ... √\n",
            "loading data for user 023 on the XY plane ... √\n",
            "loading data for user 024 on the XY plane ... √\n",
            "loading data for user 025 on the XY plane ... √\n",
            "loading data for user 001 on the YZ plane ... √\n",
            "loading data for user 002 on the YZ plane ... √\n",
            "loading data for user 003 on the YZ plane ... √\n",
            "loading data for user 004 on the YZ plane ... √\n",
            "loading data for user 005 on the YZ plane ... √\n",
            "loading data for user 006 on the YZ plane ... √\n",
            "loading data for user 007 on the YZ plane ... √\n",
            "loading data for user 008 on the YZ plane ... √\n",
            "loading data for user 009 on the YZ plane ... √\n",
            "loading data for user 010 on the YZ plane ... √\n",
            "loading data for user 011 on the YZ plane ... √\n",
            "loading data for user 012 on the YZ plane ... √\n",
            "loading data for user 013 on the YZ plane ... √\n",
            "loading data for user 014 on the YZ plane ... √\n",
            "loading data for user 015 on the YZ plane ... √\n",
            "loading data for user 016 on the YZ plane ... √\n",
            "loading data for user 017 on the YZ plane ... √\n",
            "loading data for user 018 on the YZ plane ... √\n",
            "loading data for user 019 on the YZ plane ... √\n",
            "loading data for user 020 on the YZ plane ... √\n",
            "loading data for user 021 on the YZ plane ... √\n",
            "loading data for user 022 on the YZ plane ... √\n",
            "loading data for user 023 on the YZ plane ... √\n",
            "loading data for user 024 on the YZ plane ... √\n",
            "loading data for user 025 on the YZ plane ... √\n",
            "loading data for user 001 on the ZX plane ... √\n",
            "loading data for user 002 on the ZX plane ... √\n",
            "loading data for user 003 on the ZX plane ... √\n",
            "loading data for user 004 on the ZX plane ... √\n",
            "loading data for user 005 on the ZX plane ... √\n",
            "loading data for user 006 on the ZX plane ... √\n",
            "loading data for user 007 on the ZX plane ... √\n",
            "loading data for user 008 on the ZX plane ... √\n",
            "loading data for user 009 on the ZX plane ... √\n",
            "loading data for user 010 on the ZX plane ... √\n",
            "loading data for user 011 on the ZX plane ... √\n",
            "loading data for user 012 on the ZX plane ... √\n",
            "loading data for user 013 on the ZX plane ... √\n",
            "loading data for user 014 on the ZX plane ... √\n",
            "loading data for user 015 on the ZX plane ... √\n",
            "loading data for user 016 on the ZX plane ... √\n",
            "loading data for user 017 on the ZX plane ... √\n",
            "loading data for user 018 on the ZX plane ... √\n",
            "loading data for user 019 on the ZX plane ... √\n",
            "loading data for user 020 on the ZX plane ... √\n",
            "loading data for user 021 on the ZX plane ... √\n",
            "loading data for user 022 on the ZX plane ... √\n",
            "loading data for user 023 on the ZX plane ... √\n",
            "loading data for user 024 on the ZX plane ... √\n",
            "loading data for user 025 on the ZX plane ... √\n",
            "8\n",
            "Epoch 1/300\n",
            "60/60 [==============================] - 23s 257ms/step - loss: 2.6176 - accuracy: 0.1984 - val_loss: 1.6451 - val_accuracy: 0.6250\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 1.6358 - accuracy: 0.4828 - val_loss: 0.8533 - val_accuracy: 0.6938\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.9828 - accuracy: 0.6919 - val_loss: 0.5445 - val_accuracy: 0.8062\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.6537 - accuracy: 0.7880 - val_loss: 0.4504 - val_accuracy: 0.8562\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.4896 - accuracy: 0.8471 - val_loss: 0.3238 - val_accuracy: 0.8938\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.3617 - accuracy: 0.8901 - val_loss: 0.3145 - val_accuracy: 0.8875\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.3189 - accuracy: 0.8951 - val_loss: 0.3066 - val_accuracy: 0.8938\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.2702 - accuracy: 0.9172 - val_loss: 0.2813 - val_accuracy: 0.9000\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.2401 - accuracy: 0.9289 - val_loss: 0.2135 - val_accuracy: 0.9438\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.2293 - accuracy: 0.9234 - val_loss: 0.1914 - val_accuracy: 0.9438\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1892 - accuracy: 0.9401 - val_loss: 0.2584 - val_accuracy: 0.9187\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1686 - accuracy: 0.9445 - val_loss: 0.1864 - val_accuracy: 0.9438\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1502 - accuracy: 0.9516 - val_loss: 0.2203 - val_accuracy: 0.9375\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1449 - accuracy: 0.9539 - val_loss: 0.2224 - val_accuracy: 0.9375\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1269 - accuracy: 0.9573 - val_loss: 0.2302 - val_accuracy: 0.9250\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1198 - accuracy: 0.9617 - val_loss: 0.2354 - val_accuracy: 0.9312\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1122 - accuracy: 0.9661 - val_loss: 0.2157 - val_accuracy: 0.9438\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0958 - accuracy: 0.9693 - val_loss: 0.2661 - val_accuracy: 0.9312\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0901 - accuracy: 0.9714 - val_loss: 0.2211 - val_accuracy: 0.9375\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0854 - accuracy: 0.9742 - val_loss: 0.2354 - val_accuracy: 0.9312\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0832 - accuracy: 0.9745 - val_loss: 0.2007 - val_accuracy: 0.9500\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0752 - accuracy: 0.9768 - val_loss: 0.2878 - val_accuracy: 0.9312\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0684 - accuracy: 0.9792 - val_loss: 0.1713 - val_accuracy: 0.9438\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0687 - accuracy: 0.9766 - val_loss: 0.2083 - val_accuracy: 0.9438\n",
            "Epoch 25/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0588 - accuracy: 0.9799 - val_loss: 0.2356 - val_accuracy: 0.9250\n",
            "Epoch 26/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0560 - accuracy: 0.9849 - val_loss: 0.2036 - val_accuracy: 0.9438\n",
            "Epoch 27/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0517 - accuracy: 0.9841 - val_loss: 0.3187 - val_accuracy: 0.9312\n",
            "Epoch 28/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0620 - accuracy: 0.9786 - val_loss: 0.2418 - val_accuracy: 0.9375\n",
            "Epoch 29/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0619 - accuracy: 0.9828 - val_loss: 0.2751 - val_accuracy: 0.9312\n",
            "Epoch 30/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0552 - accuracy: 0.9844 - val_loss: 0.3603 - val_accuracy: 0.9187\n",
            "Epoch 31/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0513 - accuracy: 0.9862 - val_loss: 0.2416 - val_accuracy: 0.9375\n",
            "Epoch 32/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0482 - accuracy: 0.9885 - val_loss: 0.2322 - val_accuracy: 0.9375\n",
            "Epoch 33/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0497 - accuracy: 0.9839 - val_loss: 0.2618 - val_accuracy: 0.9438\n",
            "Epoch 34/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0467 - accuracy: 0.9862 - val_loss: 0.1745 - val_accuracy: 0.9500\n",
            "Epoch 35/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0370 - accuracy: 0.9906 - val_loss: 0.2899 - val_accuracy: 0.9312\n",
            "Epoch 36/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0447 - accuracy: 0.9865 - val_loss: 0.2100 - val_accuracy: 0.9438\n",
            "Epoch 37/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0340 - accuracy: 0.9904 - val_loss: 0.2406 - val_accuracy: 0.9375\n",
            "Epoch 38/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0404 - accuracy: 0.9852 - val_loss: 0.3218 - val_accuracy: 0.9312\n",
            "Epoch 39/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0458 - accuracy: 0.9826 - val_loss: 0.1956 - val_accuracy: 0.9438\n",
            "Epoch 40/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0383 - accuracy: 0.9883 - val_loss: 0.1862 - val_accuracy: 0.9438\n",
            "Epoch 41/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0326 - accuracy: 0.9917 - val_loss: 0.2333 - val_accuracy: 0.9375\n",
            "Epoch 42/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0333 - accuracy: 0.9909 - val_loss: 0.2592 - val_accuracy: 0.9375\n",
            "Epoch 43/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0393 - accuracy: 0.9849 - val_loss: 0.3310 - val_accuracy: 0.9250\n",
            "Epoch 44/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0319 - accuracy: 0.9909 - val_loss: 0.2034 - val_accuracy: 0.9438\n",
            "Epoch 45/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0325 - accuracy: 0.9906 - val_loss: 0.2533 - val_accuracy: 0.9312\n",
            "Epoch 46/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0277 - accuracy: 0.9922 - val_loss: 0.2623 - val_accuracy: 0.9375\n",
            "Epoch 47/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0299 - accuracy: 0.9904 - val_loss: 0.3245 - val_accuracy: 0.9312\n",
            "Epoch 48/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0280 - accuracy: 0.9922 - val_loss: 0.2501 - val_accuracy: 0.9438\n",
            "Epoch 49/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 0.2570 - val_accuracy: 0.9375\n",
            "Epoch 50/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0261 - accuracy: 0.9922 - val_loss: 0.2649 - val_accuracy: 0.9375\n",
            "Epoch 51/300\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.0284 - accuracy: 0.9906 - val_loss: 0.2584 - val_accuracy: 0.9375\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.2007 - accuracy: 0.9500\n",
            "95.00 %\n",
            "Processing results for user 024... \n",
            "loading data for user 001 on the XY plane ... √\n",
            "loading data for user 002 on the XY plane ... √\n",
            "loading data for user 003 on the XY plane ... √\n",
            "loading data for user 004 on the XY plane ... √\n",
            "loading data for user 005 on the XY plane ... √\n",
            "loading data for user 006 on the XY plane ... √\n",
            "loading data for user 007 on the XY plane ... √\n",
            "loading data for user 008 on the XY plane ... √\n",
            "loading data for user 009 on the XY plane ... √\n",
            "loading data for user 010 on the XY plane ... √\n",
            "loading data for user 011 on the XY plane ... √\n",
            "loading data for user 012 on the XY plane ... √\n",
            "loading data for user 013 on the XY plane ... √\n",
            "loading data for user 014 on the XY plane ... √\n",
            "loading data for user 015 on the XY plane ... √\n",
            "loading data for user 016 on the XY plane ... √\n",
            "loading data for user 017 on the XY plane ... √\n",
            "loading data for user 018 on the XY plane ... √\n",
            "loading data for user 019 on the XY plane ... √\n",
            "loading data for user 020 on the XY plane ... √\n",
            "loading data for user 021 on the XY plane ... √\n",
            "loading data for user 022 on the XY plane ... √\n",
            "loading data for user 023 on the XY plane ... √\n",
            "loading data for user 024 on the XY plane ... √\n",
            "loading data for user 025 on the XY plane ... √\n",
            "loading data for user 001 on the YZ plane ... √\n",
            "loading data for user 002 on the YZ plane ... √\n",
            "loading data for user 003 on the YZ plane ... √\n",
            "loading data for user 004 on the YZ plane ... √\n",
            "loading data for user 005 on the YZ plane ... √\n",
            "loading data for user 006 on the YZ plane ... √\n",
            "loading data for user 007 on the YZ plane ... √\n",
            "loading data for user 008 on the YZ plane ... √\n",
            "loading data for user 009 on the YZ plane ... √\n",
            "loading data for user 010 on the YZ plane ... √\n",
            "loading data for user 011 on the YZ plane ... √\n",
            "loading data for user 012 on the YZ plane ... √\n",
            "loading data for user 013 on the YZ plane ... √\n",
            "loading data for user 014 on the YZ plane ... √\n",
            "loading data for user 015 on the YZ plane ... √\n",
            "loading data for user 016 on the YZ plane ... √\n",
            "loading data for user 017 on the YZ plane ... √\n",
            "loading data for user 018 on the YZ plane ... √\n",
            "loading data for user 019 on the YZ plane ... √\n",
            "loading data for user 020 on the YZ plane ... √\n",
            "loading data for user 021 on the YZ plane ... √\n",
            "loading data for user 022 on the YZ plane ... √\n",
            "loading data for user 023 on the YZ plane ... √\n",
            "loading data for user 024 on the YZ plane ... √\n",
            "loading data for user 025 on the YZ plane ... √\n",
            "loading data for user 001 on the ZX plane ... √\n",
            "loading data for user 002 on the ZX plane ... √\n",
            "loading data for user 003 on the ZX plane ... √\n",
            "loading data for user 004 on the ZX plane ... √\n",
            "loading data for user 005 on the ZX plane ... √\n",
            "loading data for user 006 on the ZX plane ... √\n",
            "loading data for user 007 on the ZX plane ... √\n",
            "loading data for user 008 on the ZX plane ... √\n",
            "loading data for user 009 on the ZX plane ... √\n",
            "loading data for user 010 on the ZX plane ... √\n",
            "loading data for user 011 on the ZX plane ... √\n",
            "loading data for user 012 on the ZX plane ... √\n",
            "loading data for user 013 on the ZX plane ... √\n",
            "loading data for user 014 on the ZX plane ... √\n",
            "loading data for user 015 on the ZX plane ... √\n",
            "loading data for user 016 on the ZX plane ... √\n",
            "loading data for user 017 on the ZX plane ... √\n",
            "loading data for user 018 on the ZX plane ... √\n",
            "loading data for user 019 on the ZX plane ... √\n",
            "loading data for user 020 on the ZX plane ... √\n",
            "loading data for user 021 on the ZX plane ... √\n",
            "loading data for user 022 on the ZX plane ... √\n",
            "loading data for user 023 on the ZX plane ... √\n",
            "loading data for user 024 on the ZX plane ... √\n",
            "loading data for user 025 on the ZX plane ... √\n",
            "8\n",
            "Epoch 1/300\n",
            "60/60 [==============================] - 23s 257ms/step - loss: 2.5891 - accuracy: 0.2036 - val_loss: 1.5707 - val_accuracy: 0.7437\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 1.6154 - accuracy: 0.4935 - val_loss: 0.5046 - val_accuracy: 0.9688\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.9647 - accuracy: 0.6940 - val_loss: 0.1271 - val_accuracy: 1.0000\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.5821 - accuracy: 0.8161 - val_loss: 0.0660 - val_accuracy: 1.0000\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.4586 - accuracy: 0.8513 - val_loss: 0.0493 - val_accuracy: 1.0000\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.3772 - accuracy: 0.8859 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.2993 - accuracy: 0.9068 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.2695 - accuracy: 0.9180 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.2172 - accuracy: 0.9333 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.2112 - accuracy: 0.9312 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1895 - accuracy: 0.9411 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.1650 - accuracy: 0.9435 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1551 - accuracy: 0.9474 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1416 - accuracy: 0.9521 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1241 - accuracy: 0.9612 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1107 - accuracy: 0.9646 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1166 - accuracy: 0.9654 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1095 - accuracy: 0.9654 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1070 - accuracy: 0.9667 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0967 - accuracy: 0.9719 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0860 - accuracy: 0.9716 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0838 - accuracy: 0.9734 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0878 - accuracy: 0.9727 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0760 - accuracy: 0.9768 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 25/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0730 - accuracy: 0.9760 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 26/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0724 - accuracy: 0.9779 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 27/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0655 - accuracy: 0.9802 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 28/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0570 - accuracy: 0.9833 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 29/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0636 - accuracy: 0.9792 - val_loss: 0.0096 - val_accuracy: 0.9937\n",
            "Epoch 30/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0523 - accuracy: 0.9849 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 31/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0556 - accuracy: 0.9849 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 32/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0507 - accuracy: 0.9833 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 33/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0506 - accuracy: 0.9872 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.1271 - accuracy: 1.0000\n",
            "100.00 %\n",
            "Processing results for user 025... \n",
            "loading data for user 001 on the XY plane ... √\n",
            "loading data for user 002 on the XY plane ... √\n",
            "loading data for user 003 on the XY plane ... √\n",
            "loading data for user 004 on the XY plane ... √\n",
            "loading data for user 005 on the XY plane ... √\n",
            "loading data for user 006 on the XY plane ... √\n",
            "loading data for user 007 on the XY plane ... √\n",
            "loading data for user 008 on the XY plane ... √\n",
            "loading data for user 009 on the XY plane ... √\n",
            "loading data for user 010 on the XY plane ... √\n",
            "loading data for user 011 on the XY plane ... √\n",
            "loading data for user 012 on the XY plane ... √\n",
            "loading data for user 013 on the XY plane ... √\n",
            "loading data for user 014 on the XY plane ... √\n",
            "loading data for user 015 on the XY plane ... √\n",
            "loading data for user 016 on the XY plane ... √\n",
            "loading data for user 017 on the XY plane ... √\n",
            "loading data for user 018 on the XY plane ... √\n",
            "loading data for user 019 on the XY plane ... √\n",
            "loading data for user 020 on the XY plane ... √\n",
            "loading data for user 021 on the XY plane ... √\n",
            "loading data for user 022 on the XY plane ... √\n",
            "loading data for user 023 on the XY plane ... √\n",
            "loading data for user 024 on the XY plane ... √\n",
            "loading data for user 025 on the XY plane ... √\n",
            "loading data for user 001 on the YZ plane ... √\n",
            "loading data for user 002 on the YZ plane ... √\n",
            "loading data for user 003 on the YZ plane ... √\n",
            "loading data for user 004 on the YZ plane ... √\n",
            "loading data for user 005 on the YZ plane ... √\n",
            "loading data for user 006 on the YZ plane ... √\n",
            "loading data for user 007 on the YZ plane ... √\n",
            "loading data for user 008 on the YZ plane ... √\n",
            "loading data for user 009 on the YZ plane ... √\n",
            "loading data for user 010 on the YZ plane ... √\n",
            "loading data for user 011 on the YZ plane ... √\n",
            "loading data for user 012 on the YZ plane ... √\n",
            "loading data for user 013 on the YZ plane ... √\n",
            "loading data for user 014 on the YZ plane ... √\n",
            "loading data for user 015 on the YZ plane ... √\n",
            "loading data for user 016 on the YZ plane ... √\n",
            "loading data for user 017 on the YZ plane ... √\n",
            "loading data for user 018 on the YZ plane ... √\n",
            "loading data for user 019 on the YZ plane ... √\n",
            "loading data for user 020 on the YZ plane ... √\n",
            "loading data for user 021 on the YZ plane ... √\n",
            "loading data for user 022 on the YZ plane ... √\n",
            "loading data for user 023 on the YZ plane ... √\n",
            "loading data for user 024 on the YZ plane ... √\n",
            "loading data for user 025 on the YZ plane ... √\n",
            "loading data for user 001 on the ZX plane ... √\n",
            "loading data for user 002 on the ZX plane ... √\n",
            "loading data for user 003 on the ZX plane ... √\n",
            "loading data for user 004 on the ZX plane ... √\n",
            "loading data for user 005 on the ZX plane ... √\n",
            "loading data for user 006 on the ZX plane ... √\n",
            "loading data for user 007 on the ZX plane ... √\n",
            "loading data for user 008 on the ZX plane ... √\n",
            "loading data for user 009 on the ZX plane ... √\n",
            "loading data for user 010 on the ZX plane ... √\n",
            "loading data for user 011 on the ZX plane ... √\n",
            "loading data for user 012 on the ZX plane ... √\n",
            "loading data for user 013 on the ZX plane ... √\n",
            "loading data for user 014 on the ZX plane ... √\n",
            "loading data for user 015 on the ZX plane ... √\n",
            "loading data for user 016 on the ZX plane ... √\n",
            "loading data for user 017 on the ZX plane ... √\n",
            "loading data for user 018 on the ZX plane ... √\n",
            "loading data for user 019 on the ZX plane ... √\n",
            "loading data for user 020 on the ZX plane ... √\n",
            "loading data for user 021 on the ZX plane ... √\n",
            "loading data for user 022 on the ZX plane ... √\n",
            "loading data for user 023 on the ZX plane ... √\n",
            "loading data for user 024 on the ZX plane ... √\n",
            "loading data for user 025 on the ZX plane ... √\n",
            "8\n",
            "Epoch 1/300\n",
            "60/60 [==============================] - 23s 258ms/step - loss: 2.6507 - accuracy: 0.1935 - val_loss: 1.7989 - val_accuracy: 0.6000\n",
            "Epoch 2/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 1.6426 - accuracy: 0.4914 - val_loss: 0.6833 - val_accuracy: 0.8375\n",
            "Epoch 3/300\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.9157 - accuracy: 0.7161 - val_loss: 0.2505 - val_accuracy: 0.9750\n",
            "Epoch 4/300\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.5935 - accuracy: 0.8159 - val_loss: 0.1401 - val_accuracy: 0.9875\n",
            "Epoch 5/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.4544 - accuracy: 0.8583 - val_loss: 0.1171 - val_accuracy: 0.9812\n",
            "Epoch 6/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.3728 - accuracy: 0.8865 - val_loss: 0.1001 - val_accuracy: 0.9750\n",
            "Epoch 7/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.2919 - accuracy: 0.9086 - val_loss: 0.0660 - val_accuracy: 0.9875\n",
            "Epoch 8/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.2473 - accuracy: 0.9250 - val_loss: 0.0714 - val_accuracy: 0.9812\n",
            "Epoch 9/300\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.2180 - accuracy: 0.9310 - val_loss: 0.0495 - val_accuracy: 0.9937\n",
            "Epoch 10/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.1929 - accuracy: 0.9396 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
            "Epoch 11/300\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.1773 - accuracy: 0.9471 - val_loss: 0.0418 - val_accuracy: 0.9937\n",
            "Epoch 12/300\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.1660 - accuracy: 0.9503 - val_loss: 0.0447 - val_accuracy: 0.9937\n",
            "Epoch 13/300\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1509 - accuracy: 0.9484 - val_loss: 0.0425 - val_accuracy: 0.9937\n",
            "Epoch 14/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.1359 - accuracy: 0.9547 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
            "Epoch 15/300\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.1251 - accuracy: 0.9615 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
            "Epoch 16/300\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.1120 - accuracy: 0.9641 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
            "Epoch 17/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.1060 - accuracy: 0.9677 - val_loss: 0.0299 - val_accuracy: 0.9937\n",
            "Epoch 18/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.1016 - accuracy: 0.9674 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
            "Epoch 19/300\n",
            "60/60 [==============================] - 13s 223ms/step - loss: 0.1089 - accuracy: 0.9635 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
            "Epoch 20/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0840 - accuracy: 0.9714 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
            "Epoch 21/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0910 - accuracy: 0.9716 - val_loss: 0.0263 - val_accuracy: 0.9937\n",
            "Epoch 22/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0852 - accuracy: 0.9716 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
            "Epoch 23/300\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.0786 - accuracy: 0.9768 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
            "Epoch 24/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0686 - accuracy: 0.9807 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
            "Epoch 25/300\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.0663 - accuracy: 0.9828 - val_loss: 0.0184 - val_accuracy: 0.9937\n",
            "Epoch 26/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0623 - accuracy: 0.9823 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
            "Epoch 27/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0593 - accuracy: 0.9815 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 28/300\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.0588 - accuracy: 0.9826 - val_loss: 0.0164 - val_accuracy: 0.9937\n",
            "Epoch 29/300\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.0559 - accuracy: 0.9846 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
            "Epoch 30/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0522 - accuracy: 0.9865 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
            "Epoch 31/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0551 - accuracy: 0.9836 - val_loss: 0.0164 - val_accuracy: 0.9937\n",
            "Epoch 32/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0517 - accuracy: 0.9849 - val_loss: 0.0146 - val_accuracy: 0.9937\n",
            "Epoch 33/300\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.0487 - accuracy: 0.9854 - val_loss: 0.0202 - val_accuracy: 0.9875\n",
            "Epoch 34/300\n",
            "60/60 [==============================] - 13s 223ms/step - loss: 0.0450 - accuracy: 0.9878 - val_loss: 0.0156 - val_accuracy: 0.9937\n",
            "Epoch 35/300\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.0529 - accuracy: 0.9812 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 36/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0420 - accuracy: 0.9859 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 37/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0414 - accuracy: 0.9872 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
            "Epoch 38/300\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0392 - accuracy: 0.9893 - val_loss: 0.0147 - val_accuracy: 0.9937\n",
            "Epoch 39/300\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.0437 - accuracy: 0.9867 - val_loss: 0.0168 - val_accuracy: 0.9937\n",
            "Epoch 40/300\n",
            "60/60 [==============================] - 13s 224ms/step - loss: 0.0355 - accuracy: 0.9914 - val_loss: 0.0171 - val_accuracy: 0.9937\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.0457 - accuracy: 1.0000\n",
            "100.00 %\n",
            "------------------------------------\n",
            "Average accuracy 99.10 +/- 1.56\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ACC = []\n",
        "CM = []\n",
        "HISTORY = []\n",
        "logs = ''\n",
        "\n",
        "# ... Change user limit\n",
        "users = USERS[16:]\n",
        "\n",
        "for test_user in users:\n",
        "    print('Processing results for user ' + test_user, end='... \\n')\n",
        "    \n",
        "    X_train = []\n",
        "    X_test = []\n",
        "    y_train = []\n",
        "    y_test = []\n",
        "    \n",
        "    first_time_train = True\n",
        "    first_time_test = True\n",
        "\n",
        "    for user in USERS:\n",
        "        x_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_X.joblib')\n",
        "        y_path = os.path.join(BASE_DIR, CHANNELS_DIR, CHANNELS_GROUP + user + '_y.joblib')\n",
        "        X = joblib.load(x_path)\n",
        "        y = joblib.load(y_path)\n",
        "\n",
        "        if user == test_user:\n",
        "            if first_time_train == True:\n",
        "                first_time_train = False\n",
        "                X_test = X\n",
        "                y_test = y\n",
        "                \n",
        "            else:\n",
        "                X_test = np.append(X_test, X, axis=0)\n",
        "                y_test = np.append(y_test, y, axis=0)\n",
        "                \n",
        "        else:\n",
        "            if first_time_test == True:\n",
        "                first_time_test = False\n",
        "                X_train = X\n",
        "                y_train = y\n",
        "                \n",
        "            else:\n",
        "                X_train = np.append(X_train, X, axis=0)\n",
        "                y_train = np.append(y_train, y, axis=0)\n",
        "\n",
        "\n",
        "    # X_train, y_train = shuffle(X_train, y_train)\n",
        "\n",
        "    X_train_xy, X_test_xy, y_train_xy, y_test_xy = load_data('XY', test_user)\n",
        "    X_train_yz, X_test_yz, y_train_yz, y_test_yz = load_data('YZ', test_user)\n",
        "    X_train_zx, X_test_zx, y_train_zx, y_test_zx = load_data('ZX', test_user)\n",
        "\n",
        "    X_train_xy, X_train_yz, X_train_zx, X_train, y_train = shuffle(\n",
        "        X_train_xy, X_train_yz, X_train_zx, X_train, y_train\n",
        "    )\n",
        "\n",
        "    X_train_combined = np.split(X_train, 8, axis=-1)[:5] + [X_train_xy, X_train_yz, X_train_zx]\n",
        "    X_test_combined = np.split(X_test, 8, axis=-1)[:5] + [X_test_xy, X_test_yz, X_test_zx]\n",
        "\n",
        "    del X_train_xy, X_test_xy, y_train_xy, y_test_xy\n",
        "    del X_train_yz, X_test_yz, y_train_yz, y_test_yz\n",
        "    del X_train_zx, X_test_zx, y_train_zx, y_test_zx\n",
        "    del X_train, X_test\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    print(len(X_train_combined))\n",
        "\n",
        "    callbacks = [\n",
        "                 tf.keras.callbacks.EarlyStopping(\n",
        "                    monitor='val_accuracy', \n",
        "                    patience=30, \n",
        "                    mode='max', \n",
        "                    restore_best_weights=True\n",
        "                ),\n",
        "    ]\n",
        "\n",
        "    model = get_stacked_model()\n",
        "    history = model.fit(\n",
        "        X_train_combined, \n",
        "        y_train, \n",
        "        validation_data=(X_test_combined, y_test),\n",
        "        epochs=300, \n",
        "        batch_size=64,\n",
        "        callbacks=[callbacks]\n",
        "    )\n",
        "    _, accuracy = model.evaluate(X_test_combined, y_test, batch_size=64)\n",
        "    y_pred = model.predict(X_test_combined)\n",
        "    cm = confusion_matrix(y_test.ravel(), np.argmax(y_pred, axis=-1))\n",
        "\n",
        "    CM.append(cm)\n",
        "    HISTORY.append(history)\n",
        "\n",
        "    accuracy = accuracy * 100\n",
        "    print(f'%.2f %%' %(accuracy))\n",
        "    logs = logs + 'Accuracy for user ' + str(test_user) + '... ' + str(accuracy) + '\\n'\n",
        "    ACC.append(accuracy)\n",
        "\n",
        "    del model, history\n",
        "    gc.collect()\n",
        "    \n",
        "AVG_ACC = np.mean(ACC)\n",
        "STD = np.std(ACC)\n",
        "print('------------------------------------')\n",
        "print(f'Average accuracy %.2f +/- %.2f' %(AVG_ACC, STD))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "data = {\n",
        "    \"cm\": CM,\n",
        "    \"accuracy\": ACC,\n",
        "    \"logs\": logs\n",
        "}\n",
        "\n",
        "joblib.dump(data, \"user16-25.joblib\")"
      ],
      "metadata": {
        "id": "HeOI8hw3zCXz",
        "outputId": "5ae5e18c-5d6f-4bb8-a74f-90fb60868435",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HeOI8hw3zCXz",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['user16-25.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    pass"
      ],
      "metadata": {
        "id": "3N94GWOk9KHE"
      },
      "id": "3N94GWOk9KHE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92fd4333",
      "metadata": {
        "id": "92fd4333"
      },
      "outputs": [],
      "source": [
        "# model = get_stacked_model()\n",
        "# X_train_xy, X_train_yz, X_train_zx, y_train_xy = shuffle(\n",
        "#     X_train_xy, X_train_yz, X_train_zx, y_train_xy\n",
        "# )\n",
        "\n",
        "# history = model.fit(\n",
        "#     [X_train_xy, X_train_yz, X_train_zx],\n",
        "#     y_train_xy,\n",
        "#     validation_data=([X_test_xy, X_test_yz, X_test_zx], y_test_xy),\n",
        "#     batch_size=32,\n",
        "#     epochs=10,\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "distinct-appendix",
      "metadata": {
        "id": "distinct-appendix",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# model_xy = get_model()\n",
        "# X_train_xy, y_train_xy = shuffle(X_train_xy, y_train_xy)\n",
        "# history_xy = model_xy.fit(X_train_xy, y_train_xy, validation_data=(X_test_xy, y_test_xy), epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "constitutional-genre",
      "metadata": {
        "id": "constitutional-genre"
      },
      "outputs": [],
      "source": [
        "# # prob_xy = tf.keras.Sequential([model_xy, tf.keras.layers.Softmax()])\n",
        "# # y_pred_xy = prob_xy.predict(X_test_xy)\n",
        "# y_pred_xy = model_xy.predict(X_test_xy)\n",
        "# y_pred = np.argmax(y_pred_xy, axis=1)\n",
        "# print(classification_report(y_test_xy.ravel(), y_pred, zero_division=0))\n",
        "# prc_xy = precision_score(y_test_xy.ravel(), y_pred, zero_division=0, average=None)\n",
        "# tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "emotional-chrome",
      "metadata": {
        "id": "emotional-chrome"
      },
      "outputs": [],
      "source": [
        "# model_yz = get_model()\n",
        "# X_train_yz, y_train_yz = shuffle(X_train_yz, y_train_yz)\n",
        "# history_yz = model_yz.fit(X_train_yz, y_train_yz, validation_data=(X_test_yz, y_test_yz), epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "boring-insurance",
      "metadata": {
        "id": "boring-insurance"
      },
      "outputs": [],
      "source": [
        "# # prob_yz = tf.keras.Sequential([model_yz, tf.keras.layers.Softmax()])\n",
        "# # y_pred_yz = prob_yz.predict(X_test_yz)\n",
        "# y_pred_yz = model_yz.predict(X_test_yz)\n",
        "# y_pred = np.argmax(y_pred_yz, axis=1)\n",
        "# print(classification_report(y_test_yz.ravel(), y_pred, zero_division=0))\n",
        "# prc_yz = precision_score(y_test_yz.ravel(), y_pred, zero_division=0, average=None)\n",
        "# tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "joint-evaluation",
      "metadata": {
        "id": "joint-evaluation"
      },
      "outputs": [],
      "source": [
        "# model_zx = get_model()\n",
        "# X_train_zx, y_train_zx = shuffle(X_train_zx, y_train_zx)\n",
        "# history_zx = model_zx.fit(X_train_zx, y_train_zx, validation_data=(X_test_zx, y_test_zx), epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "designed-still",
      "metadata": {
        "id": "designed-still"
      },
      "outputs": [],
      "source": [
        "# # prob_zx = tf.keras.Sequential([model_zx, tf.keras.layers.Softmax()])\n",
        "# # y_pred_zx = prob_zx.predict(X_test_zx)\n",
        "# y_pred_zx = model_zx.predict(X_test_zx)\n",
        "# y_pred = np.argmax(y_pred_zx, axis=1)\n",
        "# print(classification_report(y_test_zx.ravel(), y_pred, zero_division=0))\n",
        "# prc_zx = precision_score(y_test_zx.ravel(), y_pred, zero_division=0, average=None)\n",
        "# tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "selective-geography",
      "metadata": {
        "id": "selective-geography"
      },
      "outputs": [],
      "source": [
        "# y_total = y_pred_xy + y_pred_yz + y_pred_zx\n",
        "# y_pred = np.argmax(y_total, axis=1)\n",
        "# report = classification_report(y_test_xy.ravel(), y_pred, zero_division=0)\n",
        "# print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collected-palmer",
      "metadata": {
        "id": "collected-palmer"
      },
      "outputs": [],
      "source": [
        "# config = '\\n\\nTEST_USER ' + TEST_USER + ' T: ' + str(int(time.time())) + '\\n'\n",
        "# underline = '=====================================\\n'\n",
        "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
        "# if not os.path.exists(log_dir):\n",
        "#     os.mkdir(log_dir)\n",
        "# f = open(os.path.join(log_dir, 'logs_sptl_bw' + CONFIG + '.txt'), 'a')\n",
        "# f.write(config)\n",
        "# f.write(underline)\n",
        "# f.write(report)\n",
        "# f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "intellectual-lunch",
      "metadata": {
        "id": "intellectual-lunch"
      },
      "outputs": [],
      "source": [
        "# config = TEST_USER + ' :'\n",
        "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
        "# if not os.path.exists(log_dir):\n",
        "#     os.mkdir(log_dir)\n",
        "# f = open(os.path.join(log_dir, 'prc_sptl_bw_xy' + CONFIG + '.txt'), 'a')\n",
        "# f.write(config)\n",
        "# f.write(np.array2string(prc_xy, precision=2, max_line_width=100) + '\\n')\n",
        "# f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "trying-thread",
      "metadata": {
        "id": "trying-thread"
      },
      "outputs": [],
      "source": [
        "# config = TEST_USER + ' :'\n",
        "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
        "# if not os.path.exists(log_dir):\n",
        "#     os.mkdir(log_dir)\n",
        "# f = open(os.path.join(log_dir, 'prc_sptl_bw_yz' + CONFIG + '.txt'), 'a')\n",
        "# f.write(config)\n",
        "# f.write(np.array2string(prc_yz, precision=2, max_line_width=100) + '\\n')\n",
        "# f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "general-plant",
      "metadata": {
        "id": "general-plant"
      },
      "outputs": [],
      "source": [
        "# config = TEST_USER + ' :'\n",
        "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
        "# if not os.path.exists(log_dir):\n",
        "#     os.mkdir(log_dir)\n",
        "# f = open(os.path.join(log_dir, 'prc_sptl_bw_zx' + CONFIG + '.txt'), 'a')\n",
        "# f.write(config)\n",
        "# f.write(np.array2string(prc_zx, precision=2, max_line_width=100) + '\\n')\n",
        "# f.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Spatial_Path_Transfer_Learning_BW.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}