{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/Hand-Gesture-Recognition/blob/dev/Spatial-Path-Analysis/Spatial_Path_Transfer_Learning_BW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "tamil-chrome",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tamil-chrome",
        "outputId": "02e7848f-7575-41ad-ccdd-2dde159a865a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import joblib\n",
        "import shutil\n",
        "import tarfile\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, GlobalAvgPool2D, Dropout, Flatten, concatenate\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "MfafORnwZkyT",
      "metadata": {
        "id": "MfafORnwZkyT"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "casual-stack",
      "metadata": {
        "id": "casual-stack"
      },
      "outputs": [],
      "source": [
        "# -------- TEST USER ----------- #\n",
        "\n",
        "TEST_USER      = '010'\n",
        "DATASET_ID     = '1p0CSRb9gax0sKqdyzOYVt-BXvZ4GtrBv'\n",
        "\n",
        "# BASE_DIR       = '../Dataset/'\n",
        "\n",
        "# Google Drive\n",
        "BASE_DIR       = '.'\n",
        "DATA_DIR       = 'Sensor-Data/'\n",
        "BW_IMG_DIR     = 'BW-Spatial-Path-Images/'\n",
        "RGB_IMG_DIR    = 'RGB-Spatial-Path-Images/'\n",
        "IMG_SIZE       = (3, 3) # INCHES\n",
        "\n",
        "IMG_DIR        = 'BW-Spatial-Path-Images/'\n",
        "LOG_DIR        = 'Logs/'\n",
        "\n",
        "USERS          = ['001', '002', '003', '004', '005', '006', '007', '008', '009',\n",
        "                  '010', '011', '012', '013', '014', '015', '016', '017', '018',\n",
        "                  '019', '020', '021', '022', '023', '024', '025']\n",
        "\n",
        "# ------------------------------- Only Dynalic Gestures ------------------------------ #\n",
        "GESTURES       = ['j', 'z', 'bad', 'deaf', 'fine', 'good', 'goodbye', 'hello', 'hungry',\n",
        "                  'me', 'no', 'please', 'sorry', 'thankyou', 'yes', 'you']\n",
        "\n",
        "PLANES         = ['XY', 'YZ', 'ZX']\n",
        "\n",
        "BATCH_SIZE     = 32\n",
        "IMG_LEN        = 32\n",
        "IMG_SIZE       = (IMG_LEN, IMG_LEN)\n",
        "\n",
        "# ------------- FOR THE GREATER GOOD :) ------------- #\n",
        "DATASET_LEN    = 4000\n",
        "TRAIN_LEN      = 3840\n",
        "TEST_LEN       = 160\n",
        "\n",
        "EPOCHS         = 50\n",
        "LEARNING_RATE  = 0.001\n",
        "DECAY          = 0.0\n",
        "\n",
        "DT             = 0.01\n",
        "SHAPES         = 100\n",
        "\n",
        "CONFIG         = '_L_7_S_160x160_E_7'\n",
        "\n",
        "XY_WEIGHTS     = np.array([0.91, 0.75, 0.61, 0.63, 0.51, 0.66, 0.81, 0.65, 0.65, 0.31,\n",
        "                           0.66, 0.29, 0.34, 0.64, 0.64, 0.31])\n",
        "YZ_WEIGHTS     = np.array([0.73, 0.71, 0.70, 0.79, 0.76, 0.38, 0.80, 0.61, 0.58, 0.73,\n",
        "                           0.49, 0.26, 0.26, 0.52, 0.59, 0.54])\n",
        "ZX_WEIGHTS     = np.array([0.33, 0.66, 0.51, 0.54, 0.37, 0.51, 0.71, 0.30, 0.75, 0.41,\n",
        "                           0.40, 0.27, 0.24, 0.61, 0.36, 0.49])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------- Download util for Google Drive ------------------- #\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "        \n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "        \n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "\n",
        "def download_data(fid, destination):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(destination)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('creating data directory ... ', end='')\n",
        "    os.mkdir(destination)\n",
        "    print('√')\n",
        "    \n",
        "    print('downloading dataset from the repository ... ', end='')\n",
        "    filename = os.path.join(destination, 'dataset.tar.xz')\n",
        "    try:\n",
        "        download_file_from_google_drive(fid, filename)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('extracting the dataset ... ', end='')\n",
        "    try:\n",
        "        tar = tarfile.open(filename)\n",
        "        tar.extractall(destination)\n",
        "        tar.close()\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')   "
      ],
      "metadata": {
        "id": "ksdY7MgcqHNr"
      },
      "id": "ksdY7MgcqHNr",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------- Comment This if already downloaded -------- #\n",
        "\n",
        "# destination = os.path.join(BASE_DIR, DATA_DIR)\n",
        "# download_data(DATASET_ID, destination)"
      ],
      "metadata": {
        "id": "MtE4QJm-qOZY"
      },
      "id": "MtE4QJm-qOZY",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------- Spatial Path Image Generation ----------- #\n",
        "\n",
        "def clean_dir(path):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(path)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "    \n",
        "    print('creating ' + path + ' directory ... ', end='')\n",
        "    os.mkdir(path)\n",
        "    print('√')\n",
        "    \n",
        "# ----------- Spatial Path Vector Calculation ----------- #\n",
        "\n",
        "def get_displacement(acc):\n",
        "    v = np.zeros(acc.shape)\n",
        "    d = np.zeros(acc.shape)\n",
        "    for i in range(acc.shape[0] - 1):\n",
        "        v[i + 1] = v[i] + acc[i] * DT\n",
        "        d[i + 1] = v[i] * DT + 0.5 * acc[i] * DT * DT\n",
        "        \n",
        "    return d\n",
        "\n",
        "def write_image(x, y, path):\n",
        "    fig, ax = plt.subplots(frameon=True, figsize=(3, 3))\n",
        "    ax.axis('off')\n",
        "    plt.scatter(x, y, s=SHAPES, c='black')\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "def generate_bw_images():\n",
        "    count = 0\n",
        "    image_dir = os.path.join(BASE_DIR, BW_IMG_DIR)\n",
        "    clean_dir(image_dir)\n",
        "    \n",
        "    for plane in PLANES:\n",
        "        print('processing spatial path images for ' + plane + ' plane ... ', end='')\n",
        "        plane_dir = os.path.join(image_dir, plane)\n",
        "        os.mkdir(plane_dir)\n",
        "        \n",
        "        for gesture in GESTURES:\n",
        "            os.mkdir(os.path.join(plane_dir, gesture))\n",
        "    \n",
        "            for user in USERS:\n",
        "                user_dir = os.path.join(BASE_DIR, DATA_DIR, user)\n",
        "                gesture_dir = os.path.join(user_dir, gesture + '.csv')\n",
        "                \n",
        "                accx = pd.read_csv(gesture_dir)['ACCx'].to_numpy()\n",
        "                accy = pd.read_csv(gesture_dir)['ACCy'].to_numpy()\n",
        "                accz = pd.read_csv(gesture_dir)['ACCz'].to_numpy()\n",
        "\n",
        "                x = get_displacement(accx).reshape(-1, 150)\n",
        "                y = get_displacement(accy).reshape(-1, 150)\n",
        "                z = get_displacement(accz).reshape(-1, 150)\n",
        "\n",
        "                for i in range(x.shape[0]):\n",
        "                    image_name = 'u' + user + '_g' + '{:0>2d}'.format(GESTURES.index(gesture)) + \\\n",
        "                                 '_s' + '{:0>7d}'.format(count) + '_p' + plane + '.jpg'\n",
        "                    path = os.path.join(BASE_DIR, BW_IMG_DIR, plane, gesture, image_name)\n",
        "                    \n",
        "                    if plane == 'XY':\n",
        "                        write_image(x[i, :], y[i, :], path)\n",
        "                    elif plane == 'YZ':\n",
        "                        write_image(y[i, :], z[i, :], path)\n",
        "                    else:\n",
        "                        write_image(z[i, :], x[i, :], path)\n",
        "\n",
        "                    count = count + 1\n",
        "            \n",
        "        print('√')"
      ],
      "metadata": {
        "id": "QmReRMF-qQcl"
      },
      "id": "QmReRMF-qQcl",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate_bw_images()"
      ],
      "metadata": {
        "id": "07jhA8ukqScv"
      },
      "id": "07jhA8ukqScv",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "stylish-banner",
      "metadata": {
        "id": "stylish-banner"
      },
      "outputs": [],
      "source": [
        "def load_data(plane):\n",
        "    X_train = np.zeros((TRAIN_LEN, IMG_LEN, IMG_LEN, 1), dtype='uint8')\n",
        "    X_test = np.zeros((TEST_LEN, IMG_LEN, IMG_LEN, 1), dtype='uint8')\n",
        "    y_train = np.zeros((TRAIN_LEN, 1), dtype='uint8')\n",
        "    y_test = np.zeros((TEST_LEN, 1), dtype='uint8')\n",
        "    \n",
        "    train_count = 0\n",
        "    test_count = 0\n",
        "        \n",
        "    for gesture in GESTURES:\n",
        "        print('loading data for ' + gesture + ' gesture on the ' + plane + ' plane ... ', end='')\n",
        "        path = os.path.join(BASE_DIR, IMG_DIR, plane, gesture)\n",
        "        for filename in os.listdir(path):\n",
        "            img = cv2.imread(os.path.join(path, filename), cv2.IMREAD_GRAYSCALE)\n",
        "            resized = cv2.resize(img, IMG_SIZE)\n",
        "            resized = np.expand_dims(resized, axis=-1)\n",
        "            if filename[1:4] != TEST_USER:\n",
        "                X_train[train_count, :] = resized\n",
        "                y_train[train_count, 0] = GESTURES.index(gesture)\n",
        "                train_count = train_count + 1\n",
        "            else:\n",
        "                X_test[test_count, :] = resized\n",
        "                y_test[test_count, 0] = GESTURES.index(gesture)\n",
        "                test_count = test_count + 1\n",
        "                \n",
        "        print('√')\n",
        "        \n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def load_and_save_data(plane):\n",
        "    X = np.zeros((DATASET_LEN, IMG_LEN, IMG_LEN, 1))\n",
        "    y = np.zeros((DATASET_LEN, 1))\n",
        "    \n",
        "    train_count = 0\n",
        "    test_count  = TRAIN_LEN\n",
        "        \n",
        "    for gesture in GESTURES:\n",
        "        print('loading data for ' + gesture + ' gesture on the ' + plane + ' plane ... ', end='')\n",
        "        path = os.path.join(BASE_DIR, IMG_DIR, plane, gesture)\n",
        "        for filename in os.listdir(path):\n",
        "            img = cv2.imread(os.path.join(path, filename), cv2.IMREAD_GRAYSCALE)\n",
        "            resized = cv2.resize(img, IMG_SIZE)\n",
        "            if filename[1:4] != TEST_USER:\n",
        "                X[train_count, :] = resized\n",
        "                y[train_count, 0] = GESTURES.index(gesture)\n",
        "                train_count = train_count + 1\n",
        "            else:\n",
        "                X[test_count, :] = resized\n",
        "                y[test_count, 0] = GESTURES.index(gesture)\n",
        "                test_count = test_count + 1\n",
        "                \n",
        "        print('√')\n",
        "\n",
        "    joblib.dump(X, BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    joblib.dump(y, BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "\n",
        "def load_data_from_joblib(plane):\n",
        "    print('Loading data for ' + plane + ' plane ... ', end='')\n",
        "    X = joblib.load(BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    y = joblib.load(BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "    test_user = int(TEST_USER)\n",
        "    X_train = X[:TRAIN_LEN, :, :, :]\n",
        "    y_train = y[:TRAIN_LEN, :]\n",
        "    X_test = X[TRAIN_LEN:, :, :, :]\n",
        "    y_test = y[TRAIN_LEN:, :]\n",
        "\n",
        "    print('√')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "extra-disclosure",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "extra-disclosure",
        "outputId": "3fd3a7e9-7ee4-4c73-82d8-82f2df9e086d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data for j gesture on the XY plane ... √\n",
            "loading data for z gesture on the XY plane ... √\n",
            "loading data for bad gesture on the XY plane ... √\n",
            "loading data for deaf gesture on the XY plane ... √\n",
            "loading data for fine gesture on the XY plane ... √\n",
            "loading data for good gesture on the XY plane ... √\n",
            "loading data for goodbye gesture on the XY plane ... √\n",
            "loading data for hello gesture on the XY plane ... √\n",
            "loading data for hungry gesture on the XY plane ... √\n",
            "loading data for me gesture on the XY plane ... √\n",
            "loading data for no gesture on the XY plane ... √\n",
            "loading data for please gesture on the XY plane ... √\n",
            "loading data for sorry gesture on the XY plane ... √\n",
            "loading data for thankyou gesture on the XY plane ... √\n",
            "loading data for yes gesture on the XY plane ... √\n",
            "loading data for you gesture on the XY plane ... √\n",
            "loading data for j gesture on the YZ plane ... √\n",
            "loading data for z gesture on the YZ plane ... √\n",
            "loading data for bad gesture on the YZ plane ... √\n",
            "loading data for deaf gesture on the YZ plane ... √\n",
            "loading data for fine gesture on the YZ plane ... √\n",
            "loading data for good gesture on the YZ plane ... √\n",
            "loading data for goodbye gesture on the YZ plane ... √\n",
            "loading data for hello gesture on the YZ plane ... √\n",
            "loading data for hungry gesture on the YZ plane ... √\n",
            "loading data for me gesture on the YZ plane ... √\n",
            "loading data for no gesture on the YZ plane ... √\n",
            "loading data for please gesture on the YZ plane ... √\n",
            "loading data for sorry gesture on the YZ plane ... √\n",
            "loading data for thankyou gesture on the YZ plane ... √\n",
            "loading data for yes gesture on the YZ plane ... √\n",
            "loading data for you gesture on the YZ plane ... √\n",
            "loading data for j gesture on the ZX plane ... √\n",
            "loading data for z gesture on the ZX plane ... √\n",
            "loading data for bad gesture on the ZX plane ... √\n",
            "loading data for deaf gesture on the ZX plane ... √\n",
            "loading data for fine gesture on the ZX plane ... √\n",
            "loading data for good gesture on the ZX plane ... √\n",
            "loading data for goodbye gesture on the ZX plane ... √\n",
            "loading data for hello gesture on the ZX plane ... √\n",
            "loading data for hungry gesture on the ZX plane ... √\n",
            "loading data for me gesture on the ZX plane ... √\n",
            "loading data for no gesture on the ZX plane ... √\n",
            "loading data for please gesture on the ZX plane ... √\n",
            "loading data for sorry gesture on the ZX plane ... √\n",
            "loading data for thankyou gesture on the ZX plane ... √\n",
            "loading data for yes gesture on the ZX plane ... √\n",
            "loading data for you gesture on the ZX plane ... √\n"
          ]
        }
      ],
      "source": [
        "X_train_xy, X_test_xy, y_train_xy, y_test_xy = load_data('XY')\n",
        "X_train_yz, X_test_yz, y_train_yz, y_test_yz = load_data('YZ')\n",
        "X_train_zx, X_test_zx, y_train_zx, y_test_zx = load_data('ZX')\n",
        "\n",
        "# Save to Google  Drive\n",
        "# load_and_save_data('XY')X_train_xy, y_train_xy = shuffle(X_train_xy, y_train_xy)\n",
        "# load_and_save_data('YZ')\n",
        "# load_and_save_data('ZX')\n",
        "\n",
        "# Load from Google Drive\n",
        "# X_train_xy, X_test_xy, y_train_xy, y_test_xy = load_data_from_joblib('XY')\n",
        "# X_train_yz, X_test_yz, y_train_yz, y_test_yz = load_data_from_joblib('YZ')\n",
        "# X_train_zx, X_test_zx, y_train_zx, y_test_zx = load_data_from_joblib('ZX')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "conditional-advisory",
      "metadata": {
        "id": "conditional-advisory"
      },
      "outputs": [],
      "source": [
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "internal-arkansas",
      "metadata": {
        "id": "internal-arkansas"
      },
      "outputs": [],
      "source": [
        "IMG_SHAPE = IMG_SIZE + (1,)\n",
        "# base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "# base_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "strange-encoding",
      "metadata": {
        "id": "strange-encoding"
      },
      "outputs": [],
      "source": [
        "global_average_layer = GlobalAvgPool2D()\n",
        "prediction_layer = Dense(len(GESTURES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6e049e9a",
      "metadata": {
        "id": "6e049e9a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.keras.layers.pooling import MaxPooling2D\n",
        "def get_cnn_block():\n",
        "    input = tf.keras.layers.Input(shape=IMG_SHAPE)\n",
        "    # x = data_augmentation(input)\n",
        "    # x = preprocess_input(input)\n",
        "    # x = base_model(x, training=False)\n",
        "    # x = global_average_layer(x)\n",
        "\n",
        "    x = layers.Conv2D(16, 3, padding=\"valid\", kernel_regularizer=regularizers.l2(0.001),)(\n",
        "        input\n",
        "    )\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = tf.keras.activations.relu(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(32, 3, padding=\"valid\", kernel_regularizer=regularizers.l2(0.001),)(\n",
        "        x\n",
        "    )\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = tf.keras.activations.relu(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(\n",
        "        64, 3, padding=\"valid\", kernel_regularizer=regularizers.l2(0.001),\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = tf.keras.activations.relu(x)\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    return input, x\n",
        "\n",
        "\n",
        "def get_stacked_model(n):\n",
        "    inputs = []\n",
        "    CNNs = []\n",
        "\n",
        "    for i in range(n):\n",
        "        input_i, CNN_i = get_cnn_block()\n",
        "        inputs.append(input_i)\n",
        "        CNNs.append(CNN_i)\n",
        "\n",
        "    x = concatenate(CNNs, axis=-1)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    output = Dense(16)(x)\n",
        "    model = Model(inputs, output)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=3e-4)\n",
        "    loss = SparseCategoricalCrossentropy(from_logits=True)\n",
        "    model.compile(loss=loss, optimizer=opt, metrics=[\"accuracy\"])\n",
        "    \n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_stacked_model(1)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "WTWKoIlYyzKW",
        "outputId": "0f8bf071-b3b8-495a-e1b6-d8fc7610446b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WTWKoIlYyzKW",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 30, 30, 16)        160       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 30, 30, 16)       64        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " tf.nn.relu (TFOpLambda)     (None, 30, 30, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 32)        4640      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 13, 13, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " tf.nn.relu_1 (TFOpLambda)   (None, 13, 13, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 64)          18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 4, 4, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " tf.nn.relu_2 (TFOpLambda)   (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " concatenate (Concatenate)   (None, 1024)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               131200    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                2064      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 157,008\n",
            "Trainable params: 156,784\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "upper-tobago",
      "metadata": {
        "id": "upper-tobago"
      },
      "outputs": [],
      "source": [
        "# def get_model():\n",
        "#     inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
        "#     #     x = data_augmentation(inputs)\n",
        "#     x = preprocess_input(inputs)\n",
        "#     x = base_model(x, training=False)\n",
        "#     x = global_average_layer(x)\n",
        "#     x = tf.keras.layers.Dropout(0.2)(x)\n",
        "#     outputs = prediction_layer(x)\n",
        "#     model = tf.keras.Model(inputs, outputs)\n",
        "#     model.compile(\n",
        "#         optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE, decay=DECAY),\n",
        "#         loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#         metrics=[\"accuracy\"],\n",
        "#     )\n",
        "#     return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "92fd4333",
      "metadata": {
        "id": "92fd4333",
        "outputId": "d445df91-26ff-4eb1-8b26-94a873a7e726",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "120/120 [==============================] - 5s 11ms/step - loss: 1.3170 - accuracy: 0.6516 - val_loss: 1.0841 - val_accuracy: 0.7063\n",
            "Epoch 2/10\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.5910 - accuracy: 0.8654 - val_loss: 0.8475 - val_accuracy: 0.7812\n",
            "Epoch 3/10\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.4571 - accuracy: 0.9104 - val_loss: 0.7744 - val_accuracy: 0.8000\n",
            "Epoch 4/10\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.3729 - accuracy: 0.9367 - val_loss: 0.8793 - val_accuracy: 0.8125\n",
            "Epoch 5/10\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.3196 - accuracy: 0.9552 - val_loss: 0.8740 - val_accuracy: 0.7563\n",
            "Epoch 6/10\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.2869 - accuracy: 0.9667 - val_loss: 0.8059 - val_accuracy: 0.7688\n",
            "Epoch 7/10\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.2559 - accuracy: 0.9742 - val_loss: 0.8241 - val_accuracy: 0.7875\n",
            "Epoch 8/10\n",
            "120/120 [==============================] - 1s 9ms/step - loss: 0.2425 - accuracy: 0.9781 - val_loss: 0.8657 - val_accuracy: 0.8062\n",
            "Epoch 9/10\n",
            "120/120 [==============================] - 1s 9ms/step - loss: 0.2270 - accuracy: 0.9828 - val_loss: 0.8892 - val_accuracy: 0.7750\n",
            "Epoch 10/10\n",
            "120/120 [==============================] - 1s 10ms/step - loss: 0.2113 - accuracy: 0.9865 - val_loss: 0.8160 - val_accuracy: 0.8188\n"
          ]
        }
      ],
      "source": [
        "model = get_stacked_model(3)\n",
        "X_train_xy, X_train_yz, X_train_zx, y_train_xy = shuffle(\n",
        "    X_train_xy, X_train_yz, X_train_zx, y_train_xy\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train_xy, X_train_yz, X_train_zx],\n",
        "    y_train_xy,\n",
        "    validation_data=([X_test_xy, X_test_yz, X_test_zx], y_test_xy),\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "distinct-appendix",
      "metadata": {
        "id": "distinct-appendix",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# model_xy = get_model()\n",
        "# X_train_xy, y_train_xy = shuffle(X_train_xy, y_train_xy)\n",
        "# history_xy = model_xy.fit(X_train_xy, y_train_xy, validation_data=(X_test_xy, y_test_xy), epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "constitutional-genre",
      "metadata": {
        "id": "constitutional-genre"
      },
      "outputs": [],
      "source": [
        "# # prob_xy = tf.keras.Sequential([model_xy, tf.keras.layers.Softmax()])\n",
        "# # y_pred_xy = prob_xy.predict(X_test_xy)\n",
        "# y_pred_xy = model_xy.predict(X_test_xy)\n",
        "# y_pred = np.argmax(y_pred_xy, axis=1)\n",
        "# print(classification_report(y_test_xy.ravel(), y_pred, zero_division=0))\n",
        "# prc_xy = precision_score(y_test_xy.ravel(), y_pred, zero_division=0, average=None)\n",
        "# tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "emotional-chrome",
      "metadata": {
        "id": "emotional-chrome"
      },
      "outputs": [],
      "source": [
        "# model_yz = get_model()\n",
        "# X_train_yz, y_train_yz = shuffle(X_train_yz, y_train_yz)\n",
        "# history_yz = model_yz.fit(X_train_yz, y_train_yz, validation_data=(X_test_yz, y_test_yz), epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "boring-insurance",
      "metadata": {
        "id": "boring-insurance"
      },
      "outputs": [],
      "source": [
        "# # prob_yz = tf.keras.Sequential([model_yz, tf.keras.layers.Softmax()])\n",
        "# # y_pred_yz = prob_yz.predict(X_test_yz)\n",
        "# y_pred_yz = model_yz.predict(X_test_yz)\n",
        "# y_pred = np.argmax(y_pred_yz, axis=1)\n",
        "# print(classification_report(y_test_yz.ravel(), y_pred, zero_division=0))\n",
        "# prc_yz = precision_score(y_test_yz.ravel(), y_pred, zero_division=0, average=None)\n",
        "# tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "joint-evaluation",
      "metadata": {
        "id": "joint-evaluation"
      },
      "outputs": [],
      "source": [
        "# model_zx = get_model()\n",
        "# X_train_zx, y_train_zx = shuffle(X_train_zx, y_train_zx)\n",
        "# history_zx = model_zx.fit(X_train_zx, y_train_zx, validation_data=(X_test_zx, y_test_zx), epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "designed-still",
      "metadata": {
        "id": "designed-still"
      },
      "outputs": [],
      "source": [
        "# # prob_zx = tf.keras.Sequential([model_zx, tf.keras.layers.Softmax()])\n",
        "# # y_pred_zx = prob_zx.predict(X_test_zx)\n",
        "# y_pred_zx = model_zx.predict(X_test_zx)\n",
        "# y_pred = np.argmax(y_pred_zx, axis=1)\n",
        "# print(classification_report(y_test_zx.ravel(), y_pred, zero_division=0))\n",
        "# prc_zx = precision_score(y_test_zx.ravel(), y_pred, zero_division=0, average=None)\n",
        "# tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "selective-geography",
      "metadata": {
        "id": "selective-geography"
      },
      "outputs": [],
      "source": [
        "# y_total = y_pred_xy + y_pred_yz + y_pred_zx\n",
        "# y_pred = np.argmax(y_total, axis=1)\n",
        "# report = classification_report(y_test_xy.ravel(), y_pred, zero_division=0)\n",
        "# print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collected-palmer",
      "metadata": {
        "id": "collected-palmer"
      },
      "outputs": [],
      "source": [
        "# config = '\\n\\nTEST_USER ' + TEST_USER + ' T: ' + str(int(time.time())) + '\\n'\n",
        "# underline = '=====================================\\n'\n",
        "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
        "# if not os.path.exists(log_dir):\n",
        "#     os.mkdir(log_dir)\n",
        "# f = open(os.path.join(log_dir, 'logs_sptl_bw' + CONFIG + '.txt'), 'a')\n",
        "# f.write(config)\n",
        "# f.write(underline)\n",
        "# f.write(report)\n",
        "# f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "intellectual-lunch",
      "metadata": {
        "id": "intellectual-lunch"
      },
      "outputs": [],
      "source": [
        "# config = TEST_USER + ' :'\n",
        "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
        "# if not os.path.exists(log_dir):\n",
        "#     os.mkdir(log_dir)\n",
        "# f = open(os.path.join(log_dir, 'prc_sptl_bw_xy' + CONFIG + '.txt'), 'a')\n",
        "# f.write(config)\n",
        "# f.write(np.array2string(prc_xy, precision=2, max_line_width=100) + '\\n')\n",
        "# f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "trying-thread",
      "metadata": {
        "id": "trying-thread"
      },
      "outputs": [],
      "source": [
        "# config = TEST_USER + ' :'\n",
        "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
        "# if not os.path.exists(log_dir):\n",
        "#     os.mkdir(log_dir)\n",
        "# f = open(os.path.join(log_dir, 'prc_sptl_bw_yz' + CONFIG + '.txt'), 'a')\n",
        "# f.write(config)\n",
        "# f.write(np.array2string(prc_yz, precision=2, max_line_width=100) + '\\n')\n",
        "# f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "general-plant",
      "metadata": {
        "id": "general-plant"
      },
      "outputs": [],
      "source": [
        "# config = TEST_USER + ' :'\n",
        "# log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
        "# if not os.path.exists(log_dir):\n",
        "#     os.mkdir(log_dir)\n",
        "# f = open(os.path.join(log_dir, 'prc_sptl_bw_zx' + CONFIG + '.txt'), 'a')\n",
        "# f.write(config)\n",
        "# f.write(np.array2string(prc_zx, precision=2, max_line_width=100) + '\\n')\n",
        "# f.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Spatial_Path_Transfer_Learning_BW.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}